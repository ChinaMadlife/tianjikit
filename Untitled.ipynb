{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:48:44.458000Z",
     "start_time": "2018-12-19T08:48:44.393000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=20, n_informative= 6 ,\n",
    "             n_classes=2, n_clusters_per_class=10,random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = [u'f'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(dftrain.drop('label',axis = 1), dftrain['label'])\n",
    "dvalid = xgb.DMatrix(dftest.drop('label',axis = 1), dftest['label'])\n",
    "dtest = xgb.DMatrix(dftest.drop('label',axis = 1), dftest['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:14.138000Z",
     "start_time": "2018-12-19T08:03:14.108000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "params_dict = dict()\n",
    "\n",
    "# 以下为待调整参数\n",
    "# booster参数\n",
    "params_dict['learning_rate'] = 0.1       # 学习率，初始值为 0.1，通常越小越好。\n",
    "params_dict['n_estimators'] = 60         # 加法模型树的数量，初始值为50。\n",
    "\n",
    "# tree参数\n",
    "params_dict['max_depth'] = 3              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "params_dict['min_child_weight']= 30       # 最小叶子节点样本权重和，越大模型越保守。\n",
    "params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "params_dict['colsample_bytree'] = 1.0     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "# regulazation参数 \n",
    "# Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  \n",
    "\n",
    "params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "# 以下参数通常不需要调整\n",
    "params_dict['objective'] = 'binary:logistic'\n",
    "params_dict['tree_method'] = 'hist'       # 构建树的策略,可以是auto, exact, approx, hist\n",
    "params_dict['eval_metric'] =  'auc'\n",
    "params_dict['silent'] = 1\n",
    "params_dict['nthread'] = 2\n",
    "params_dict['scale_pos_weight'] = 1        #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "params_dict['seed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:17.098000Z",
     "start_time": "2018-12-19T08:03:17.076000Z"
    }
   },
   "outputs": [],
   "source": [
    "def auc(labels, preds):\n",
    "    \"\"\"\n",
    "    auc值的大小可以理解为: 随机抽一个正样本和一个负样本，正样本预测值比负样本大的概率\n",
    "    最简单粗暴的方法\n",
    "　　先排序，然后统计有多少正负样本对满足：正样本预测值>负样本预测值, 再除以总的正负样本对个数\n",
    "    复杂度 O(NlogN), N为样本数\n",
    "    \"\"\"\n",
    "    n_pos = sum(labels)\n",
    "    n_neg = len(labels) - n_pos\n",
    "    total_pair = n_pos * n_neg\n",
    " \n",
    "    labels_preds = zip(labels, preds)\n",
    "    labels_preds = sorted(labels_preds, key=lambda x: x[1])\n",
    "    accumulated_neg = 0\n",
    "    satisfied_pair = 0\n",
    "    for i in range(len(labels_preds)):\n",
    "        if labels_preds[i][0] == 1:\n",
    "            satisfied_pair += accumulated_neg\n",
    "        else:\n",
    "            accumulated_neg += 1\n",
    "    return satisfied_pair / float(total_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T04:36:56.374000Z",
     "start_time": "2018-12-19T04:36:56.354000Z"
    }
   },
   "outputs": [],
   "source": [
    "dtrain.slice(np.arange(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T04:33:39.948000Z",
     "start_time": "2018-12-19T04:33:39.924000Z"
    }
   },
   "outputs": [],
   "source": [
    "bst.save_model('msg.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T04:34:17.488000Z",
     "start_time": "2018-12-19T04:34:17.470000Z"
    }
   },
   "outputs": [],
   "source": [
    "booster = xgb.Booster(model_file='msg.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T03:38:43.547000Z",
     "start_time": "2018-12-19T03:38:43.525000Z"
    }
   },
   "outputs": [],
   "source": [
    "bst.get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T06:24:51.299000Z",
     "start_time": "2018-12-19T06:24:51.290000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:22.248000Z",
     "start_time": "2018-12-19T08:03:22.217000Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys,os,json,datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "\n",
    "# 定义ks评分指标,供xgboost.train函数的feval调用\n",
    "def ks_feval(preds,xgbtrain):\n",
    "    label = xgbtrain.get_label()\n",
    "    assert len(preds) == len(label)\n",
    "    df = pd.DataFrame(data = np.array([preds,label]).T,columns = ['preds','label'])\n",
    "    df_0,df_1 = df[df['label']<0.5],df[df['label']>=0.5]\n",
    "    ks,ks_pvalue = stats.ks_2samp(df_0['preds'].values,df_1['preds'].values)\n",
    "    return 'ks',ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:26.109000Z",
     "start_time": "2018-12-19T08:03:26.041000Z"
    }
   },
   "outputs": [],
   "source": [
    "def auc(labels, preds):\n",
    "    \"\"\"\n",
    "    auc值的大小可以理解为: 随机抽一个正样本和一个负样本，正样本预测值比负样本大的概率\n",
    "　　先排序，然后统计有多少正负样本对满足：正样本预测值>负样本预测值, 再除以总的正负样本对个数\n",
    "    \"\"\"\n",
    "    n_pos = sum(labels)\n",
    "    n_neg = len(labels) - n_pos\n",
    "    total_pair = n_pos * n_neg\n",
    " \n",
    "    labels_preds = zip(labels, preds)\n",
    "    labels_preds = sorted(labels_preds, key=lambda x: x[1])\n",
    "    accumulated_neg = 0\n",
    "    satisfied_pair = 0\n",
    "    for i in range(len(labels_preds)):\n",
    "        if labels_preds[i][0] == 1:\n",
    "            satisfied_pair += accumulated_neg\n",
    "        else:\n",
    "            accumulated_neg += 1\n",
    "    return satisfied_pair / float(total_pair)\n",
    "    \n",
    "def stratified_kfold(data,label,nfolds = 5):\n",
    "\n",
    "    label = np.array(label)\n",
    "    assert len(data) == len(label), 'the length of data and label not match!'\n",
    "    assert set(label) == {0,1}, 'label can only be 0 or 1!'\n",
    "    \n",
    "    index = np.arange(len(label))\n",
    "    index_0 = index[label<0.5].copy()\n",
    "    index_1 = index[label>0.5].copy()\n",
    "    np.random.shuffle(index_0)\n",
    "    np.random.shuffle(index_1)\n",
    "    \n",
    "    split_points_0 = (len(index_0) * np.arange(1,nfolds))//nfolds\n",
    "    split_points_1 = (len(index_1) * np.arange(1,nfolds))//nfolds\n",
    "    split_index_0_list = np.split(index_0,split_points_0)\n",
    "    split_index_1_list = np.split(index_1,split_points_1)\n",
    "    split_index_list = [np.concatenate((x,y)) for x,y in \n",
    "                     zip(split_index_0_list,split_index_1_list)]\n",
    "    \n",
    "    result = [(np.setdiff1d(index,x),x) for x in split_index_list]\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:26:20.609000Z",
     "start_time": "2018-12-19T08:26:20.578000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练xgb模型\n",
    "def train_xgb(params_dict,dtrain,dvalid = None,dtest = None,verbose_eval = 10):\n",
    "    \n",
    "    result = {}\n",
    "    watchlist = [x for x in [(dtrain, 'train'),(dvalid,'valid'),(dtest,'test')] if x[0] is not None]\n",
    "    datasets = [x[1] for x in watchlist]\n",
    "    \n",
    "    bst = xgb.train(params = params_dict, dtrain = dtrain, \n",
    "                    num_boost_round = params_dict.get('n_estimators',100), \n",
    "                    feval = ks_feval,verbose_eval= verbose_eval,\n",
    "                    evals = watchlist,\n",
    "                    evals_result = result)\n",
    "    dfresult = pd.DataFrame({(dataset+'_'+feval): result[dataset][feval] \n",
    "               for dataset in datasets for feval in ('auc','ks')})\n",
    "    \n",
    "    return bst,dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:30:59.252000Z",
     "start_time": "2018-12-19T08:30:58.741000Z"
    }
   },
   "outputs": [],
   "source": [
    "bst,_ = train_xgb(params_dict,dtrain,None,None,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:38:30.233000Z",
     "start_time": "2018-12-19T08:38:30.189000Z"
    }
   },
   "outputs": [],
   "source": [
    "dfimportance = dfimportance.sort('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:39:43.714000Z",
     "start_time": "2018-12-19T08:39:43.685000Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_scores = bst.get_score()\n",
    "dfimportance = pd.DataFrame({'feature':feature_scores.keys(),'importance':feature_scores.values()})\n",
    "try:\n",
    "    dfimportance = dfimportance.sort_values('importance',ascending=False)\n",
    "except AttributeError as err:\n",
    "    dfimportance = dfimportance.sort('importance',ascending = False)\n",
    "    \n",
    "dfimportance.index = range(len(dfimportance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:58:21.439000Z",
     "start_time": "2018-12-19T08:58:20.697000Z"
    }
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "#!/usr/bin/python2.7\n",
    "\n",
    "##################################################\n",
    "#update_dt:2018-12-19\n",
    "#author：liangyun\n",
    "#usage: run xgboost model\n",
    "##################################################\n",
    "from __future__ import print_function\n",
    "import datetime,sys,os\n",
    "import ks,outliers,dropfeature\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# 定义ks评分指标,供xgboost.train函数的feval调用\n",
    "def ks_feval(preds,xgbtrain):\n",
    "    label = xgbtrain.get_label()\n",
    "    assert len(preds) == len(label)\n",
    "    df = pd.DataFrame(data = np.array([preds,label]).T,columns = ['preds','label'])\n",
    "    df_0,df_1 = df[df['label']<0.5],df[df['label']>=0.5]\n",
    "    ks,ks_pvalue = stats.ks_2samp(df_0['preds'].values,df_1['preds'].values)\n",
    "    return 'ks',ks\n",
    "\n",
    "def auc(labels, preds):\n",
    "    \"\"\"\n",
    "    auc值的大小可以理解为: 随机抽一个正样本和一个负样本，正样本预测值比负样本大的概率\n",
    "　　先排序，然后统计有多少正负样本对满足：正样本预测值>负样本预测值, 再除以总的正负样本对个数\n",
    "    \"\"\"\n",
    "    n_pos = sum(labels)\n",
    "    n_neg = len(labels) - n_pos\n",
    "    total_pair = n_pos * n_neg\n",
    " \n",
    "    labels_preds = zip(labels, preds)\n",
    "    labels_preds = sorted(labels_preds, key=lambda x: x[1])\n",
    "    accumulated_neg = 0\n",
    "    satisfied_pair = 0\n",
    "    for i in range(len(labels_preds)):\n",
    "        if labels_preds[i][0] == 1:\n",
    "            satisfied_pair += accumulated_neg\n",
    "        else:\n",
    "            accumulated_neg += 1\n",
    "    return satisfied_pair / float(total_pair)\n",
    "    \n",
    "def stratified_kfold(data,label,nfolds = 5):\n",
    "\n",
    "    label = np.array(label)\n",
    "    assert len(data) == len(label), 'the length of data and label not match!'\n",
    "    assert set(label) == {0,1}, 'label can only be 0 or 1!'\n",
    "    \n",
    "    index = np.arange(len(label))\n",
    "    index_0 = index[label<0.5].copy()\n",
    "    index_1 = index[label>0.5].copy()\n",
    "    np.random.shuffle(index_0)\n",
    "    np.random.shuffle(index_1)\n",
    "    \n",
    "    split_points_0 = (len(index_0) * np.arange(1,nfolds))//nfolds\n",
    "    split_points_1 = (len(index_1) * np.arange(1,nfolds))//nfolds\n",
    "    split_index_0_list = np.split(index_0,split_points_0)\n",
    "    split_index_1_list = np.split(index_1,split_points_1)\n",
    "    split_index_list = [np.concatenate((x,y)) for x,y in \n",
    "                     zip(split_index_0_list,split_index_1_list)]\n",
    "    \n",
    "    result = [(np.setdiff1d(index,x),x) for x in split_index_list]\n",
    "    return result\n",
    "\n",
    "\n",
    "# 训练xgb模型\n",
    "def train_xgb(params_dict,dtrain,dvalid = None,dtest = None,verbose_eval = 10):\n",
    "    \n",
    "    result = {}\n",
    "    watchlist = [x for x in [(dtrain, 'train'),(dvalid,'valid'),(dtest,'test')] if x[0] is not None]\n",
    "    datasets = [x[1] for x in watchlist]\n",
    "    \n",
    "    bst = xgb.train(params = params_dict, dtrain = dtrain, \n",
    "                    num_boost_round = params_dict.get('n_estimators',100), \n",
    "                    feval = ks_feval,verbose_eval= verbose_eval,\n",
    "                    evals = watchlist,\n",
    "                    evals_result = result)\n",
    "    dfresult = pd.DataFrame({(dataset+'_'+feval): result[dataset][feval] \n",
    "               for dataset in datasets for feval in ('auc','ks')})\n",
    "    \n",
    "    return bst,dfresult\n",
    "\n",
    "class RunXgboost(object):\n",
    "    \"\"\"\n",
    "    Examples\n",
    "    ---------\n",
    "    # 准备训练数据\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data,label = datasets.make_classification(n_samples= 10000, n_features=20,n_classes=2, random_state=0)\n",
    "    dfdata = pd.DataFrame(data,columns = ['feature'+str(i) for i in range(data.shape[1])])\n",
    "    dfdata['label'] = label\n",
    "    dftrain,dftest = train_test_split(dfdata)\n",
    "    dftrain,dftest = dftrain.copy(),dftest.copy()\n",
    "    dftrain.index,dftest.index  = range(len(dftrain)),range(len(dftest))\n",
    "    dftrain.loc[0,['feature0','feature1','feature2']] = np.nan #构造若干缺失值\n",
    "    \n",
    "    \n",
    "    # 配置xgboost模型参数\n",
    "    params_dict = dict()\n",
    "\n",
    "    # 以下为待调整参数\n",
    "    # booster参数\n",
    "    params_dict['learning_rate'] = 0.1       # 学习率，初始值为 0.1，通常越小越好。\n",
    "    params_dict['n_estimators'] = 60         # 加法模型树的数量，初始值为50。\n",
    "    \n",
    "    # tree参数\n",
    "    params_dict['max_depth'] = 3              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "    params_dict['min_child_weight']= 30       # 最小叶子节点样本权重和，越大模型越保守。\n",
    "    params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "    params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "    params_dict['colsample_bytree'] = 1.0     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "    # regulazation参数 \n",
    "    # Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  \n",
    "\n",
    "    params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "    params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "    # 以下参数通常不需要调整\n",
    "    params_dict['objective'] = 'binary:logistic'\n",
    "    params_dict['tree_method'] = 'hist'       # 构建树的策略,可以是auto, exact, approx, hist\n",
    "    params_dict['eval_metric'] =  'auc'\n",
    "    params_dict['silent'] = 1\n",
    "    params_dict['nthread'] = 2\n",
    "    params_dict['scale_pos_weight'] = 1        #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "    params_dict['seed'] = 0\n",
    "    \n",
    "    # 训练xgboost模型\n",
    "    from tianjikit.runxgboost import RunXgboost\n",
    "    model = RunXgboost(dftrain = dftrain,dftest = dftest, coverage_th=0, ks_th=0,\n",
    "            outliers_th=None, selected_features=None)\n",
    "    bst = model.train(cv=5, model_idx=5,params_dict = params_dict) \n",
    "    model.test(bst,dftest)\n",
    "    dfimportance = model.dfimportance\n",
    "    bst.save_model('bst.model')\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dftrain,dftest = '',coverage_th = 0, ks_th = 0, outliers_th = None,\n",
    "                  selected_features = None):\n",
    "        \n",
    "        # 校验是否有label列\n",
    "        assert 'label' in dftrain.columns, 'illegal input,there should be a  \"label\" column in dftrain!'\n",
    "        \n",
    "        # 校验label列的合法性\n",
    "        assert set(dftrain['label']) == {0,1},'illegal label values,label can only be 0 or 1!'\n",
    "        \n",
    "        self.dftrain = dftrain\n",
    "        self.dftest = dftest\n",
    "        \n",
    "        # 记录预处理参数信息\n",
    "        self.coverage_th = coverage_th\n",
    "        self.ks_th = ks_th\n",
    "        self.outliers_th = outliers_th\n",
    "        self.selected_features = selected_features\n",
    "        \n",
    "        X_train,y_train,X_test,y_test = self.preprocess_data(self.dftrain,self.dftest)\n",
    "        \n",
    "       \n",
    "        # 预处理后的训练和验证集\n",
    "        self.X_train,self.y_train = X_train,y_train\n",
    "        self.X_test,self.y_test  = X_test,y_test\n",
    "        \n",
    "        \n",
    "        # 特征重要性\n",
    "        self.dfimportance = None \n",
    "        \n",
    "        # 报告信息\n",
    "        self.report_info = ''\n",
    "        \n",
    "        \n",
    "    def preprocess_data(self,dftrain,dftest):\n",
    "        \n",
    "        # 输出预处理提示信息\n",
    "        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('\\n================================================================================ %s\\n'%nowtime)\n",
    "        print('start data preprocessing ...\\n')\n",
    "        print('train set size:  {}'.format(len(dftrain)))\n",
    "        print('test set size:  {}'.format(len(dftest)))\n",
    "        print('coverage threshold:  {}'.format(self.coverage_th))\n",
    "        print('outlier threshold:  {}'.format(self.outliers_th))\n",
    "        print('ks threshold:  {}'.format(self.ks_th))\n",
    "\n",
    "       \n",
    "        # 去掉['phone','id','idcard','id_card','loan_dt','name','id_map']等非特征列\n",
    "        for  col in {'phone','id','unique_id','uniq_id','idcard','id-card','id_card','name','loan_dt','idmap','id_map','id-map'}:\n",
    "            if col in dftrain.columns:\n",
    "                dftrain = dftrain.drop(col,axis = 1)\n",
    "                if len(dftest):dftest = dftest.drop(col,axis = 1)\n",
    "                    \n",
    "        # 校验是否存在非数值列 \n",
    "        try:\n",
    "            assert not np.dtype('O') in dftrain.dtypes.values\n",
    "        except:\n",
    "            object_cols = dftrain.columns[dftrain.dtypes == np.object].tolist()\n",
    "            print('removed feature columns not numerical: %s'%(','.join(map(str,object_cols))),file = sys.stderr)\n",
    "            dftrain = dftrain.drop(object_cols,axis = 1)\n",
    "            if len(dftest):dftest = dftest.drop(object_cols,axis = 1)\n",
    "        \n",
    "        # 如果selected_features 不为空，则进行特征筛选\n",
    "        if self.selected_features:\n",
    "            remained_cols = [col for col in dftrain.columns if col in self.selected_features + ['label']]\n",
    "            dftrain = dftrain[remained_cols]\n",
    "            if len(dftest):dftest = dftest[remained_cols]\n",
    "                    \n",
    "        # 分割feature和label\n",
    "        X_train = dftrain.drop(['label'],axis = 1)\n",
    "        y_train = dftrain[['label']]\n",
    "        X_test = dftest.drop(['label'],axis = 1) if len(dftest) else ''\n",
    "        y_test = dftest[['label']] if len(dftest) else ''\n",
    "        \n",
    "        print('original feature number:  {}'.format(X_train.shape[1]))\n",
    "        \n",
    "        # drop_outliers()\n",
    "        if self.outliers_th:\n",
    "            for col in X_train.columns:\n",
    "                X_train[col] = outliers.drop_outliers(X_train[col].values, X_train[col].values, alpha = self.outliers_th) \n",
    "                if len(dftest): X_test[col] = outliers.drop_outliers(X_train[col].values,X_test[col].values, alpha = self.outliers_th)  \n",
    "                    \n",
    "        # drop_feature()\n",
    "        X_train, X_test = dropfeature.drop_feature(X_train,y_train,X_test,coverage_threshold = self.coverage_th, \n",
    "                          ks_threshold = self.ks_th) \n",
    "        \n",
    "        print('feature number remain after dropfeature:  {}'.format(X_train.shape[1]))\n",
    "        \n",
    "        # 重置index  \n",
    "        X_train.index = range(len(X_train))\n",
    "        y_train.index = range(len(X_train))\n",
    "        X_test.index = range(len(X_test)) \n",
    "        y_test.index = range(len(X_test))\n",
    "        \n",
    "        return(X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    \n",
    "    def train(self,cv = 5,model_idx = 5,\n",
    "              params_dict = {'n_estimators': 50,'objective':'binary:logistic','eval_metric':'auc','silent':1},\n",
    "              verbose_eval = 20):\n",
    "        \n",
    "        info = \"start train xgboost model ...\"\n",
    "        print(info)\n",
    "        self.report_info = self.report_info + info + '\\n'\n",
    "        \n",
    "        dtrain = xgb.DMatrix(self.X_train, self.y_train['label'])\n",
    "        \n",
    "        if cv:\n",
    "            \n",
    "            k,ks_mean_train,auc_mean_train,ks_mean_validate,auc_mean_validate = 0,0,0,0,0\n",
    "\n",
    "            models = {}\n",
    "\n",
    "            for train_index,validate_index in stratified_kfold(self.X_train,np.ravel(self.y_train),nfolds = cv):\n",
    "\n",
    "                k = k + 1\n",
    "                nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                info = '\\n{}: k = {}'.format(nowtime,k)\n",
    "                print(info)\n",
    "                self.report_info = self.report_info + info + '\\n'\n",
    "                \n",
    "                dtrain_k,dvalid_k = dtrain.slice(train_index),dtrain.slice(validate_index)\n",
    "                bst,_ = train_xgb(params_dict,dtrain_k,dvalid_k,None,verbose_eval)\n",
    "                predict_train_k = bst.predict(dtrain_k)\n",
    "                predict_validate_k = bst.predict(dvalid_k)\n",
    "\n",
    "                dfks_train = ks.ks_analysis(predict_train_k,dtrain_k.get_label())\n",
    "                dfks_validate = ks.ks_analysis(predict_validate_k,dvalid_k.get_label())\n",
    "\n",
    "                ks_train,ks_validate = max(dfks_train['ks_value']),max(dfks_validate['ks_value'])\n",
    "                \n",
    "                auc_train = auc(dtrain_k.get_label(),predict_train_k)\n",
    "                auc_validate = auc(dvalid_k.get_label(), predict_validate_k)\n",
    "        \n",
    "                ks_mean_train = ks_mean_train + ks_train\n",
    "                auc_mean_train = auc_mean_train + auc_train\n",
    "                ks_mean_validate = ks_mean_validate + ks_validate\n",
    "                auc_mean_validate = auc_mean_validate + auc_validate\n",
    "\n",
    "                info = '\\ntrain: ks = {} \\t auc = {} '.format(ks_train,auc_train)\n",
    "                prettyks = ks.print_ks(predict_train_k,dtrain_k.get_label())\n",
    "                info = info + '\\n' + str(prettyks) + '\\n'\n",
    "                info = info + '\\nvalidate: ks = {} \\t auc = {}'.format(ks_validate,auc_validate) + '\\n'\n",
    "                prettyks = ks.print_ks(predict_validate_k,dvalid_k.get_label())\n",
    "                info = info + str(prettyks) + '\\n'\n",
    "                print(info)\n",
    "                self.report_info = self.report_info + info\n",
    "                \n",
    "                models[k] = bst\n",
    "\n",
    "            ks_mean_train = ks_mean_train/float(k)\n",
    "            auc_mean_train = auc_mean_train/float(k)\n",
    "            ks_mean_validate = ks_mean_validate/float(k)\n",
    "            auc_mean_validate = auc_mean_validate/float(k)\n",
    "            \n",
    "            nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            info = '\\n================================================================================ %s\\n'%nowtime\n",
    "            info = info + 'train : ks mean {:.5f} ; auc mean {:.5f}'.format(ks_mean_train, auc_mean_train) + '\\n'\n",
    "            info = info + 'validate : ks mean {:.5f} ; auc mean {:.5f}'.format(ks_mean_validate, auc_mean_validate) + '\\n'\n",
    "            print(info)\n",
    "            self.report_info = self.report_info + info\n",
    "\n",
    "            bst = models[model_idx]\n",
    "            \n",
    "        # 处理 cv = 0 或 cv = None时无需交叉验证逻辑\n",
    "        else:\n",
    "            \n",
    "            nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            info = '\\n================================================================================ %s\\n'%nowtime\n",
    "            print(info)\n",
    "            self.report_info = self.report_info + info\n",
    "            \n",
    "            bst,_ = train_xgb(params_dict,dtrain,None,None,verbose_eval)\n",
    "            predict_train = bst.predict(dtrain)\n",
    "            dfks_train = ks.ks_analysis(predict_train,self.y_train.values)\n",
    "            ks_train = max(dfks_train['ks_value'])   \n",
    "            auc_train = auc(dtrain.get_label(),predict_train)\n",
    "            \n",
    "            info = '\\ntrain: ks = {} \\t auc = {} '.format(ks_train,auc_train) + '\\n'\n",
    "            prettyks = ks.print_ks(predict_train,self.y_train.values)\n",
    "            info = info + str(prettyks) + '\\n'\n",
    "            print(info)\n",
    "            self.report_info = self.report_info + info\n",
    "            \n",
    "        # 计算特征重要性\n",
    "        feature_scores = bst.get_score()\n",
    "        dfimportance = pd.DataFrame({'feature':feature_scores.keys(),'importance':feature_scores.values()})\n",
    "        try:\n",
    "            dfimportance = dfimportance.sort_values('importance',ascending=False)\n",
    "        except AttributeError as err:\n",
    "            dfimportance = dfimportance.sort('importance',ascending = False)\n",
    "\n",
    "        dfimportance.index = range(len(dfimportance))\n",
    "        \n",
    "        self.dfimportance = dfimportance\n",
    "        \n",
    "        return(bst)\n",
    "        \n",
    "    def test(self,bst,dftest = pd.DataFrame()):\n",
    "        \n",
    "        info = \"\\nstart test xgboost model ... \"\n",
    "        print(info)\n",
    "        self.report_info = self.report_info + info + '\\n'\n",
    "        \n",
    "        # 若传入新的dftest，则需要再次做数据预处理\n",
    "        if len(dftest)>0:\n",
    "            \n",
    "            print('preprocessing test data...\\n')\n",
    "            \n",
    "            # 禁止数据预处理期间打印输出\n",
    "            stdout = sys.stdout\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "            \n",
    "            X_train,y_train,X_test,y_test = self.preprocess_data(self.dftrain,dftest)\n",
    "            \n",
    "            # 恢复打印输出\n",
    "            sys.stdout = stdout\n",
    "            \n",
    "            # 预处理后的训练和测试集\n",
    "            self.X_train,self.y_train = X_train,y_train\n",
    "            self.X_test,self.y_test  = X_test,y_test\n",
    "            \n",
    "        dtest = xgb.DMatrix(self.X_test, self.y_test['label'])\n",
    "        y_test_hat = bst.predict(dtest)\n",
    "        dfks_test = ks.ks_analysis(y_test_hat,np.ravel(self.y_test))\n",
    "        ks_test = max(dfks_test['ks_value'])\n",
    "        auc_test = auc(np.ravel(self.y_test),y_test_hat)\n",
    "        \n",
    "        info = 'test: ks = {} \\t auc = {} '.format(ks_test,auc_test) + '\\n'\n",
    "        prettyks = ks.print_ks(y_test_hat,np.ravel(self.y_test))\n",
    "        info = info + str(prettyks) + '\\n'\n",
    "        print(info)\n",
    "        self.report_info = self.report_info + info + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:52:51.449000Z",
     "start_time": "2018-12-19T09:52:50.280000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=20,n_classes=2, random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = ['feature'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)\n",
    "dftrain,dftest = dftrain.copy(),dftest.copy()\n",
    "dftrain.index,dftest.index  = range(len(dftrain)),range(len(dftest))\n",
    "dftrain.loc[0,['feature0','feature1','feature2']] = np.nan #构造若干缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:52:56.016000Z",
     "start_time": "2018-12-19T09:52:55.986000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 配置xgboost模型参数\n",
    "params_dict = dict()\n",
    "\n",
    "# 以下为待调整参数\n",
    "# booster参数\n",
    "params_dict['learning_rate'] = 0.1       # 学习率，初始值为 0.1，通常越小越好。\n",
    "params_dict['n_estimators'] = 60         # 加法模型树的数量，初始值为50。\n",
    "\n",
    "# tree参数\n",
    "params_dict['max_depth'] = 3              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "params_dict['min_child_weight']= 30       # 最小叶子节点样本权重和，越大模型越保守。\n",
    "params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "params_dict['colsample_bytree'] = 1.0     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "# regulazation参数 \n",
    "# Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  \n",
    "\n",
    "params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "# 以下参数通常不需要调整\n",
    "params_dict['objective'] = 'binary:logistic'\n",
    "params_dict['tree_method'] = 'hist'       # 构建树的策略,可以是auto, exact, approx, hist\n",
    "params_dict['eval_metric'] =  'auc'\n",
    "params_dict['silent'] = 1\n",
    "params_dict['nthread'] = 2\n",
    "params_dict['scale_pos_weight'] = 1        #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "params_dict['seed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:58:36.356000Z",
     "start_time": "2018-12-19T08:58:29.175000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练xgboost模型\n",
    "\n",
    "model = RunXgboost(dftrain = dftrain,dftest = dftest, coverage_th=0, ks_th=0,\n",
    "        outliers_th=None, selected_features=None)\n",
    "bst = model.train(cv=5, model_idx=5) \n",
    "model.test(bst,dftest)\n",
    "dfimportance = model.dfimportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T10:50:43.784000Z",
     "start_time": "2018-12-19T10:50:43.765000Z"
    }
   },
   "outputs": [],
   "source": [
    "from tianjikit.runxgboost import RunXgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T10:50:48.020000Z",
     "start_time": "2018-12-19T10:50:47.968000Z"
    }
   },
   "outputs": [],
   "source": [
    "?RunXgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:14:59.579000Z",
     "start_time": "2018-12-19T09:14:59.569000Z"
    }
   },
   "outputs": [],
   "source": [
    "bst.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:09:40.354000Z",
     "start_time": "2018-12-19T09:09:40.202000Z"
    }
   },
   "outputs": [],
   "source": [
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:10:34.604000Z",
     "start_time": "2018-12-19T09:10:34.468000Z"
    }
   },
   "outputs": [],
   "source": [
    "model.X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:10:24.852000Z",
     "start_time": "2018-12-19T09:10:24.677000Z"
    }
   },
   "outputs": [],
   "source": [
    "model.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T10:51:48.119000Z",
     "start_time": "2018-12-19T10:51:42.273000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================ 2018-12-19 18:51:42\n",
      "\n",
      "start data preprocessing ...\n",
      "\n",
      "train set size:  7500\n",
      "test set size:  2500\n",
      "coverage threshold:  0\n",
      "outlier threshold:  None\n",
      "ks threshold:  0\n",
      "original feature number:  30\n",
      "feature number remain after dropfeature:  30\n",
      "start train xgboost model ...\n",
      "\n",
      "2018-12-19 18:51:42: k = 1\n",
      "[18:51:42] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.916843\tvalid-auc:0.915064\ttrain-ks:0.702783\tvalid-ks:0.70355\n",
      "[10]\ttrain-auc:0.959983\tvalid-auc:0.954811\ttrain-ks:0.778878\tvalid-ks:0.760004\n",
      "[20]\ttrain-auc:0.968062\tvalid-auc:0.962927\ttrain-ks:0.826546\tvalid-ks:0.809272\n",
      "[30]\ttrain-auc:0.969705\tvalid-auc:0.964499\ttrain-ks:0.831205\tvalid-ks:0.815951\n",
      "[40]\ttrain-auc:0.970408\tvalid-auc:0.965181\ttrain-ks:0.832513\tvalid-ks:0.819983\n",
      "[50]\ttrain-auc:0.971305\tvalid-auc:0.965386\ttrain-ks:0.835078\tvalid-ks:0.818625\n",
      "[59]\ttrain-auc:0.972556\tvalid-auc:0.966113\ttrain-ks:0.837858\tvalid-ks:0.821299\n",
      "\n",
      "train: ks = 0.83069 \t auc = 0.972555834352 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01043,0.01457) |    599    |     0.1     |      3      |    0.00501    | 0.19727  |\n",
      "| 1 | [0.01457,0.02054) |    601    |     0.1     |      3      |    0.00499    | 0.39521  |\n",
      "| 2 |  [0.02054,0.0276) |    600    |     0.1     |      5      |    0.00833    | 0.59147  |\n",
      "| 3 |  [0.0276,0.14338) |    600    |     0.1     |      20     |    0.03333    | 0.77774  |\n",
      "| 4 | [0.14338,0.59921) |    600    |     0.1     |     220     |    0.36667    | 0.83069  |\n",
      "| 5 | [0.59921,0.81577) |    600    |     0.1     |     441     |     0.735     | 0.73635  |\n",
      "| 6 | [0.81577,0.93783) |    600    |     0.1     |     544     |    0.90667    | 0.57334  |\n",
      "| 7 | [0.93783,0.96304) |    600    |     0.1     |     575     |    0.95833    | 0.38967  |\n",
      "| 8 | [0.96304,0.97145) |    600    |     0.1     |     586     |    0.97667    | 0.19867  |\n",
      "| 9 | [0.97145,0.98441] |    601    |     0.1     |     598     |    0.99501    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.81321 \t auc = 0.96611291896\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.01105,0.0147) |    150    |     0.1     |      0      |      0.0      | 0.19973  |\n",
      "| 1 |  [0.0147,0.0206)  |    150    |     0.1     |      0      |      0.0      | 0.39947  |\n",
      "| 2 |  [0.0206,0.02849) |    150    |     0.1     |      1      |    0.00667    | 0.59653  |\n",
      "| 3 | [0.02849,0.12895) |    150    |     0.1     |      8      |    0.05333    | 0.77492  |\n",
      "| 4 | [0.12895,0.55609) |    149    |     0.1     |      60     |    0.40268    | 0.81321  |\n",
      "| 5 |  [0.55609,0.8023) |    150    |     0.1     |     107     |    0.71333    | 0.72743  |\n",
      "| 6 |  [0.8023,0.93558) |    150    |     0.1     |     141     |      0.94     |  0.5509  |\n",
      "| 7 | [0.93558,0.96377) |    150    |     0.1     |     143     |    0.95333    | 0.36905  |\n",
      "| 8 | [0.96377,0.97194) |    150    |     0.1     |     140     |    0.93333    |  0.1952  |\n",
      "| 9 | [0.97194,0.98429] |    150    |     0.1     |     148     |    0.98667    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 18:51:43: k = 2\n",
      "[18:51:43] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.915606\tvalid-auc:0.917297\ttrain-ks:0.699067\tvalid-ks:0.705111\n",
      "[10]\ttrain-auc:0.96334\tvalid-auc:0.958028\ttrain-ks:0.799724\tvalid-ks:0.789322\n",
      "[20]\ttrain-auc:0.967899\tvalid-auc:0.961621\ttrain-ks:0.819579\tvalid-ks:0.81083\n",
      "[30]\ttrain-auc:0.969049\tvalid-auc:0.964256\ttrain-ks:0.830162\tvalid-ks:0.822778\n",
      "[40]\ttrain-auc:0.970056\tvalid-auc:0.965736\ttrain-ks:0.833148\tvalid-ks:0.826787\n",
      "[50]\ttrain-auc:0.971584\tvalid-auc:0.965727\ttrain-ks:0.837149\tvalid-ks:0.829443\n",
      "[59]\ttrain-auc:0.972462\tvalid-auc:0.966533\ttrain-ks:0.839164\tvalid-ks:0.832099\n",
      "\n",
      "train: ks = 0.82401 \t auc = 0.972462445405 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00867,0.01233) |    600    |     0.1     |      2      |    0.00333    | 0.19827  |\n",
      "| 1 |  [0.01233,0.0183) |    600    |     0.1     |      1      |    0.00167    |  0.3972  |\n",
      "| 2 |  [0.0183,0.02329) |    600    |     0.1     |      3      |     0.005     | 0.59481  |\n",
      "| 3 | [0.02329,0.12323) |    600    |     0.1     |      17     |    0.02833    | 0.78307  |\n",
      "| 4 | [0.12323,0.60994) |    600    |     0.1     |     238     |    0.39667    | 0.82401  |\n",
      "| 5 | [0.60994,0.82643) |    600    |     0.1     |     431     |    0.71833    | 0.73627  |\n",
      "| 6 | [0.82643,0.93645) |    600    |     0.1     |     551     |    0.91833    | 0.56854  |\n",
      "| 7 | [0.93645,0.95727) |    600    |     0.1     |     566     |    0.94333    |  0.3908  |\n",
      "| 8 | [0.95727,0.97041) |    600    |     0.1     |     588     |      0.98     |  0.1984  |\n",
      "| 9 | [0.97041,0.98365] |    600    |     0.1     |     597     |     0.995     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.82534 \t auc = 0.966533273837\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.00879,0.0126) |    150    |     0.1     |      2      |    0.01333    |  0.1944  |\n",
      "| 1 |  [0.0126,0.01855) |    150    |     0.1     |      1      |    0.00667    | 0.39146  |\n",
      "| 2 | [0.01855,0.02386) |    150    |     0.1     |      5      |    0.03333    | 0.57787  |\n",
      "| 3 | [0.02386,0.12538) |    150    |     0.1     |      5      |    0.03333    | 0.76426  |\n",
      "| 4 | [0.12538,0.61977) |    150    |     0.1     |      52     |    0.34667    | 0.82534  |\n",
      "| 5 | [0.61977,0.81682) |    150    |     0.1     |     110     |    0.73333    | 0.73174  |\n",
      "| 6 | [0.81682,0.93394) |    150    |     0.1     |     137     |    0.91333    | 0.56613  |\n",
      "| 7 | [0.93394,0.95704) |    150    |     0.1     |     144     |      0.96     | 0.38187  |\n",
      "| 8 | [0.95704,0.97142) |    150    |     0.1     |     144     |      0.96     |  0.1976  |\n",
      "| 9 | [0.97142,0.98412] |    150    |     0.1     |     149     |    0.99333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 18:51:44: k = 3\n",
      "[18:51:44] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.917693\tvalid-auc:0.918066\ttrain-ks:0.709434\tvalid-ks:0.696908\n",
      "[10]\ttrain-auc:0.961224\tvalid-auc:0.961008\ttrain-ks:0.779968\tvalid-ks:0.790839\n",
      "[20]\ttrain-auc:0.967746\tvalid-auc:0.965087\ttrain-ks:0.81717\tvalid-ks:0.82028\n",
      "[30]\ttrain-auc:0.969432\tvalid-auc:0.966569\ttrain-ks:0.827773\tvalid-ks:0.825606\n",
      "[40]\ttrain-auc:0.970205\tvalid-auc:0.967058\ttrain-ks:0.829475\tvalid-ks:0.828287\n",
      "[50]\ttrain-auc:0.971287\tvalid-auc:0.967003\ttrain-ks:0.834467\tvalid-ks:0.828173\n",
      "[59]\ttrain-auc:0.972408\tvalid-auc:0.96673\ttrain-ks:0.839472\tvalid-ks:0.82956\n",
      "\n",
      "train: ks = 0.83233 \t auc = 0.972407923355 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00983,0.01418) |    600    |     0.1     |      1      |    0.00167    |  0.199   |\n",
      "| 1 | [0.01418,0.02009) |    600    |     0.1     |      2      |    0.00333    | 0.39734  |\n",
      "| 2 | [0.02009,0.02749) |    600    |     0.1     |      5      |    0.00833    | 0.59367  |\n",
      "| 3 | [0.02749,0.15708) |    600    |     0.1     |      22     |    0.03667    | 0.77867  |\n",
      "| 4 | [0.15708,0.59356) |    600    |     0.1     |     219     |     0.365     | 0.83233  |\n",
      "| 5 | [0.59356,0.81399) |    600    |     0.1     |     442     |    0.73667    | 0.73733  |\n",
      "| 6 | [0.81399,0.93919) |    600    |     0.1     |     551     |    0.91833    | 0.56967  |\n",
      "| 7 | [0.93919,0.95737) |    600    |     0.1     |     571     |    0.95167    | 0.38867  |\n",
      "| 8 |  [0.95737,0.9663) |    600    |     0.1     |     586     |    0.97667    | 0.19767  |\n",
      "| 9 |  [0.9663,0.98594] |    600    |     0.1     |     596     |    0.99333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.81068 \t auc = 0.966730430083\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01061,0.01368) |    150    |     0.1     |      2      |    0.01333    | 0.19414  |\n",
      "| 1 |  [0.01368,0.0199) |    150    |     0.1     |      0      |      0.0      | 0.39361  |\n",
      "| 2 |  [0.0199,0.02569) |    150    |     0.1     |      1      |    0.00667    |  0.5904  |\n",
      "| 3 | [0.02569,0.13696) |    150    |     0.1     |      3      |      0.02     | 0.78187  |\n",
      "| 4 | [0.13696,0.57915) |    150    |     0.1     |      64     |    0.42667    | 0.81068  |\n",
      "| 5 | [0.57915,0.79586) |    150    |     0.1     |     106     |    0.70667    | 0.72748  |\n",
      "| 6 | [0.79586,0.93714) |    150    |     0.1     |     137     |    0.91333    |  0.5616  |\n",
      "| 7 | [0.93714,0.95733) |    150    |     0.1     |     144     |      0.96     | 0.37707  |\n",
      "| 8 | [0.95733,0.96703) |    150    |     0.1     |     142     |    0.94667    | 0.19787  |\n",
      "| 9 | [0.96703,0.98469] |    150    |     0.1     |     149     |    0.99333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 18:51:45: k = 4\n",
      "[18:51:45] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.919725\tvalid-auc:0.904624\ttrain-ks:0.707024\tvalid-ks:0.685198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-auc:0.961832\tvalid-auc:0.946595\ttrain-ks:0.784698\tvalid-ks:0.757251\n",
      "[20]\ttrain-auc:0.969801\tvalid-auc:0.954413\ttrain-ks:0.831457\tvalid-ks:0.796126\n",
      "[30]\ttrain-auc:0.971547\tvalid-auc:0.957051\ttrain-ks:0.837788\tvalid-ks:0.801452\n",
      "[40]\ttrain-auc:0.972386\tvalid-auc:0.958281\ttrain-ks:0.838725\tvalid-ks:0.80011\n",
      "[50]\ttrain-auc:0.973821\tvalid-auc:0.958459\ttrain-ks:0.844143\tvalid-ks:0.801424\n",
      "[59]\ttrain-auc:0.974831\tvalid-auc:0.95811\ttrain-ks:0.847474\tvalid-ks:0.802784\n",
      "\n",
      "train: ks = 0.84267 \t auc = 0.9748306771 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.0097,0.01431) |    600    |     0.1     |      3      |     0.005     |  0.1976  |\n",
      "| 1 | [0.01431,0.01895) |    600    |     0.1     |      1      |    0.00167    | 0.39653  |\n",
      "| 2 | [0.01895,0.02346) |    600    |     0.1     |      5      |    0.00833    |  0.5928  |\n",
      "| 3 |  [0.02346,0.1405) |    600    |     0.1     |      17     |    0.02833    | 0.78107  |\n",
      "| 4 |  [0.1405,0.60614) |    600    |     0.1     |     207     |     0.345     | 0.84267  |\n",
      "| 5 |  [0.60614,0.8328) |    600    |     0.1     |     454     |    0.75667    |  0.7396  |\n",
      "| 6 |  [0.8328,0.94186) |    600    |     0.1     |     552     |      0.92     |  0.5712  |\n",
      "| 7 | [0.94186,0.95593) |    600    |     0.1     |     572     |    0.95333    | 0.38946  |\n",
      "| 8 | [0.95593,0.96634) |    599    |     0.1     |     583     |    0.97329    | 0.20007  |\n",
      "| 9 | [0.96634,0.98727] |    601    |     0.1     |     600     |    0.99834    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.78 \t auc = 0.958110147751\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01073,0.01479) |    150    |     0.1     |      1      |    0.00667    | 0.19706  |\n",
      "| 1 | [0.01479,0.01954) |    150    |     0.1     |      1      |    0.00667    | 0.39413  |\n",
      "| 2 | [0.01954,0.03046) |    150    |     0.1     |      3      |      0.02     | 0.58586  |\n",
      "| 3 | [0.03046,0.22691) |    150    |     0.1     |      8      |    0.05333    | 0.76426  |\n",
      "| 4 | [0.22691,0.65177) |    150    |     0.1     |      69     |      0.46     |   0.78   |\n",
      "| 5 | [0.65177,0.87289) |    150    |     0.1     |     104     |    0.69333    |  0.7024  |\n",
      "| 6 | [0.87289,0.94402) |    150    |     0.1     |     130     |    0.86667    | 0.55546  |\n",
      "| 7 | [0.94402,0.95565) |    150    |     0.1     |     142     |    0.94667    | 0.37654  |\n",
      "| 8 | [0.95565,0.96487) |    150    |     0.1     |     143     |    0.95333    | 0.19494  |\n",
      "| 9 | [0.96487,0.98734] |    150    |     0.1     |     148     |    0.98667    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 18:51:46: k = 5\n",
      "[18:51:46] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.914358\tvalid-auc:0.920648\ttrain-ks:0.702051\tvalid-ks:0.714573\n",
      "[10]\ttrain-auc:0.958729\tvalid-auc:0.964263\ttrain-ks:0.780849\tvalid-ks:0.816441\n",
      "[20]\ttrain-auc:0.966083\tvalid-auc:0.972873\ttrain-ks:0.819071\tvalid-ks:0.852191\n",
      "[30]\ttrain-auc:0.968011\tvalid-auc:0.975144\ttrain-ks:0.823098\tvalid-ks:0.852181\n",
      "[40]\ttrain-auc:0.968477\tvalid-auc:0.975002\ttrain-ks:0.825133\tvalid-ks:0.857537\n",
      "[50]\ttrain-auc:0.969926\tvalid-auc:0.975653\ttrain-ks:0.827468\tvalid-ks:0.865516\n",
      "[59]\ttrain-auc:0.970983\tvalid-auc:0.976389\ttrain-ks:0.830433\tvalid-ks:0.868127\n",
      "\n",
      "train: ks = 0.8253 \t auc = 0.970982786427 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01086,0.01518) |    600    |     0.1     |      3      |     0.005     | 0.19767  |\n",
      "| 1 | [0.01518,0.01986) |    600    |     0.1     |      2      |    0.00333    |  0.396   |\n",
      "| 2 | [0.01986,0.02474) |    600    |     0.1     |      6      |      0.01     | 0.59167  |\n",
      "| 3 | [0.02474,0.17802) |    600    |     0.1     |      21     |     0.035     | 0.77733  |\n",
      "| 4 | [0.17802,0.60138) |    599    |     0.1     |     227     |    0.37896    |  0.8253  |\n",
      "| 5 | [0.60138,0.80327) |    600    |     0.1     |     439     |    0.73167    | 0.73226  |\n",
      "| 6 | [0.80327,0.93379) |    600    |     0.1     |     548     |    0.91333    | 0.56653  |\n",
      "| 7 | [0.93379,0.95553) |    600    |     0.1     |     565     |    0.94167    | 0.38946  |\n",
      "| 8 | [0.95553,0.96735) |    600    |     0.1     |     587     |    0.97833    | 0.19773  |\n",
      "| 9 | [0.96735,0.98585] |    600    |     0.1     |     596     |    0.99333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.86409 \t auc = 0.976388731074\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.0118,0.01478) |    150    |     0.1     |      0      |      0.0      | 0.19947  |\n",
      "| 1 | [0.01478,0.01904) |    150    |     0.1     |      0      |      0.0      | 0.39894  |\n",
      "| 2 | [0.01904,0.02395) |    150    |     0.1     |      2      |    0.01333    | 0.59307  |\n",
      "| 3 | [0.02395,0.15407) |    150    |     0.1     |      2      |    0.01333    | 0.78721  |\n",
      "| 4 | [0.15407,0.59937) |    150    |     0.1     |      46     |    0.30667    | 0.86409  |\n",
      "| 5 | [0.59937,0.80233) |    150    |     0.1     |     119     |    0.79333    | 0.74644  |\n",
      "| 6 | [0.80233,0.93405) |    150    |     0.1     |     141     |      0.94     | 0.57015  |\n",
      "| 7 | [0.93405,0.95656) |    150    |     0.1     |     144     |      0.96     | 0.38588  |\n",
      "| 8 | [0.95656,0.96755) |    150    |     0.1     |     145     |    0.96667    | 0.19894  |\n",
      "| 9 | [0.96755,0.98682] |    151    |     0.1     |     150     |    0.99338    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "================================================================================ 2018-12-19 18:51:47\n",
      "train : ks mean 0.83100 ; auc mean 0.97265\n",
      "validate : ks mean 0.81866 ; auc mean 0.96678\n",
      "\n",
      "\n",
      "start test xgboost model ... \n",
      "preprocessing test data...\n",
      "\n",
      "test: ks = 0.79705 \t auc = 0.964222517567 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01028,0.01435) |    250    |     0.1     |      2      |     0.008     | 0.20038  |\n",
      "| 1 | [0.01435,0.02079) |    250    |     0.1     |      0      |      0.0      | 0.40397  |\n",
      "| 2 | [0.02079,0.02911) |    250    |     0.1     |      3      |     0.012     | 0.60275  |\n",
      "| 3 | [0.02911,0.21846) |    250    |     0.1     |      14     |     0.056     | 0.78392  |\n",
      "| 4 | [0.21846,0.60864) |    250    |     0.1     |     119     |     0.476     | 0.79705  |\n",
      "| 5 | [0.60864,0.80275) |    250    |     0.1     |     183     |     0.732     | 0.70774  |\n",
      "| 6 | [0.80275,0.93692) |    250    |     0.1     |     225     |      0.9      | 0.55121  |\n",
      "| 7 |  [0.93692,0.9632) |    250    |     0.1     |     244     |     0.976     | 0.36427  |\n",
      "| 8 |  [0.9632,0.97053) |    250    |     0.1     |     237     |     0.948     | 0.18854  |\n",
      "| 9 | [0.97053,0.98486] |    250    |     0.1     |     245     |      0.98     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 准备训练数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=30,n_classes=2, random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = ['feature'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)\n",
    "dftrain,dftest = dftrain.copy(),dftest.copy()\n",
    "dftrain.index,dftest.index  = range(len(dftrain)),range(len(dftest))\n",
    "dftrain.loc[0,['feature0','feature1','feature2']] = np.nan #构造若干缺失值\n",
    "\n",
    "\n",
    "# 配置xgboost模型参数\n",
    "params_dict = dict()\n",
    "\n",
    "# 以下为待调整参数\n",
    "# booster参数\n",
    "params_dict['learning_rate'] = 0.1       # 学习率，初始值为 0.1，通常越小越好。\n",
    "params_dict['n_estimators'] = 60         # 加法模型树的数量，初始值为50。\n",
    "\n",
    "# tree参数\n",
    "params_dict['max_depth'] = 3              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "params_dict['min_child_weight']= 30       # 最小叶子节点样本权重和，越大模型越保守。\n",
    "params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "params_dict['colsample_bytree'] = 1.0     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "# regulazation参数 \n",
    "# Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  \n",
    "\n",
    "params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "# 以下参数通常不需要调整\n",
    "params_dict['objective'] = 'binary:logistic'\n",
    "params_dict['tree_method'] = 'hist'       # 构建树的策略,可以是auto, exact, approx, hist\n",
    "params_dict['eval_metric'] =  'auc'\n",
    "params_dict['silent'] = 1\n",
    "params_dict['nthread'] = 2\n",
    "params_dict['scale_pos_weight'] = 1        #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "params_dict['seed'] = 0\n",
    "\n",
    "# 训练xgboost模型\n",
    "from tianjikit.runxgboost import RunXgboost\n",
    "model = RunXgboost(dftrain = dftrain,dftest = dftest, coverage_th=0, ks_th=0,\n",
    "        outliers_th=None, selected_features=None)\n",
    "bst = model.train(cv=5, model_idx=1,params_dict = params_dict,verbose_eval = 10) \n",
    "model.test(bst,dftest)\n",
    "dfimportance = model.dfimportance\n",
    "#bst.save_model('bst.model')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:24:49.739000Z",
     "start_time": "2018-12-19T09:24:49.721000Z"
    }
   },
   "outputs": [],
   "source": [
    "bst.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:26:02.985000Z",
     "start_time": "2018-12-19T09:26:02.966000Z"
    }
   },
   "outputs": [],
   "source": [
    "model.dtrain.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T09:37:27.627000Z",
     "start_time": "2018-12-19T09:37:27.613000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "data = pd.DataFrame(np.random.randn(5,3),columns = list('abc'))\n",
    "dtrain = xgb.DMatrix(data)\n",
    "dslice = dtrain.slice([0,1,2])\n",
    "print(dtrain.feature_names)\n",
    "print(dslice.feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
