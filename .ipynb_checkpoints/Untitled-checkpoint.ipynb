{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:48:44.458000Z",
     "start_time": "2018-12-19T08:48:44.393000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=20, n_informative= 6 ,\n",
    "             n_classes=2, n_clusters_per_class=10,random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = [u'f'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(dftrain.drop('label',axis = 1), dftrain['label'])\n",
    "dvalid = xgb.DMatrix(dftest.drop('label',axis = 1), dftest['label'])\n",
    "dtest = xgb.DMatrix(dftest.drop('label',axis = 1), dftest['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:14.138000Z",
     "start_time": "2018-12-19T08:03:14.108000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "params_dict = dict()\n",
    "\n",
    "# 以下为待调整参数\n",
    "# booster参数\n",
    "params_dict['learning_rate'] = 0.1       # 学习率，初始值为 0.1，通常越小越好。\n",
    "params_dict['n_estimators'] = 60         # 加法模型树的数量，初始值为50。\n",
    "\n",
    "# tree参数\n",
    "params_dict['max_depth'] = 3              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "params_dict['min_child_weight']= 30       # 最小叶子节点样本权重和，越大模型越保守。\n",
    "params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "params_dict['colsample_bytree'] = 1.0     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "# regulazation参数 \n",
    "# Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  \n",
    "\n",
    "params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "# 以下参数通常不需要调整\n",
    "params_dict['objective'] = 'binary:logistic'\n",
    "params_dict['tree_method'] = 'hist'       # 构建树的策略,可以是auto, exact, approx, hist\n",
    "params_dict['eval_metric'] =  'auc'\n",
    "params_dict['silent'] = 1\n",
    "params_dict['nthread'] = 2\n",
    "params_dict['scale_pos_weight'] = 1        #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "params_dict['seed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:17.098000Z",
     "start_time": "2018-12-19T08:03:17.076000Z"
    }
   },
   "outputs": [],
   "source": [
    "def auc(labels, preds):\n",
    "    \"\"\"\n",
    "    auc值的大小可以理解为: 随机抽一个正样本和一个负样本，正样本预测值比负样本大的概率\n",
    "    最简单粗暴的方法\n",
    "　　先排序，然后统计有多少正负样本对满足：正样本预测值>负样本预测值, 再除以总的正负样本对个数\n",
    "    复杂度 O(NlogN), N为样本数\n",
    "    \"\"\"\n",
    "    n_pos = sum(labels)\n",
    "    n_neg = len(labels) - n_pos\n",
    "    total_pair = n_pos * n_neg\n",
    " \n",
    "    labels_preds = zip(labels, preds)\n",
    "    labels_preds = sorted(labels_preds, key=lambda x: x[1])\n",
    "    accumulated_neg = 0\n",
    "    satisfied_pair = 0\n",
    "    for i in range(len(labels_preds)):\n",
    "        if labels_preds[i][0] == 1:\n",
    "            satisfied_pair += accumulated_neg\n",
    "        else:\n",
    "            accumulated_neg += 1\n",
    "    return satisfied_pair / float(total_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T04:36:56.374000Z",
     "start_time": "2018-12-19T04:36:56.354000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100L"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.slice(np.arange(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T04:33:39.948000Z",
     "start_time": "2018-12-19T04:33:39.924000Z"
    }
   },
   "outputs": [],
   "source": [
    "bst.save_model('msg.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T04:34:17.488000Z",
     "start_time": "2018-12-19T04:34:17.470000Z"
    }
   },
   "outputs": [],
   "source": [
    "booster = xgb.Booster(model_file='msg.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T03:38:43.547000Z",
     "start_time": "2018-12-19T03:38:43.525000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\u4e2d\\u56fd@_abc.f0': 9.08396149,\n",
       " u'\\u4e2d\\u56fd@_abc.f1': 25.15135812030303,\n",
       " u'\\u4e2d\\u56fd@_abc.f10': 41.938080745781235,\n",
       " u'\\u4e2d\\u56fd@_abc.f11': 6.25136948,\n",
       " u'\\u4e2d\\u56fd@_abc.f12': 2.82127762,\n",
       " u'\\u4e2d\\u56fd@_abc.f13': 17.62893230555555,\n",
       " u'\\u4e2d\\u56fd@_abc.f15': 20.852823002820507,\n",
       " u'\\u4e2d\\u56fd@_abc.f17': 6.437244416666666,\n",
       " u'\\u4e2d\\u56fd@_abc.f18': 6.425109385,\n",
       " u'\\u4e2d\\u56fd@_abc.f19': 62.315462803947376,\n",
       " u'\\u4e2d\\u56fd@_abc.f2': 34.80039481826923,\n",
       " u'\\u4e2d\\u56fd@_abc.f3': 7.6599724275000005,\n",
       " u'\\u4e2d\\u56fd@_abc.f4': 28.268154418571424,\n",
       " u'\\u4e2d\\u56fd@_abc.f6': 6.381576535000001,\n",
       " u'\\u4e2d\\u56fd@_abc.f7': 7.52671242,\n",
       " u'\\u4e2d\\u56fd@_abc.f8': 6.59309673,\n",
       " u'\\u4e2d\\u56fd@_abc.f9': 20.556989746562497}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T06:24:51.299000Z",
     "start_time": "2018-12-19T06:24:51.290000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:22.248000Z",
     "start_time": "2018-12-19T08:03:22.217000Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys,os,json,datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "\n",
    "# 定义ks评分指标,供xgboost.train函数的feval调用\n",
    "def ks_feval(preds,xgbtrain):\n",
    "    label = xgbtrain.get_label()\n",
    "    assert len(preds) == len(label)\n",
    "    df = pd.DataFrame(data = np.array([preds,label]).T,columns = ['preds','label'])\n",
    "    df_0,df_1 = df[df['label']<0.5],df[df['label']>=0.5]\n",
    "    ks,ks_pvalue = stats.ks_2samp(df_0['preds'].values,df_1['preds'].values)\n",
    "    return 'ks',ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:03:26.109000Z",
     "start_time": "2018-12-19T08:03:26.041000Z"
    }
   },
   "outputs": [],
   "source": [
    "def auc(labels, preds):\n",
    "    \"\"\"\n",
    "    auc值的大小可以理解为: 随机抽一个正样本和一个负样本，正样本预测值比负样本大的概率\n",
    "　　先排序，然后统计有多少正负样本对满足：正样本预测值>负样本预测值, 再除以总的正负样本对个数\n",
    "    \"\"\"\n",
    "    n_pos = sum(labels)\n",
    "    n_neg = len(labels) - n_pos\n",
    "    total_pair = n_pos * n_neg\n",
    " \n",
    "    labels_preds = zip(labels, preds)\n",
    "    labels_preds = sorted(labels_preds, key=lambda x: x[1])\n",
    "    accumulated_neg = 0\n",
    "    satisfied_pair = 0\n",
    "    for i in range(len(labels_preds)):\n",
    "        if labels_preds[i][0] == 1:\n",
    "            satisfied_pair += accumulated_neg\n",
    "        else:\n",
    "            accumulated_neg += 1\n",
    "    return satisfied_pair / float(total_pair)\n",
    "    \n",
    "def stratified_kfold(data,label,nfolds = 5):\n",
    "\n",
    "    label = np.array(label)\n",
    "    assert len(data) == len(label), 'the length of data and label not match!'\n",
    "    assert set(label) == {0,1}, 'label can only be 0 or 1!'\n",
    "    \n",
    "    index = np.arange(len(label))\n",
    "    index_0 = index[label<0.5].copy()\n",
    "    index_1 = index[label>0.5].copy()\n",
    "    np.random.shuffle(index_0)\n",
    "    np.random.shuffle(index_1)\n",
    "    \n",
    "    split_points_0 = (len(index_0) * np.arange(1,nfolds))//nfolds\n",
    "    split_points_1 = (len(index_1) * np.arange(1,nfolds))//nfolds\n",
    "    split_index_0_list = np.split(index_0,split_points_0)\n",
    "    split_index_1_list = np.split(index_1,split_points_1)\n",
    "    split_index_list = [np.concatenate((x,y)) for x,y in \n",
    "                     zip(split_index_0_list,split_index_1_list)]\n",
    "    \n",
    "    result = [(np.setdiff1d(index,x),x) for x in split_index_list]\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:26:20.609000Z",
     "start_time": "2018-12-19T08:26:20.578000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练xgb模型\n",
    "def train_xgb(params_dict,dtrain,dvalid = None,dtest = None,verbose_eval = 10):\n",
    "    \n",
    "    result = {}\n",
    "    watchlist = [x for x in [(dtrain, 'train'),(dvalid,'valid'),(dtest,'test')] if x[0] is not None]\n",
    "    datasets = [x[1] for x in watchlist]\n",
    "    \n",
    "    bst = xgb.train(params = params_dict, dtrain = dtrain, \n",
    "                    num_boost_round = params_dict.get('n_estimators',100), \n",
    "                    feval = ks_feval,verbose_eval= verbose_eval,\n",
    "                    evals = watchlist,\n",
    "                    evals_result = result)\n",
    "    dfresult = pd.DataFrame({(dataset+'_'+feval): result[dataset][feval] \n",
    "               for dataset in datasets for feval in ('auc','ks')})\n",
    "    \n",
    "    return bst,dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:30:59.252000Z",
     "start_time": "2018-12-19T08:30:58.741000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:58] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-auc:0.711875\ttrain-ks:0.313049\n",
      "[10]\ttrain-auc:0.772605\ttrain-ks:0.412831\n",
      "[20]\ttrain-auc:0.790242\ttrain-ks:0.430453\n",
      "[30]\ttrain-auc:0.801675\ttrain-ks:0.450484\n",
      "[40]\ttrain-auc:0.810105\ttrain-ks:0.466901\n",
      "[50]\ttrain-auc:0.81822\ttrain-ks:0.478335\n",
      "[59]\ttrain-auc:0.826765\ttrain-ks:0.495413\n"
     ]
    }
   ],
   "source": [
    "bst,_ = train_xgb(params_dict,dtrain,None,None,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:38:30.233000Z",
     "start_time": "2018-12-19T08:38:30.189000Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-845f49fb6b07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfimportance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'importance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgrameFiles\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "dfimportance = dfimportance.sort('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:39:43.714000Z",
     "start_time": "2018-12-19T08:39:43.685000Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_scores = bst.get_score()\n",
    "dfimportance = pd.DataFrame({'feature':feature_scores.keys(),'importance':feature_scores.values()})\n",
    "try:\n",
    "    dfimportance = dfimportance.sort_values('importance',ascending=False)\n",
    "except AttributeError as err:\n",
    "    dfimportance = dfimportance.sort('importance',ascending = False)\n",
    "    \n",
    "dfimportance.index = range(len(dfimportance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:58:21.439000Z",
     "start_time": "2018-12-19T08:58:20.697000Z"
    }
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "#!/usr/bin/python2.7\n",
    "\n",
    "##################################################\n",
    "#update_dt:2018-10-08\n",
    "#author：liangyun\n",
    "#usage: run xgboost model\n",
    "##################################################\n",
    "from __future__ import print_function\n",
    "import datetime,sys,os\n",
    "import ks,outliers,dropfeature\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "class RunXgboost(object):\n",
    "    \"\"\"\n",
    "    Examples\n",
    "    ---------\n",
    "    # 准备训练数据\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data,label = datasets.make_classification(n_samples= 10000, n_features=20,n_classes=2, random_state=0)\n",
    "    dfdata = pd.DataFrame(data,columns = ['feature'+str(i) for i in range(data.shape[1])])\n",
    "    dfdata['label'] = label\n",
    "    dftrain,dftest = train_test_split(dfdata)\n",
    "    dftrain,dftest = dftrain.copy(),dftest.copy()\n",
    "    dftrain.index,dftest.index  = range(len(dftrain)),range(len(dftest))\n",
    "    dftrain.loc[0,['feature0','feature1','feature2']] = np.nan #构造若干缺失值\n",
    "    \n",
    "    \n",
    "    # 配置xgboost模型参数\n",
    "    params_dict = dict()\n",
    "\n",
    "    # 以下为待调整参数\n",
    "    # booster参数\n",
    "    params_dict['learning_rate'] = 0.1       # 学习率，初始值为 0.1，通常越小越好。\n",
    "    params_dict['n_estimators'] = 60         # 加法模型树的数量，初始值为50。\n",
    "    \n",
    "    # tree参数\n",
    "    params_dict['max_depth'] = 3              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "    params_dict['min_child_weight']= 30       # 最小叶子节点样本权重和，越大模型越保守。\n",
    "    params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "    params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "    params_dict['colsample_bytree'] = 1.0     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "    # regulazation参数 \n",
    "    # Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  \n",
    "\n",
    "    params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "    params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "    # 以下参数通常不需要调整\n",
    "    params_dict['objective'] = 'binary:logistic'\n",
    "    params_dict['tree_method'] = 'hist'       # 构建树的策略,可以是auto, exact, approx, hist\n",
    "    params_dict['eval_metric'] =  'auc'\n",
    "    params_dict['silent'] = 1\n",
    "    params_dict['nthread'] = 2\n",
    "    params_dict['scale_pos_weight'] = 1        #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "    params_dict['seed'] = 0\n",
    "    \n",
    "    # 训练xgboost模型\n",
    "    from tianjikit.runxgboost import RunXgboost\n",
    "    model = RunXgboost(dftrain = dftrain,dftest = dftest, coverage_th=0, ks_th=0,\n",
    "            outliers_th=None, selected_features=None)\n",
    "    bst = model.train(cv=5, model_idx=5,params_dict = params_dict) \n",
    "    model.test(bst,dftest)\n",
    "    dfimportance = model.dfimportance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dftrain,dftest = '',coverage_th = 0, ks_th = 0, outliers_th = None,\n",
    "                  selected_features = None):\n",
    "        \n",
    "        # 校验是否有label列\n",
    "        assert 'label' in dftrain.columns, 'illegal input,there should be a  \"label\" column in dftrain!'\n",
    "        \n",
    "        # 校验label列的合法性\n",
    "        assert set(dftrain['label']) == {0,1},'illegal label values,label can only be 0 or 1!'\n",
    "        \n",
    "        self.dftrain = dftrain\n",
    "        self.dftest = dftest\n",
    "        \n",
    "        # 记录预处理参数信息\n",
    "        self.coverage_th = coverage_th\n",
    "        self.ks_th = ks_th\n",
    "        self.outliers_th = outliers_th\n",
    "        self.selected_features = selected_features\n",
    "        \n",
    "        X_train,y_train,X_test,y_test = self.preprocess_data(self.dftrain,self.dftest)\n",
    "        \n",
    "       \n",
    "        # 预处理后的训练和验证集\n",
    "        self.X_train,self.y_train = X_train,y_train\n",
    "        self.X_test,self.y_test  = X_test,y_test\n",
    "        \n",
    "        \n",
    "        # 特征重要性\n",
    "        self.dfimportance = None \n",
    "        \n",
    "        # 报告信息\n",
    "        self.report_info = ''\n",
    "        \n",
    "        \n",
    "    def preprocess_data(self,dftrain,dftest):\n",
    "        \n",
    "        # 输出预处理提示信息\n",
    "        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('\\n================================================================================ %s\\n'%nowtime)\n",
    "        print('start data preprocessing ...\\n')\n",
    "        print('train set size:  {}'.format(len(dftrain)))\n",
    "        print('test set size:  {}'.format(len(dftest)))\n",
    "        print('coverage threshold:  {}'.format(self.coverage_th))\n",
    "        print('outlier threshold:  {}'.format(self.outliers_th))\n",
    "        print('ks threshold:  {}'.format(self.ks_th))\n",
    "\n",
    "       \n",
    "        # 去掉['phone','id','idcard','id_card','loan_dt','name','id_map']等非特征列\n",
    "        for  col in {'phone','id','unique_id','uniq_id','idcard','id-card','id_card','name','loan_dt','idmap','id_map','id-map'}:\n",
    "            if col in dftrain.columns:\n",
    "                dftrain = dftrain.drop(col,axis = 1)\n",
    "                if len(dftest):dftest = dftest.drop(col,axis = 1)\n",
    "                    \n",
    "        # 校验是否存在非数值列 \n",
    "        try:\n",
    "            assert not np.dtype('O') in dftrain.dtypes.values\n",
    "        except:\n",
    "            object_cols = dftrain.columns[dftrain.dtypes == np.object].tolist()\n",
    "            print('removed feature columns not numerical: %s'%(','.join(map(str,object_cols))),file = sys.stderr)\n",
    "            dftrain = dftrain.drop(object_cols,axis = 1)\n",
    "            if len(dftest):dftest = dftest.drop(object_cols,axis = 1)\n",
    "        \n",
    "        # 如果selected_features 不为空，则进行特征筛选\n",
    "        if self.selected_features:\n",
    "            remained_cols = [col for col in dftrain.columns if col in self.selected_features + ['label']]\n",
    "            dftrain = dftrain[remained_cols]\n",
    "            if len(dftest):dftest = dftest[remained_cols]\n",
    "                    \n",
    "        # 分割feature和label\n",
    "        X_train = dftrain.drop(['label'],axis = 1)\n",
    "        y_train = dftrain[['label']]\n",
    "        X_test = dftest.drop(['label'],axis = 1) if len(dftest) else ''\n",
    "        y_test = dftest[['label']] if len(dftest) else ''\n",
    "        \n",
    "        print('original feature number:  {}'.format(X_train.shape[1]))\n",
    "        \n",
    "        # drop_outliers()\n",
    "        if self.outliers_th:\n",
    "            for col in X_train.columns:\n",
    "                X_train[col] = outliers.drop_outliers(X_train[col].values, X_train[col].values, alpha = self.outliers_th) \n",
    "                if len(dftest): X_test[col] = outliers.drop_outliers(X_train[col].values,X_test[col].values, alpha = self.outliers_th)  \n",
    "                    \n",
    "        # drop_feature()\n",
    "        X_train, X_test = dropfeature.drop_feature(X_train,y_train,X_test,coverage_threshold = self.coverage_th, \n",
    "                          ks_threshold = self.ks_th) \n",
    "        \n",
    "        print('feature number remain after dropfeature:  {}'.format(X_train.shape[1]))\n",
    "        \n",
    "        # 重置index  \n",
    "        X_train.index = range(len(X_train))\n",
    "        y_train.index = range(len(X_train))\n",
    "        X_test.index = range(len(X_test)) \n",
    "        y_test.index = range(len(X_test))\n",
    "        \n",
    "        return(X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    \n",
    "    def train(self,cv = 5,model_idx = 5,\n",
    "              params_dict = {'n_estimators': 50,'objective':'binary:logistic','eval_metric':'auc','silent':1},\n",
    "              verbose_eval = 20):\n",
    "        \n",
    "        info = \"start train xgboost model ...\"\n",
    "        print(info)\n",
    "        self.report_info = self.report_info + info + '\\n'\n",
    "        \n",
    "        dtrain = xgb.DMatrix(self.X_train, self.y_train['label'])\n",
    "        \n",
    "        if cv:\n",
    "            \n",
    "            k,ks_mean_train,auc_mean_train,ks_mean_validate,auc_mean_validate = 0,0,0,0,0\n",
    "\n",
    "            models = {}\n",
    "\n",
    "            for train_index,validate_index in stratified_kfold(self.X_train,np.ravel(self.y_train),nfolds = cv):\n",
    "\n",
    "                k = k + 1\n",
    "                nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                info = '\\n{}: k = {}'.format(nowtime,k)\n",
    "                print(info)\n",
    "                self.report_info = self.report_info + info + '\\n'\n",
    "                \n",
    "                dtrain_k,dvalid_k = dtrain.slice(train_index),dtrain.slice(validate_index)\n",
    "                bst,_ = train_xgb(params_dict,dtrain_k,dvalid_k,None,verbose_eval)\n",
    "                predict_train_k = bst.predict(dtrain_k)\n",
    "                predict_validate_k = bst.predict(dvalid_k)\n",
    "\n",
    "                dfks_train = ks.ks_analysis(predict_train_k,dtrain_k.get_label())\n",
    "                dfks_validate = ks.ks_analysis(predict_validate_k,dvalid_k.get_label())\n",
    "\n",
    "                ks_train,ks_validate = max(dfks_train['ks_value']),max(dfks_validate['ks_value'])\n",
    "                \n",
    "                auc_train = auc(dtrain_k.get_label(),predict_train_k)\n",
    "                auc_validate = auc(dvalid_k.get_label(), predict_validate_k)\n",
    "        \n",
    "                ks_mean_train = ks_mean_train + ks_train\n",
    "                auc_mean_train = auc_mean_train + auc_train\n",
    "                ks_mean_validate = ks_mean_validate + ks_validate\n",
    "                auc_mean_validate = auc_mean_validate + auc_validate\n",
    "\n",
    "                info = '\\ntrain: ks = {} \\t auc = {} '.format(ks_train,auc_train)\n",
    "                prettyks = ks.print_ks(predict_train_k,dtrain_k.get_label())\n",
    "                info = info + '\\n' + str(prettyks) + '\\n'\n",
    "                info = info + '\\nvalidate: ks = {} \\t auc = {}'.format(ks_validate,auc_validate) + '\\n'\n",
    "                prettyks = ks.print_ks(predict_validate_k,dvalid_k.get_label())\n",
    "                info = info + str(prettyks) + '\\n'\n",
    "                print(info)\n",
    "                self.report_info = self.report_info + info\n",
    "                \n",
    "                models[k] = bst\n",
    "\n",
    "            ks_mean_train = ks_mean_train/float(k)\n",
    "            auc_mean_train = auc_mean_train/float(k)\n",
    "            ks_mean_validate = ks_mean_validate/float(k)\n",
    "            auc_mean_validate = auc_mean_validate/float(k)\n",
    "            \n",
    "            nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            info = '\\n================================================================================ %s\\n'%nowtime\n",
    "            info = info + 'train : ks mean {:.5f} ; auc mean {:.5f}'.format(ks_mean_train, auc_mean_train) + '\\n'\n",
    "            info = info + 'validate : ks mean {:.5f} ; auc mean {:.5f}'.format(ks_mean_validate, auc_mean_validate) + '\\n'\n",
    "            print(info)\n",
    "            self.report_info = self.report_info + info\n",
    "\n",
    "            bst = models[model_idx]\n",
    "            \n",
    "        # 处理 cv = 0 或 cv = None时无需交叉验证逻辑\n",
    "        else:\n",
    "            \n",
    "            nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            info = '\\n================================================================================ %s\\n'%nowtime\n",
    "            print(info)\n",
    "            self.report_info = self.report_info + info\n",
    "            \n",
    "            bst,_ = train_xgb(params_dict,dtrain,None,None,verbose_eval)\n",
    "            predict_train = bst.predict(dtrain)\n",
    "            dfks_train = ks.ks_analysis(predict_train,self.y_train.values)\n",
    "            ks_train = max(dfks_train['ks_value'])   \n",
    "            auc_train = auc(dtrain.get_label(),predict_train)\n",
    "            \n",
    "            info = '\\ntrain: ks = {} \\t auc = {} '.format(ks_train,auc_train) + '\\n'\n",
    "            prettyks = ks.print_ks(predict_train,self.y_train.values)\n",
    "            info = info + str(prettyks) + '\\n'\n",
    "            print(info)\n",
    "            self.report_info = self.report_info + info\n",
    "            \n",
    "        # 计算特征重要性\n",
    "        feature_scores = bst.get_score()\n",
    "        dfimportance = pd.DataFrame({'feature':feature_scores.keys(),'importance':feature_scores.values()})\n",
    "        try:\n",
    "            dfimportance = dfimportance.sort_values('importance',ascending=False)\n",
    "        except AttributeError as err:\n",
    "            dfimportance = dfimportance.sort('importance',ascending = False)\n",
    "\n",
    "        dfimportance.index = range(len(dfimportance))\n",
    "        \n",
    "        self.dfimportance = dfimportance\n",
    "        \n",
    "        return(bst)\n",
    "        \n",
    "    def test(self,bst,dftest = pd.DataFrame()):\n",
    "        \n",
    "        info = \"\\nstart test xgboost model ... \"\n",
    "        print(info)\n",
    "        self.report_info = self.report_info + info + '\\n'\n",
    "        \n",
    "        # 若传入新的dftest，则需要再次做数据预处理\n",
    "        if len(dftest)>0:\n",
    "            \n",
    "            print('preprocessing test data...\\n')\n",
    "            \n",
    "            # 禁止数据预处理期间打印输出\n",
    "            stdout = sys.stdout\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "            \n",
    "            X_train,y_train,X_test,y_test = self.preprocess_data(self.dftrain,dftest)\n",
    "            \n",
    "            # 恢复打印输出\n",
    "            sys.stdout = stdout\n",
    "            \n",
    "            # 预处理后的训练和测试集\n",
    "            self.X_train,self.y_train = X_train,y_train\n",
    "            self.X_test,self.y_test  = X_test,y_test\n",
    "            \n",
    "        dtest = xgb.DMatrix(self.X_test, self.y_test['label'])\n",
    "        y_test_hat = bst.predict(dtest)\n",
    "        dfks_test = ks.ks_analysis(y_test_hat,np.ravel(self.y_test))\n",
    "        ks_test = max(dfks_test['ks_value'])\n",
    "        auc_test = auc(np.ravel(self.y_test),y_test_hat)\n",
    "        \n",
    "        info = 'test: ks = {} \\t auc = {} '.format(ks_test,auc_test) + '\\n'\n",
    "        prettyks = ks.print_ks(y_test_hat,np.ravel(self.y_test))\n",
    "        info = info + str(prettyks) + '\\n'\n",
    "        print(info)\n",
    "        self.report_info = self.report_info + info + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:43:27.007000Z",
     "start_time": "2018-12-19T08:43:26.918000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=20,n_classes=2, random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = ['feature'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)\n",
    "dftrain,dftest = dftrain.copy(),dftest.copy()\n",
    "dftrain.index,dftest.index  = range(len(dftrain)),range(len(dftest))\n",
    "dftrain.loc[0,['feature0','feature1','feature2']] = np.nan #构造若干缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:49:18.755000Z",
     "start_time": "2018-12-19T08:49:18.722000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 配置xgboost模型参数\n",
    "params_dict = dict()\n",
    "\n",
    "# 以下为待调整参数\n",
    "# booster参数\n",
    "params_dict['learning_rate'] = 0.1       # 学习率，初始值为 0.1，通常越小越好。\n",
    "params_dict['n_estimators'] = 60         # 加法模型树的数量，初始值为50。\n",
    "\n",
    "# tree参数\n",
    "params_dict['max_depth'] = 3              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "params_dict['min_child_weight']= 30       # 最小叶子节点样本权重和，越大模型越保守。\n",
    "params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "params_dict['colsample_bytree'] = 1.0     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "# regulazation参数 \n",
    "# Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  \n",
    "\n",
    "params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "# 以下参数通常不需要调整\n",
    "params_dict['objective'] = 'binary:logistic'\n",
    "params_dict['tree_method'] = 'hist'       # 构建树的策略,可以是auto, exact, approx, hist\n",
    "params_dict['eval_metric'] =  'auc'\n",
    "params_dict['silent'] = 1\n",
    "params_dict['nthread'] = 2\n",
    "params_dict['scale_pos_weight'] = 1        #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "params_dict['seed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T08:58:36.356000Z",
     "start_time": "2018-12-19T08:58:29.175000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================ 2018-12-19 16:58:29\n",
      "\n",
      "start data preprocessing ...\n",
      "\n",
      "train set size:  7500\n",
      "test set size:  2500\n",
      "coverage threshold:  0\n",
      "outlier threshold:  None\n",
      "ks threshold:  0\n",
      "original feature number:  20\n",
      "feature number remain after dropfeature:  20\n",
      "start train xgboost model ...\n",
      "\n",
      "2018-12-19 16:58:29: k = 1\n",
      "[0]\ttrain-auc:0.8343\tvalid-auc:0.770675\ttrain-ks:0.514832\tvalid-ks:0.431357\n",
      "[20]\ttrain-auc:0.960162\tvalid-auc:0.854302\ttrain-ks:0.793492\tvalid-ks:0.574098\n",
      "[40]\ttrain-auc:0.989131\tvalid-auc:0.856022\ttrain-ks:0.897768\tvalid-ks:0.569063\n",
      "[49]\ttrain-auc:0.993604\tvalid-auc:0.857684\ttrain-ks:0.925666\tvalid-ks:0.581156\n",
      "\n",
      "train: ks = 0.92369 \t auc = 0.993604371407 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00289,0.04961) |    600    |     0.1     |      0      |      0.0      | 0.20074  |\n",
      "| 1 | [0.04961,0.10204) |    600    |     0.1     |      0      |      0.0      | 0.40147  |\n",
      "| 2 | [0.10204,0.17815) |    600    |     0.1     |      1      |    0.00167    | 0.60154  |\n",
      "| 3 | [0.17815,0.29102) |    600    |     0.1     |      15     |     0.025     | 0.79228  |\n",
      "| 4 | [0.29102,0.50902) |    600    |     0.1     |     104     |    0.17333    | 0.92369  |\n",
      "| 5 | [0.50902,0.72993) |    600    |     0.1     |     499     |    0.83167    | 0.79181  |\n",
      "| 6 | [0.72993,0.82227) |    600    |     0.1     |     595     |    0.99167    | 0.59595  |\n",
      "| 7 | [0.82227,0.88852) |    600    |     0.1     |     597     |     0.995     | 0.39874  |\n",
      "| 8 | [0.88852,0.94446) |    600    |     0.1     |     600     |      1.0      | 0.19954  |\n",
      "| 9 | [0.94446,0.99788] |    601    |     0.1     |     601     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.57839 \t auc = 0.857684283232\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00235,0.06501) |    150    |     0.1     |      9      |      0.06     | 0.17679  |\n",
      "| 1 | [0.06501,0.15599) |    150    |     0.1     |      12     |      0.08     | 0.34556  |\n",
      "| 2 | [0.15599,0.28878) |    150    |     0.1     |      31     |    0.20667    | 0.46365  |\n",
      "| 3 | [0.28878,0.43147) |    150    |     0.1     |      43     |    0.28667    | 0.54971  |\n",
      "| 4 | [0.43147,0.54389) |    149    |     0.1     |      64     |    0.42953    | 0.57839  |\n",
      "| 5 | [0.54389,0.65633) |    150    |     0.1     |     103     |    0.68667    | 0.50434  |\n",
      "| 6 | [0.65633,0.75548) |    150    |     0.1     |     106     |    0.70667    | 0.42229  |\n",
      "| 7 | [0.75548,0.84025) |    150    |     0.1     |     114     |      0.76     | 0.31888  |\n",
      "| 8 | [0.84025,0.92173) |    150    |     0.1     |     126     |      0.84     | 0.18346  |\n",
      "| 9 | [0.92173,0.99597] |    150    |     0.1     |     144     |      0.96     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 16:58:30: k = 2\n",
      "[0]\ttrain-auc:0.81803\tvalid-auc:0.781488\ttrain-ks:0.489725\tvalid-ks:0.426092\n",
      "[20]\ttrain-auc:0.960182\tvalid-auc:0.861361\ttrain-ks:0.786979\tvalid-ks:0.552324\n",
      "[40]\ttrain-auc:0.990664\tvalid-auc:0.859137\ttrain-ks:0.907999\tvalid-ks:0.558228\n",
      "[49]\ttrain-auc:0.99381\tvalid-auc:0.859048\ttrain-ks:0.925066\tvalid-ks:0.55314\n",
      "\n",
      "train: ks = 0.92368 \t auc = 0.993809916778 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00227,0.04739) |    600    |     0.1     |      0      |      0.0      | 0.20074  |\n",
      "| 1 | [0.04739,0.10673) |    600    |     0.1     |      0      |      0.0      | 0.40147  |\n",
      "| 2 | [0.10673,0.18189) |    600    |     0.1     |      3      |     0.005     |  0.6002  |\n",
      "| 3 |  [0.18189,0.2999) |    600    |     0.1     |      11     |    0.01833    | 0.79361  |\n",
      "| 4 |  [0.2999,0.51142) |    600    |     0.1     |     106     |    0.17667    | 0.92368  |\n",
      "| 5 | [0.51142,0.72153) |    600    |     0.1     |     500     |    0.83333    | 0.79108  |\n",
      "| 6 | [0.72153,0.81896) |    600    |     0.1     |     592     |    0.98667    | 0.59715  |\n",
      "| 7 |  [0.81896,0.8855) |    600    |     0.1     |     599     |    0.99833    | 0.39854  |\n",
      "| 8 |  [0.8855,0.94411) |    600    |     0.1     |     600     |      1.0      | 0.19927  |\n",
      "| 9 | [0.94411,0.99767] |    600    |     0.1     |     600     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.53468 \t auc = 0.859048411441\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.00464,0.0639) |    150    |     0.1     |      5      |    0.03333    | 0.18747  |\n",
      "| 1 |  [0.0639,0.15627) |    150    |     0.1     |      11     |    0.07333    | 0.35894  |\n",
      "| 2 | [0.15627,0.26602) |    150    |     0.1     |      32     |    0.21333    |  0.4744  |\n",
      "| 3 | [0.26602,0.38806) |    150    |     0.1     |      57     |      0.38     | 0.52321  |\n",
      "| 4 | [0.38806,0.50738) |    150    |     0.1     |      71     |    0.47333    | 0.53468  |\n",
      "| 5 | [0.50738,0.61654) |    150    |     0.1     |      83     |    0.55333    | 0.51414  |\n",
      "| 6 | [0.61654,0.74462) |    150    |     0.1     |      96     |      0.64     | 0.45894  |\n",
      "| 7 | [0.74462,0.84434) |    150    |     0.1     |     124     |    0.82667    | 0.32907  |\n",
      "| 8 | [0.84434,0.92108) |    150    |     0.1     |     136     |    0.90667    | 0.16721  |\n",
      "| 9 | [0.92108,0.99847] |    150    |     0.1     |     138     |      0.92     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 16:58:32: k = 3\n",
      "[0]\ttrain-auc:0.833241\tvalid-auc:0.767864\ttrain-ks:0.504391\tvalid-ks:0.395868\n",
      "[20]\ttrain-auc:0.96049\tvalid-auc:0.84145\ttrain-ks:0.790144\tvalid-ks:0.52388\n",
      "[40]\ttrain-auc:0.986861\tvalid-auc:0.845962\ttrain-ks:0.891088\tvalid-ks:0.53115\n",
      "[49]\ttrain-auc:0.99266\tvalid-auc:0.84631\ttrain-ks:0.922119\tvalid-ks:0.530936\n",
      "\n",
      "train: ks = 0.91768 \t auc = 0.992660456879 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00194,0.04997) |    600    |     0.1     |      0      |      0.0      | 0.20074  |\n",
      "| 1 | [0.04997,0.10037) |    600    |     0.1     |      1      |    0.00167    | 0.40081  |\n",
      "| 2 | [0.10037,0.17657) |    600    |     0.1     |      4      |    0.00667    | 0.59888  |\n",
      "| 3 | [0.17657,0.29429) |    600    |     0.1     |      17     |    0.02833    | 0.78827  |\n",
      "| 4 | [0.29429,0.51203) |    600    |     0.1     |     107     |    0.17833    | 0.91768  |\n",
      "| 5 | [0.51203,0.72501) |    600    |     0.1     |     493     |    0.82167    | 0.78974  |\n",
      "| 6 | [0.72501,0.82353) |    600    |     0.1     |     590     |    0.98333    | 0.59715  |\n",
      "| 7 | [0.82353,0.89041) |    600    |     0.1     |     599     |    0.99833    | 0.39854  |\n",
      "| 8 | [0.89041,0.94647) |    600    |     0.1     |     600     |      1.0      | 0.19927  |\n",
      "| 9 | [0.94647,0.99763] |    600    |     0.1     |     600     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.51867 \t auc = 0.846310429856\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00173,0.06761) |    150    |     0.1     |      15     |      0.1      |  0.1608  |\n",
      "| 1 | [0.06761,0.14747) |    150    |     0.1     |      12     |      0.08     |  0.3296  |\n",
      "| 2 | [0.14747,0.25509) |    150    |     0.1     |      31     |    0.20667    | 0.44774  |\n",
      "| 3 | [0.25509,0.36938) |    150    |     0.1     |      55     |    0.36667    | 0.50187  |\n",
      "| 4 | [0.36938,0.49244) |    150    |     0.1     |      69     |      0.46     | 0.51867  |\n",
      "| 5 | [0.49244,0.60984) |    150    |     0.1     |      78     |      0.52     | 0.51147  |\n",
      "| 6 | [0.60984,0.73264) |    150    |     0.1     |     100     |    0.66667    |  0.4456  |\n",
      "| 7 | [0.73264,0.83121) |    150    |     0.1     |     122     |    0.81333    | 0.32107  |\n",
      "| 8 | [0.83121,0.91682) |    150    |     0.1     |     127     |    0.84667    | 0.18321  |\n",
      "| 9 | [0.91682,0.99581] |    150    |     0.1     |     144     |      0.96     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 16:58:33: k = 4\n",
      "[0]\ttrain-auc:0.819499\tvalid-auc:0.762241\ttrain-ks:0.491124\tvalid-ks:0.395078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-auc:0.964397\tvalid-auc:0.830879\ttrain-ks:0.799638\tvalid-ks:0.509549\n",
      "[40]\ttrain-auc:0.986566\tvalid-auc:0.834013\ttrain-ks:0.889762\tvalid-ks:0.51364\n",
      "[49]\ttrain-auc:0.991475\tvalid-auc:0.835932\ttrain-ks:0.913352\tvalid-ks:0.517379\n",
      "\n",
      "train: ks = 0.91235 \t auc = 0.991475329835 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00435,0.05042) |    600    |     0.1     |      0      |      0.0      | 0.20074  |\n",
      "| 1 | [0.05042,0.10271) |    600    |     0.1     |      0      |      0.0      | 0.40147  |\n",
      "| 2 | [0.10271,0.17754) |    600    |     0.1     |      4      |    0.00667    | 0.59954  |\n",
      "| 3 | [0.17754,0.29891) |    600    |     0.1     |      16     |    0.02667    | 0.78961  |\n",
      "| 4 | [0.29891,0.51369) |    600    |     0.1     |     117     |     0.195     | 0.91235  |\n",
      "| 5 | [0.51369,0.72351) |    600    |     0.1     |     488     |    0.81333    | 0.78775  |\n",
      "| 6 | [0.72351,0.81716) |    600    |     0.1     |     587     |    0.97833    | 0.59715  |\n",
      "| 7 | [0.81716,0.88764) |    600    |     0.1     |     599     |    0.99833    | 0.39854  |\n",
      "| 8 | [0.88764,0.94398) |    600    |     0.1     |     600     |      1.0      | 0.19927  |\n",
      "| 9 | [0.94398,0.99855] |    600    |     0.1     |     600     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.51334 \t auc = 0.835931597128\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00665,0.06779) |    150    |     0.1     |      7      |    0.04667    | 0.18213  |\n",
      "| 1 | [0.06779,0.14748) |    150    |     0.1     |      26     |    0.17333    | 0.31361  |\n",
      "| 2 | [0.14748,0.25052) |    150    |     0.1     |      31     |    0.20667    | 0.43174  |\n",
      "| 3 | [0.25052,0.38829) |    150    |     0.1     |      53     |    0.35333    | 0.49121  |\n",
      "| 4 | [0.38829,0.50611) |    150    |     0.1     |      67     |    0.44667    | 0.51334  |\n",
      "| 5 | [0.50611,0.63088) |    150    |     0.1     |      80     |    0.53333    | 0.50081  |\n",
      "| 6 | [0.63088,0.73903) |    150    |     0.1     |     105     |      0.7      | 0.42161  |\n",
      "| 7 | [0.73903,0.83665) |    150    |     0.1     |     119     |    0.79333    | 0.30508  |\n",
      "| 8 | [0.83665,0.91985) |    150    |     0.1     |     119     |    0.79333    | 0.18854  |\n",
      "| 9 | [0.91985,0.99672] |    150    |     0.1     |     146     |    0.97333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "2018-12-19 16:58:34: k = 5\n",
      "[0]\ttrain-auc:0.831829\tvalid-auc:0.752437\ttrain-ks:0.51358\tvalid-ks:0.379629\n",
      "[20]\ttrain-auc:0.964484\tvalid-auc:0.828351\ttrain-ks:0.801949\tvalid-ks:0.513452\n",
      "[40]\ttrain-auc:0.989032\tvalid-auc:0.823036\ttrain-ks:0.895754\tvalid-ks:0.490556\n",
      "[49]\ttrain-auc:0.99481\tvalid-auc:0.827079\ttrain-ks:0.932637\tvalid-ks:0.498365\n",
      "\n",
      "train: ks = 0.93034 \t auc = 0.994810305097 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00158,0.04366) |    600    |     0.1     |      0      |      0.0      |  0.2008  |\n",
      "| 1 | [0.04366,0.09444) |    600    |     0.1     |      0      |      0.0      | 0.40161  |\n",
      "| 2 | [0.09444,0.16303) |    600    |     0.1     |      1      |    0.00167    | 0.60174  |\n",
      "| 3 | [0.16303,0.27862) |    600    |     0.1     |      5      |    0.00833    | 0.79921  |\n",
      "| 4 | [0.27862,0.52163) |    599    |     0.1     |     104     |    0.17362    | 0.93034  |\n",
      "| 5 | [0.52163,0.73443) |    600    |     0.1     |     508     |    0.84667    | 0.79241  |\n",
      "| 6 | [0.73443,0.83522) |    600    |     0.1     |     594     |      0.99     | 0.59715  |\n",
      "| 7 | [0.83522,0.90262) |    600    |     0.1     |     600     |      1.0      | 0.39788  |\n",
      "| 8 | [0.90262,0.95257) |    600    |     0.1     |     599     |    0.99833    | 0.19927  |\n",
      "| 9 | [0.95257,0.99764] |    600    |     0.1     |     600     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.49301 \t auc = 0.827078495288\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00205,0.05732) |    150    |     0.1     |      7      |    0.04667    | 0.18188  |\n",
      "| 1 | [0.05732,0.14146) |    150    |     0.1     |      18     |      0.12     | 0.33445  |\n",
      "| 2 | [0.14146,0.25821) |    150    |     0.1     |      29     |    0.19333    |  0.4577  |\n",
      "| 3 | [0.25821,0.40717) |    150    |     0.1     |      62     |    0.41333    | 0.49301  |\n",
      "| 4 | [0.40717,0.52473) |    150    |     0.1     |      81     |      0.54     | 0.47768  |\n",
      "| 5 |  [0.52473,0.6385) |    150    |     0.1     |      80     |    0.53333    | 0.46503  |\n",
      "| 6 |  [0.6385,0.75313) |    150    |     0.1     |     102     |      0.68     | 0.39374  |\n",
      "| 7 | [0.75313,0.83034) |    150    |     0.1     |     109     |    0.72667    |  0.3038  |\n",
      "| 8 |  [0.83034,0.9117) |    150    |     0.1     |     131     |    0.87333    | 0.15522  |\n",
      "| 9 |  [0.9117,0.99769] |    151    |     0.1     |     134     |    0.88742    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "\n",
      "================================================================================ 2018-12-19 16:58:36\n",
      "train : ks mean 0.92155 ; auc mean 0.99327\n",
      "validate : ks mean 0.52762 ; auc mean 0.84521\n",
      "\n",
      "\n",
      "start test xgboost model ... \n",
      "preprocessing test data...\n",
      "\n",
      "test: ks = 0.52171 \t auc = 0.843997091237 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.0028,0.0585)  |    250    |     0.1     |      13     |     0.052     | 0.17636  |\n",
      "| 1 |  [0.0585,0.13993) |    250    |     0.1     |      30     |      0.12     | 0.32551  |\n",
      "| 2 | [0.13993,0.25949) |    250    |     0.1     |      48     |     0.192     | 0.44586  |\n",
      "| 3 | [0.25949,0.39211) |    250    |     0.1     |      83     |     0.332     | 0.51019  |\n",
      "| 4 | [0.39211,0.52325) |    250    |     0.1     |     116     |     0.464     | 0.52171  |\n",
      "| 5 | [0.52325,0.63732) |    250    |     0.1     |     143     |     0.572     | 0.49002  |\n",
      "| 6 | [0.63732,0.75231) |    250    |     0.1     |     154     |     0.616     | 0.44073  |\n",
      "| 7 | [0.75231,0.84828) |    250    |     0.1     |     191     |     0.764     | 0.33223  |\n",
      "| 8 | [0.84828,0.92624) |    250    |     0.1     |     220     |      0.88     | 0.17732  |\n",
      "| 9 | [0.92624,0.99667] |    250    |     0.1     |     234     |     0.936     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练xgboost模型\n",
    "\n",
    "model = RunXgboost(dftrain = dftrain,dftest = dftest, coverage_th=0, ks_th=0,\n",
    "        outliers_th=None, selected_features=None)\n",
    "bst = model.train(cv=5, model_idx=5) \n",
    "model.test(bst,dftest)\n",
    "dfimportance = model.dfimportance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
