{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureAnalysis模块使用指南"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一，模块整体架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](FeatureAnalysis_Frame.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### outlier_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:39.055000Z",
     "start_time": "2018-07-24T08:46:39.041000Z"
    }
   },
   "outputs": [],
   "source": [
    "'med', #中位数\n",
    "'seg_25', #1/4分位数\n",
    "'seg_75', #3/4分位数\n",
    "'up_limit',  #离群值判定上边界\n",
    "'low_limit', #离群值判定下边界\n",
    "'up_ratio',  #超上边界离群值比例\n",
    "'low_ratio';  #超下边界离群值比例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:42.714000Z",
     "start_time": "2018-07-24T08:46:42.697000Z"
    }
   },
   "outputs": [],
   "source": [
    "#------覆盖率------------------------#\n",
    "'not_nan_ratio',  #非空比例，通常覆盖率coverage即指它\n",
    "'not_zero_ratio', #非零比例，非零值不含空值\n",
    "'not_outlier_ratio', #非离群值比例，非离群值不含空值\n",
    "\n",
    "#------统计值------------------------#\n",
    "'class_num', #数据类别数目\n",
    "'value_num', #非空数据数目\n",
    "'min', #最小值\n",
    "'mean',#均值\n",
    "'med', #中位数\n",
    "'most', #众数\n",
    "'max', #最大值\n",
    "\n",
    "#------有效性----------------------#\n",
    "'ks(continous feature)', #ks统计量，适合连续特征\n",
    "'ks_pvalue', #ks统计量的p值\n",
    "'chi2(discrete feature)', #chi2统计量，适合离散特征\n",
    "'chi2_pvalue', #chi2统计量的p值\n",
    "'t(for mean)', #均值t检验,仅对连续特征适用\n",
    "'t_pvalue' ,#均值t检验的p值\n",
    "'z(for coverage)',#覆盖率z检验，适合连续和离散特征，coverage指 not_nan_ratio\n",
    "'z_pvalue'; #覆盖率z检验的p值\n",
    "'iv'; #iv统计量，适合连续和离散特征，iv>0.1有效，iv>0.2强有效\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### psi_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:44.989000Z",
     "start_time": "2018-07-24T08:46:44.981000Z"
    }
   },
   "outputs": [],
   "source": [
    "'psi', #psi指标，仅当 train_data和 test_data 有效数据数量 >10时才取值，否则为 nan值\n",
    "'is_stable', #是否稳定，psi<0.2判定为稳定\n",
    "'train_class_num', # train_data中数据类别数目\n",
    "'test_class_num' , # test_data中数据类别数目\n",
    "'train_value_num', #train_data中有效数据数目\n",
    "'test_value_num';#test_data中有效数据数目\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ks_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:47.547000Z",
     "start_time": "2018-07-24T08:46:47.533000Z"
    }
   },
   "outputs": [],
   "source": [
    "'feature_interval',#特征取值区间\n",
    "'order_num', #订单数量\n",
    "'order_ratio', #订单占比\n",
    "'overdue_num', #逾期订单数量\n",
    "'overdue_ratio', #逾期订单占比\n",
    "'normal_num', #正常订单数量\n",
    "'normal_ratio', #正常订单占比\n",
    "'overdue_cum_ratio', #累计逾期订单比例\n",
    "'normal_cum_ratio', #累计正常订单比例\n",
    "'ks_value'; #ks统计值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:49.863000Z",
     "start_time": "2018-07-24T08:46:49.851000Z"
    }
   },
   "outputs": [],
   "source": [
    "'feature_interval',#区间\n",
    "'order_num', #订单数量\n",
    "'order_ratio', #订单占比\n",
    "'overdue_num', #逾期订单数量\n",
    "'overdue_ratio', #逾期订单比例\n",
    "'overdue_interval_ratio', #区间逾期订单占总逾期订单比例\n",
    "'normal_num', #正常订单数量\n",
    "'normal_ratio', #正常订单占比\n",
    "'normal_interval_ratio', #区间正常订单占总正常订单比例\n",
    "'iv_value'; #iv检验值，列重复\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chi2_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:52.318000Z",
     "start_time": "2018-07-24T08:46:52.291000Z"
    }
   },
   "outputs": [],
   "source": [
    "'TP', #feature为1的逾期样本数量\n",
    "'FP', #feature为1的正常样本数量\n",
    "'TN', #feature为0的正常样本数量\n",
    "'FN', #feature为0的逾期的样本数量\n",
    "'TPR', #TP/(TP+FN),逾期样本中feature取1比例\n",
    "'FPR',#FP/(FP+TN),正常样本中feature取1比例\n",
    "'overdue_ratio_0',# feature为0样本的逾期率\n",
    "'overdue_ratio_1',# feature为1样本的逾期率\n",
    "'precision',#精度\n",
    "'accuracy',#准确度\n",
    "'chi2', #shi nme shenmeenme\n",
    "'chi2_pvalue'; #卡方统计量的p值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二，单特征分析示范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T07:31:08.275000Z",
     "start_time": "2018-10-09T07:31:07.147000Z"
    }
   },
   "outputs": [],
   "source": [
    "import FeatureAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T07:33:03.890000Z",
     "start_time": "2018-10-09T07:33:03.487000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  FeatureAnalysis import feature_analysis\n",
    "\n",
    "# 准备数据\n",
    "data = [1.0,2,3,4,5,6,4,3,2,1,2,9,10,100,np.nan,0,7,8,10,6]\n",
    "label = [0,1,1,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,1]\n",
    "assert len(data)==len(label)\n",
    "\n",
    "fa = feature_analysis()\n",
    "# 离群值分析\n",
    "dfoutliers = fa.outliers_analysis(data,alpha = 2)\n",
    "\n",
    "# 去除离群值\n",
    "data_clean = fa.drop_outliers(data,data,alpha = 2)\n",
    "\n",
    "# 基本分析\n",
    "dfbasic = fa.basic_analysis(data,label)\n",
    "\n",
    "# psi稳定性分析\n",
    "test_data = [10,9,5,3,4,3,2,1,6,7,5,np.nan,10,100]\n",
    "dfpsi = fa.psi_analysis(data,test_data)\n",
    "\n",
    "# ks有效性分析,主要对连续特征，对离散特征也可分析\n",
    "dfks = fa.ks_analysis(data,label)\n",
    "\n",
    "# iv有效性分析，主要针对离散特征，对连续特征也适用\n",
    "dfiv = fa.iv_analysis(data,label)\n",
    "\n",
    "# 卡方及召回率等分析，主要针对离散特征\n",
    "dfchi2 = fa.chi2_analysis(data,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三，多特征分析示范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T07:34:33.949000Z",
     "start_time": "2018-10-09T07:34:33.426000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 多特征分析示范\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from FeatureAnalysis import FeatureAnalysis\n",
    "\n",
    "# 构造dftrain 训练集特征数据\n",
    "dftrain = pd.DataFrame()\n",
    "dftrain['phone'] = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12']\n",
    "dftrain['loan_dt'] = ['2018-01-01']*12\n",
    "dftrain['label'] = [0,1,1,0,1,0,0,0,0,0,1,0]\n",
    "dftrain['feature1'] = [1,0,1,0,1,0,1,0,1,0,1,1]\n",
    "dftrain['feature2'] = [1.0,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "\n",
    "# 构造dftest测试集特征\n",
    "dftest = pd.DataFrame()\n",
    "dftest['phone'] = ['y1','y2','y3','y4','y5','y6','y7','y8','y9','y10']\n",
    "dftest['loan_dt'] = ['2018-02-01']*10\n",
    "dftest['label'] = [1,0,0,1,0,0,0,1,0,0]\n",
    "dftest['feature1'] = [1,0,0,1,0,0,1,0,1,0]\n",
    "dftest['feature2'] = [10.0,9,8,7,6,5,4,3,2,1]\n",
    "\n",
    "FA = FeatureAnalysis(dftrain,dftest)\n",
    "\n",
    "#特征基本分析\n",
    "dfBasic = FA.BasicAnalysis()\n",
    "\n",
    "#特征稳定性分析\n",
    "dfPsi = FA.PsiAnalysis()\n",
    "\n",
    "#特征ks分析\n",
    "dfKs = FA.KsAnalysis()\n",
    "\n",
    "#特征iv分析\n",
    "dfIv = FA.IvAnalysis()\n",
    "\n",
    "#特征chi2分析\n",
    "dfChi2 = FA.Chi2Analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四，跑模型评分示范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T07:36:07.471000Z",
     "start_time": "2018-10-09T07:36:02.047000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=20,n_classes=2, random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = ['feature'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)\n",
    "dftrain,dftest = dftrain.copy(),dftest.copy()\n",
    "dftrain.index,dftest.index  = range(len(dftrain)),range(len(dftest))\n",
    "dftrain.loc[0,['feature0','feature1','feature2']] = np.nan #构造若干缺失值\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "from FeatureAnalysis import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method='most', scale_method= None)\n",
    "lr = model.train_lr(outputdir = './train_lr',cv=5, model_idx=5)\n",
    "model.test(lr)\n",
    "\n",
    "# 训练随机森林模型\n",
    "from FeatureAnalysis import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method='most', scale_method= None)\n",
    "rf = model.train_rf(outputdir = './train_randomforest',cv=5, model_idx=5,\n",
    "      n_estimators=100, max_depth=10, min_samples_split=2,\n",
    "      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "      max_features='auto', max_leaf_nodes=None, n_jobs = 4)\n",
    "model.test(rf)\n",
    "\n",
    "# 训练GBDT模型\n",
    "from FeatureAnalysis import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method='most', scale_method= None)\n",
    "gbdt = model.train_gbdt(outputdir = './train_gbdt',cv=5, model_idx=5,\n",
    "       learning_rate=0.01, n_estimators=1000, max_depth= 3, min_samples_split= 50, \n",
    "       min_samples_leaf= 5, subsample=0.7, max_features='sqrt',random_state= 0) \n",
    "model.test(gbdt)\n",
    "\n",
    "# 训练XGBOOST模型\n",
    "from FeatureAnalysis import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method= None, scale_method= None)\n",
    "xgb = model.train_xgb(outputdir = './train_xgb',learning_rate=0.1,cv=5, model_idx=5,\n",
    "      n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "      colsample_bytree=0.8,scale_pos_weight=1, nthread=4, seed=10) \n",
    "model.test(xgb)\n",
    "\n",
    "# 训练神经网络模型\n",
    "from FeatureAnalysis import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "             outliers_th=None, fillna_method='most', scale_method= None)\n",
    "nn = model.train_nn(outputdir = './train_nn', cv = 5, model_idx = 5,\n",
    "     hidden_layer_sizes=(100,20), activation='relu', alpha=0.0001, \n",
    "     learning_rate='constant', learning_rate_init=0.001, max_iter=200,tol=0.0001, \n",
    "     early_stopping=False, validation_fraction=0.1, warm_start=False, random_state = None)\n",
    "model.test(nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
