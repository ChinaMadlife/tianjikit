{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tianjikit模块使用指南"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一，模块整体架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](readme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### outlier_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:39.055000Z",
     "start_time": "2018-07-24T08:46:39.041000Z"
    }
   },
   "outputs": [],
   "source": [
    "'med', #中位数\n",
    "'seg_25', #1/4分位数\n",
    "'seg_75', #3/4分位数\n",
    "'up_limit',  #离群值判定上边界\n",
    "'low_limit', #离群值判定下边界\n",
    "'up_ratio',  #超上边界离群值比例\n",
    "'low_ratio';  #超下边界离群值比例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:42.714000Z",
     "start_time": "2018-07-24T08:46:42.697000Z"
    }
   },
   "outputs": [],
   "source": [
    "#------覆盖率------------------------#\n",
    "'not_nan_ratio',  #非空比例，通常覆盖率coverage即指它\n",
    "'not_zero_ratio', #非零比例，非零值不含空值\n",
    "'not_outlier_ratio', #非离群值比例，非离群值不含空值\n",
    "\n",
    "#------统计值------------------------#\n",
    "'class_num', #数据类别数目\n",
    "'value_num', #非空数据数目\n",
    "'min', #最小值\n",
    "'mean',#均值\n",
    "'med', #中位数\n",
    "'most', #众数\n",
    "'max', #最大值\n",
    "\n",
    "#------有效性----------------------#\n",
    "'ks(continous feature)', #ks统计量，适合连续特征\n",
    "'ks_pvalue', #ks统计量的p值\n",
    "'chi2(discrete feature)', #chi2统计量，适合离散特征\n",
    "'chi2_pvalue', #chi2统计量的p值\n",
    "'t(for mean)', #均值t检验,仅对连续特征适用\n",
    "'t_pvalue' ,#均值t检验的p值\n",
    "'z(for coverage)',#覆盖率z检验，适合连续和离散特征，coverage指 not_nan_ratio\n",
    "'z_pvalue'; #覆盖率z检验的p值\n",
    "'iv'; #iv统计量，适合连续和离散特征，iv>0.1有效，iv>0.2强有效\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### psi_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:44.989000Z",
     "start_time": "2018-07-24T08:46:44.981000Z"
    }
   },
   "outputs": [],
   "source": [
    "'psi', #psi指标，仅当 train_data和 test_data 有效数据数量 >10时才取值，否则为 nan值\n",
    "'is_stable', #是否稳定，psi<0.2判定为稳定\n",
    "'train_class_num', # train_data中数据类别数目\n",
    "'test_class_num' , # test_data中数据类别数目\n",
    "'train_value_num', #train_data中有效数据数目\n",
    "'test_value_num';#test_data中有效数据数目\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ks_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:47.547000Z",
     "start_time": "2018-07-24T08:46:47.533000Z"
    }
   },
   "outputs": [],
   "source": [
    "'feature_interval',#特征取值区间\n",
    "'order_num', #订单数量\n",
    "'order_ratio', #订单占比\n",
    "'overdue_num', #逾期订单数量\n",
    "'overdue_ratio', #逾期订单占比\n",
    "'normal_num', #正常订单数量\n",
    "'normal_ratio', #正常订单占比\n",
    "'overdue_cum_ratio', #累计逾期订单比例\n",
    "'normal_cum_ratio', #累计正常订单比例\n",
    "'ks_value'; #ks统计值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:49.863000Z",
     "start_time": "2018-07-24T08:46:49.851000Z"
    }
   },
   "outputs": [],
   "source": [
    "'feature_interval',#区间\n",
    "'order_num', #订单数量\n",
    "'order_ratio', #订单占比\n",
    "'overdue_num', #逾期订单数量\n",
    "'overdue_ratio', #逾期订单比例\n",
    "'overdue_interval_ratio', #区间逾期订单占总逾期订单比例\n",
    "'normal_num', #正常订单数量\n",
    "'normal_ratio', #正常订单占比\n",
    "'normal_interval_ratio', #区间正常订单占总正常订单比例\n",
    "'iv_value'; #iv检验值，列重复\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chi2_analysis的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T08:46:52.318000Z",
     "start_time": "2018-07-24T08:46:52.291000Z"
    }
   },
   "outputs": [],
   "source": [
    "'TP', #feature为1的逾期样本数量\n",
    "'FP', #feature为1的正常样本数量\n",
    "'TN', #feature为0的正常样本数量\n",
    "'FN', #feature为0的逾期的样本数量\n",
    "'TPR', #TP/(TP+FN),逾期样本中feature取1比例\n",
    "'FPR',#FP/(FP+TN),正常样本中feature取1比例\n",
    "'overdue_ratio_0',# feature为0样本的逾期率\n",
    "'overdue_ratio_1',# feature为1样本的逾期率\n",
    "'precision',#精度\n",
    "'accuracy',#准确度\n",
    "'chi2', #shi nme shenmeenme\n",
    "'chi2_pvalue'; #卡方统计量的p值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二，单特征分析示范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T03:44:16.042000Z",
     "start_time": "2018-10-16T03:44:15.630000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tianjikit.analysisfeature import AnalysisFeature\n",
    "\n",
    "# 准备数据\n",
    "data = [1.0,2,3,4,5,6,4,3,2,1,2,9,10,100,np.nan,0,7,8,10,6]\n",
    "label = [0,1,1,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,1]\n",
    "assert len(data)==len(label)\n",
    "\n",
    "af = AnalysisFeature()\n",
    "# 离群值分析\n",
    "dfoutliers = af.outliers_analysis(data,alpha = 2)\n",
    "\n",
    "# 去除离群值\n",
    "data_clean = af.drop_outliers(data,data,alpha = 2)\n",
    "\n",
    "# 基本分析\n",
    "dfbasic = af.basic_analysis(data,label)\n",
    "\n",
    "# psi稳定性分析\n",
    "test_data = [10,9,5,3,4,3,2,1,6,7,5,np.nan,10,100]\n",
    "dfpsi = af.psi_analysis(data,test_data)\n",
    "\n",
    "# ks有效性分析,主要对连续特征，对离散特征也可分析\n",
    "dfks = af.ks_analysis(data,label)\n",
    "\n",
    "# iv有效性分析，主要针对离散特征，对连续特征也适用\n",
    "dfiv = af.iv_analysis(data,label)\n",
    "\n",
    "# 卡方及召回率等分析，主要针对离散特征\n",
    "dfchi2 = af.chi2_analysis(data,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三，多特征分析示范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:34:36.461000Z",
     "start_time": "2018-10-26T04:34:34.900000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start basic_analysises...\n",
      "[total|done|todo]\n",
      "[2|2|0]\n",
      "start psi_analysises...\n",
      "[total|done|todo]\n",
      "[2|2|0]\n",
      "start ks_analysis...\n",
      "[total|done|todo]\n",
      "[2|2|0]\n",
      "start IvAnalysis...\n",
      "[total|done|todo]\n",
      "[2|2|0]\n"
     ]
    }
   ],
   "source": [
    "# 多特征分析示范\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tianjikit.analysisfeatures import AnalysisFeatures\n",
    "\n",
    "# 构造dftrain 训练集特征数据\n",
    "dftrain = pd.DataFrame()\n",
    "dftrain['phone'] = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12']\n",
    "dftrain['loan_dt'] = ['2018-01-01']*12\n",
    "dftrain['label'] = [0,1,1,0,1,0,0,0,0,0,1,0]\n",
    "dftrain['feature1'] = [1,0,1,0,1,0,1,0,1,0,1,1]\n",
    "dftrain['feature2'] = [1.0,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "\n",
    "# 构造dftest测试集特征\n",
    "dftest = pd.DataFrame()\n",
    "dftest['phone'] = ['y1','y2','y3','y4','y5','y6','y7','y8','y9','y10']\n",
    "dftest['loan_dt'] = ['2018-02-01']*10\n",
    "dftest['label'] = [1,0,0,1,0,0,0,1,0,0]\n",
    "dftest['feature1'] = [1,0,0,1,0,0,1,0,1,0]\n",
    "dftest['feature2'] = [10.0,9,8,7,6,5,4,3,2,1]\n",
    "\n",
    "afs = AnalysisFeatures(dftrain,dftest)\n",
    "\n",
    "#特征基本分析\n",
    "dfbasic = afs.basic_analysises()\n",
    "\n",
    "#特征稳定性分析\n",
    "dfpsi = afs.psi_analysises()\n",
    "\n",
    "#特征ks分析\n",
    "dfks = afs.ks_analysises()\n",
    "\n",
    "#特征iv分析\n",
    "dfiv = afs.iv_analysises()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四，跑模型评分示范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:34:45.626000Z",
     "start_time": "2018-10-26T04:34:45.524000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=20,n_classes=2, random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = ['feature'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)\n",
    "dftrain,dftest = dftrain.copy(),dftest.copy()\n",
    "dftrain.index,dftest.index  = range(len(dftrain)),range(len(dftest))\n",
    "dftrain.loc[0,['feature0','feature1','feature2']] = np.nan #构造若干缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:35:05.397000Z",
     "start_time": "2018-10-26T04:35:02.847000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START DATA PREPROCESSING ...\n",
      "\n",
      "train set size:  7500\n",
      "test set size:  2500\n",
      "coverage threshold:  0.1\n",
      "outlier threshold:  None\n",
      "ks threshold:  0\n",
      "chi2 threshold:  0\n",
      "fillna method:  most\n",
      "scale method:  None\n",
      "------------------------------------------------------------------------\n",
      "original feature number:  20\n",
      "feature number remain after dropfeature:  20\n",
      "feature number increased to after fill_na:  23\n",
      "------------------------------------------------------------------------\n",
      "START TRAIN LR MODEL ...\n",
      "\n",
      "2018-10-26 12:35:04:\n",
      "\n",
      "train: ks = 0.65334 \t auc = 0.898266528728 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00037,0.03416) |    750    |     0.1     |      28     |    0.03733    | 0.18433  |\n",
      "| 1 |  [0.03416,0.091)  |    750    |     0.1     |      49     |    0.06533    | 0.35745  |\n",
      "| 2 |   [0.091,0.193)   |    750    |     0.1     |      98     |    0.13067    | 0.50444  |\n",
      "| 3 |   [0.193,0.3394)  |    750    |     0.1     |     159     |     0.212     | 0.61889  |\n",
      "| 4 |  [0.3394,0.52545) |    750    |     0.1     |     309     |     0.412     | 0.65334  |\n",
      "| 5 | [0.52545,0.69104) |    750    |     0.1     |     461     |    0.61467    | 0.60673  |\n",
      "| 6 | [0.69104,0.79906) |    750    |     0.1     |     581     |    0.77467    | 0.49611  |\n",
      "| 7 | [0.79906,0.87366) |    750    |     0.1     |     657     |     0.876     | 0.34497  |\n",
      "| 8 | [0.87366,0.93562) |    750    |     0.1     |     685     |    0.91333    | 0.17889  |\n",
      "| 9 | [0.93562,0.99976] |    750    |     0.1     |     709     |    0.94533    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "START TEST MODEL ... \n",
      "\n",
      "test: ks = 0.6578 \t auc = 0.897232166636 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.0008,0.03283) |    250    |     0.1     |      11     |     0.044     | 0.18598  |\n",
      "| 1 | [0.03283,0.09289) |    250    |     0.1     |      24     |     0.096     | 0.35114  |\n",
      "| 2 | [0.09289,0.19794) |    250    |     0.1     |      27     |     0.108     | 0.51152  |\n",
      "| 3 | [0.19794,0.34959) |    250    |     0.1     |      65     |      0.26     | 0.61107  |\n",
      "| 4 | [0.34959,0.53476) |    250    |     0.1     |      98     |     0.392     |  0.6578  |\n",
      "| 5 | [0.53476,0.69727) |    250    |     0.1     |     156     |     0.624     | 0.61171  |\n",
      "| 6 | [0.69727,0.80616) |    250    |     0.1     |     199     |     0.796     |  0.4968  |\n",
      "| 7 | [0.80616,0.88007) |    250    |     0.1     |     224     |     0.896     | 0.34186  |\n",
      "| 8 | [0.88007,0.93361) |    250    |     0.1     |     234     |     0.936     | 0.17093  |\n",
      "| 9 |  [0.93361,0.9995] |    250    |     0.1     |     234     |     0.936     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# 训练逻辑回归模型\n",
    "from tianjikit.runmodel import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method='most', scale_method= None)\n",
    "lr = model.train_lr(cv=None, model_idx=5)\n",
    "model.test(lr)\n",
    "dfimportance = model.dfimportances['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:35:19.152000Z",
     "start_time": "2018-10-26T04:35:15.317000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START DATA PREPROCESSING ...\n",
      "\n",
      "train set size:  7500\n",
      "test set size:  2500\n",
      "coverage threshold:  0.1\n",
      "outlier threshold:  None\n",
      "ks threshold:  0\n",
      "chi2 threshold:  0\n",
      "fillna method:  most\n",
      "scale method:  None\n",
      "------------------------------------------------------------------------\n",
      "original feature number:  20\n",
      "feature number remain after dropfeature:  20\n",
      "feature number increased to after fill_na:  23\n",
      "------------------------------------------------------------------------\n",
      "START TRAIN RANDOMFOREST MODEL ...\n",
      "\n",
      "2018-10-26 12:35:17:\n",
      "\n",
      "train: ks = 0.90188 \t auc = 0.990171738571 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00343,0.02105) |    750    |     0.1     |      0      |      0.0      | 0.19926  |\n",
      "| 1 | [0.02105,0.03165) |    750    |     0.1     |      0      |      0.0      | 0.39851  |\n",
      "| 2 | [0.03165,0.04889) |    750    |     0.1     |      0      |      0.0      | 0.59777  |\n",
      "| 3 | [0.04889,0.19323) |    750    |     0.1     |      3      |     0.004     | 0.79543  |\n",
      "| 4 |  [0.19323,0.5547) |    750    |     0.1     |     174     |     0.232     | 0.90188  |\n",
      "| 5 |  [0.5547,0.80001) |    750    |     0.1     |     598     |    0.79733    |  0.7822  |\n",
      "| 6 | [0.80001,0.92866) |    750    |     0.1     |     712     |    0.94933    | 0.60171  |\n",
      "| 7 |  [0.92866,0.9486) |    750    |     0.1     |     749     |    0.99867    |  0.4015  |\n",
      "| 8 |  [0.9486,0.95906) |    750    |     0.1     |     750     |      1.0      | 0.20075  |\n",
      "| 9 | [0.95906,0.99266] |    750    |     0.1     |     750     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "START TEST MODEL ... \n",
      "\n",
      "test: ks = 0.81145 \t auc = 0.962367863069 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00766,0.02623) |    250    |     0.1     |      2      |     0.008     | 0.20038  |\n",
      "| 1 | [0.02623,0.03983) |    250    |     0.1     |      3      |     0.012     | 0.39916  |\n",
      "| 2 | [0.03983,0.07054) |    250    |     0.1     |      3      |     0.012     | 0.59794  |\n",
      "| 3 | [0.07054,0.24263) |    250    |     0.1     |      9      |     0.036     | 0.78713  |\n",
      "| 4 | [0.24263,0.55061) |    250    |     0.1     |     112     |     0.448     | 0.81145  |\n",
      "| 5 | [0.55061,0.81884) |    250    |     0.1     |     194     |     0.776     | 0.70454  |\n",
      "| 6 | [0.81884,0.91473) |    250    |     0.1     |     230     |      0.92     | 0.54001  |\n",
      "| 7 | [0.91473,0.94029) |    250    |     0.1     |     235     |      0.94     | 0.36747  |\n",
      "| 8 | [0.94029,0.95521) |    250    |     0.1     |     240     |      0.96     | 0.18693  |\n",
      "| 9 | [0.95521,0.99061] |    250    |     0.1     |     244     |     0.976     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# 训练随机森林模型\n",
    "from tianjikit.runmodel import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method='most', scale_method= None)\n",
    "rf = model.train_rf(cv=None, model_idx=5,\n",
    "      n_estimators=100, max_depth=10, min_samples_split=2,\n",
    "      min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "      max_features='auto', max_leaf_nodes=None, n_jobs = 4)\n",
    "model.test(rf)\n",
    "dfimportance = model.dfimportances['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:35:46.565000Z",
     "start_time": "2018-10-26T04:35:24.498000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START DATA PREPROCESSING ...\n",
      "\n",
      "train set size:  7500\n",
      "test set size:  2500\n",
      "coverage threshold:  0.1\n",
      "outlier threshold:  None\n",
      "ks threshold:  0\n",
      "chi2 threshold:  0\n",
      "fillna method:  most\n",
      "scale method:  None\n",
      "------------------------------------------------------------------------\n",
      "original feature number:  20\n",
      "feature number remain after dropfeature:  20\n",
      "feature number increased to after fill_na:  23\n",
      "------------------------------------------------------------------------\n",
      "START TRAIN GBDT MODEL ...\n",
      "\n",
      "2018-10-26 12:35:26: k = 1\n",
      "\n",
      "train: ks = 0.85266 \t auc = 0.980178991178 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00453,0.02046) |    600    |     0.1     |      0      |      0.0      | 0.19927  |\n",
      "| 1 |  [0.02046,0.0244) |    600    |     0.1     |      1      |    0.00167    | 0.39788  |\n",
      "| 2 |  [0.0244,0.03266) |    600    |     0.1     |      3      |     0.005     | 0.59514  |\n",
      "| 3 | [0.03266,0.16885) |    600    |     0.1     |      19     |    0.03167    | 0.78174  |\n",
      "| 4 | [0.16885,0.58204) |    599    |     0.1     |     192     |    0.32053    | 0.85266  |\n",
      "| 5 | [0.58204,0.82191) |    600    |     0.1     |     444     |      0.74     | 0.75587  |\n",
      "| 6 | [0.82191,0.93338) |    600    |     0.1     |     549     |     0.915     | 0.58908  |\n",
      "| 7 | [0.93338,0.95379) |    600    |     0.1     |     584     |    0.97333    | 0.39894  |\n",
      "| 8 | [0.95379,0.96321) |    600    |     0.1     |     597     |     0.995     | 0.20014  |\n",
      "| 9 |   [0.96321,0.98]  |    600    |     0.1     |     599     |    0.99833    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.79349 \t auc = 0.961061280724\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00618,0.02062) |    150    |     0.1     |      2      |    0.01333    | 0.19388  |\n",
      "| 1 | [0.02062,0.02477) |    150    |     0.1     |      0      |      0.0      | 0.39308  |\n",
      "| 2 | [0.02477,0.03439) |    150    |     0.1     |      1      |    0.00667    | 0.58962  |\n",
      "| 3 | [0.03439,0.19245) |    150    |     0.1     |      11     |    0.07333    |  0.7595  |\n",
      "| 4 | [0.19245,0.58713) |    150    |     0.1     |      62     |    0.41333    | 0.79349  |\n",
      "| 5 |  [0.58713,0.8086) |    150    |     0.1     |     109     |    0.72667    | 0.70221  |\n",
      "| 6 |  [0.8086,0.93068) |    150    |     0.1     |     125     |    0.83333    |  0.5683  |\n",
      "| 7 | [0.93068,0.95168) |    150    |     0.1     |     144     |      0.96     | 0.38375  |\n",
      "| 8 | [0.95168,0.96233) |    150    |     0.1     |     146     |    0.97333    | 0.19388  |\n",
      "| 9 | [0.96233,0.97818] |    151    |     0.1     |     148     |    0.98013    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:35:30: k = 2\n",
      "\n",
      "train: ks = 0.85102 \t auc = 0.980119954946 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.00341,0.021)  |    600    |     0.1     |      0      |      0.0      | 0.19927  |\n",
      "| 1 |   [0.021,0.0252)  |    600    |     0.1     |      1      |    0.00167    | 0.39788  |\n",
      "| 2 |  [0.0252,0.03457) |    600    |     0.1     |      3      |     0.005     | 0.59514  |\n",
      "| 3 |  [0.03457,0.174)  |    600    |     0.1     |      19     |    0.03167    | 0.78175  |\n",
      "| 4 |  [0.174,0.58761)  |    600    |     0.1     |     195     |     0.325     | 0.85102  |\n",
      "| 5 | [0.58761,0.81646) |    600    |     0.1     |     442     |    0.73667    | 0.75561  |\n",
      "| 6 | [0.81646,0.93146) |    600    |     0.1     |     546     |      0.91     | 0.59087  |\n",
      "| 7 | [0.93146,0.95098) |    600    |     0.1     |     586     |    0.97667    | 0.39947  |\n",
      "| 8 | [0.95098,0.96077) |    600    |     0.1     |     598     |    0.99667    | 0.20007  |\n",
      "| 9 | [0.96077,0.98494] |    600    |     0.1     |     599     |    0.99833    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.79335 \t auc = 0.961154934035\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00514,0.02149) |    150    |     0.1     |      1      |    0.00667    | 0.19654  |\n",
      "| 1 | [0.02149,0.02673) |    150    |     0.1     |      2      |    0.01333    |  0.3904  |\n",
      "| 2 | [0.02673,0.04011) |    150    |     0.1     |      1      |    0.00667    | 0.58695  |\n",
      "| 3 | [0.04011,0.21003) |    150    |     0.1     |      10     |    0.06667    | 0.75948  |\n",
      "| 4 |  [0.21003,0.6055) |    150    |     0.1     |      62     |    0.41333    | 0.79335  |\n",
      "| 5 |  [0.6055,0.82387) |    150    |     0.1     |     104     |    0.69333    | 0.71522  |\n",
      "| 6 | [0.82387,0.93412) |    150    |     0.1     |     133     |    0.88667    | 0.55974  |\n",
      "| 7 | [0.93412,0.95168) |    150    |     0.1     |     142     |    0.94667    | 0.38028  |\n",
      "| 8 | [0.95168,0.96092) |    150    |     0.1     |     147     |      0.98     | 0.18747  |\n",
      "| 9 |  [0.96092,0.983]  |    150    |     0.1     |     145     |    0.96667    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:35:34: k = 3\n",
      "\n",
      "train: ks = 0.85102 \t auc = 0.978618601428 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00952,0.02144) |    600    |     0.1     |      0      |      0.0      | 0.19927  |\n",
      "| 1 | [0.02144,0.02619) |    600    |     0.1     |      3      |     0.005     | 0.39654  |\n",
      "| 2 | [0.02619,0.03655) |    600    |     0.1     |      3      |     0.005     | 0.59381  |\n",
      "| 3 | [0.03655,0.17243) |    600    |     0.1     |      22     |    0.03667    | 0.77841  |\n",
      "| 4 | [0.17243,0.58283) |    600    |     0.1     |     190     |    0.31667    | 0.85102  |\n",
      "| 5 | [0.58283,0.82175) |    600    |     0.1     |     456     |      0.76     | 0.74628  |\n",
      "| 6 | [0.82175,0.92752) |    600    |     0.1     |     532     |    0.88667    | 0.59087  |\n",
      "| 7 |  [0.92752,0.949)  |    600    |     0.1     |     585     |     0.975     | 0.40014  |\n",
      "| 8 |  [0.949,0.95989)  |    600    |     0.1     |     600     |      1.0      | 0.19941  |\n",
      "| 9 | [0.95989,0.98338] |    600    |     0.1     |     598     |    0.99667    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.82002 \t auc = 0.972310668082\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01213,0.02194) |    150    |     0.1     |      0      |      0.0      |  0.1992  |\n",
      "| 1 | [0.02194,0.02683) |    150    |     0.1     |      1      |    0.00667    | 0.39574  |\n",
      "| 2 | [0.02683,0.03702) |    150    |     0.1     |      0      |      0.0      | 0.59494  |\n",
      "| 3 | [0.03702,0.17616) |    150    |     0.1     |      4      |    0.02667    | 0.78348  |\n",
      "| 4 | [0.17616,0.56387) |    150    |     0.1     |      61     |    0.40667    | 0.82002  |\n",
      "| 5 | [0.56387,0.80316) |    150    |     0.1     |     102     |      0.68     | 0.74721  |\n",
      "| 6 | [0.80316,0.92413) |    150    |     0.1     |     138     |      0.92     | 0.57841  |\n",
      "| 7 | [0.92413,0.94696) |    150    |     0.1     |     147     |      0.98     |  0.3856  |\n",
      "| 8 | [0.94696,0.95828) |    150    |     0.1     |     148     |    0.98667    | 0.19014  |\n",
      "| 9 | [0.95828,0.98056] |    150    |     0.1     |     146     |    0.97333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:35:38: k = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train: ks = 0.84301 \t auc = 0.978524489051 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00606,0.02095) |    600    |     0.1     |      1      |    0.00167    | 0.19861  |\n",
      "| 1 | [0.02095,0.02553) |    600    |     0.1     |      2      |    0.00333    | 0.39654  |\n",
      "| 2 | [0.02553,0.03448) |    600    |     0.1     |      2      |    0.00333    | 0.59448  |\n",
      "| 3 | [0.03448,0.17386) |    600    |     0.1     |      19     |    0.03167    | 0.78108  |\n",
      "| 4 | [0.17386,0.59024) |    600    |     0.1     |     206     |    0.34333    | 0.84301  |\n",
      "| 5 | [0.59024,0.81136) |    600    |     0.1     |     438     |      0.73     | 0.75027  |\n",
      "| 6 | [0.81136,0.92612) |    600    |     0.1     |     538     |    0.89667    | 0.59087  |\n",
      "| 7 | [0.92612,0.94773) |    600    |     0.1     |     589     |    0.98167    | 0.39747  |\n",
      "| 8 | [0.94773,0.95922) |    600    |     0.1     |     596     |    0.99333    | 0.19941  |\n",
      "| 9 | [0.95922,0.98183] |    600    |     0.1     |     598     |    0.99667    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.82002 \t auc = 0.971796882083\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.00397,0.02114) |    150    |     0.1     |      0      |      0.0      |  0.1992  |\n",
      "| 1 | [0.02114,0.02558) |    150    |     0.1     |      1      |    0.00667    | 0.39574  |\n",
      "| 2 | [0.02558,0.03441) |    150    |     0.1     |      1      |    0.00667    | 0.59227  |\n",
      "| 3 | [0.03441,0.18069) |    150    |     0.1     |      6      |      0.04     | 0.77548  |\n",
      "| 4 | [0.18069,0.56876) |    150    |     0.1     |      58     |    0.38667    | 0.82002  |\n",
      "| 5 | [0.56876,0.81916) |    150    |     0.1     |     100     |    0.66667    | 0.75255  |\n",
      "| 6 | [0.81916,0.92743) |    150    |     0.1     |     142     |    0.94667    | 0.57307  |\n",
      "| 7 | [0.92743,0.94637) |    150    |     0.1     |     145     |    0.96667    |  0.3856  |\n",
      "| 8 | [0.94637,0.95798) |    150    |     0.1     |     145     |    0.96667    | 0.19813  |\n",
      "| 9 | [0.95798,0.98253] |    150    |     0.1     |     149     |    0.99333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:35:42: k = 5\n",
      "\n",
      "train: ks = 0.8547 \t auc = 0.979112322873 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |  [0.0097,0.02109) |    600    |     0.1     |      0      |      0.0      |  0.1992  |\n",
      "| 1 | [0.02109,0.02518) |    600    |     0.1     |      0      |      0.0      | 0.39841  |\n",
      "| 2 |  [0.02518,0.0343) |    600    |     0.1     |      3      |     0.005     | 0.59561  |\n",
      "| 3 |  [0.0343,0.18086) |    600    |     0.1     |      22     |    0.03667    | 0.78015  |\n",
      "| 4 | [0.18086,0.57451) |    600    |     0.1     |     187     |    0.31167    |  0.8547  |\n",
      "| 5 | [0.57451,0.82253) |    600    |     0.1     |     453     |     0.755     | 0.75196  |\n",
      "| 6 | [0.82253,0.92792) |    600    |     0.1     |     542     |    0.90333    | 0.58988  |\n",
      "| 7 | [0.92792,0.95009) |    600    |     0.1     |     585     |     0.975     | 0.39914  |\n",
      "| 8 | [0.95009,0.96049) |    600    |     0.1     |     599     |    0.99833    | 0.19907  |\n",
      "| 9 | [0.96049,0.98827] |    601    |     0.1     |     598     |    0.99501    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.80922 \t auc = 0.968537269646\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01108,0.02121) |    150    |     0.1     |      1      |    0.00667    |  0.1968  |\n",
      "| 1 | [0.02121,0.02517) |    150    |     0.1     |      1      |    0.00667    |  0.3936  |\n",
      "| 2 |  [0.02517,0.0342) |    150    |     0.1     |      1      |    0.00667    | 0.59039  |\n",
      "| 3 |  [0.0342,0.17141) |    150    |     0.1     |      5      |    0.03333    | 0.77652  |\n",
      "| 4 | [0.17141,0.56607) |    149    |     0.1     |      62     |    0.41611    | 0.80922  |\n",
      "| 5 | [0.56607,0.83366) |    150    |     0.1     |     101     |    0.67333    | 0.73917  |\n",
      "| 6 | [0.83366,0.92589) |    150    |     0.1     |     139     |    0.92667    | 0.56772  |\n",
      "| 7 | [0.92589,0.94773) |    150    |     0.1     |     143     |    0.95333    | 0.38559  |\n",
      "| 8 | [0.94773,0.95915) |    150    |     0.1     |     145     |    0.96667    | 0.19813  |\n",
      "| 9 | [0.95915,0.97994] |    150    |     0.1     |     149     |    0.99333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "#################################################################################\n",
      "train : ks mean 0.85048 ; auc mean 0.97931\n",
      "validate : ks mean 0.80722 ; auc mean 0.96697\n",
      "\n",
      "START TEST MODEL ... \n",
      "\n",
      "test: ks = 0.81145 \t auc = 0.963698195153 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 | [0.01287,0.02169) |    250    |     0.1     |      1      |     0.004     | 0.20198  |\n",
      "| 1 | [0.02169,0.02606) |    250    |     0.1     |      5      |      0.02     | 0.39756  |\n",
      "| 2 | [0.02606,0.03677) |    250    |     0.1     |      2      |     0.008     | 0.59794  |\n",
      "| 3 | [0.03677,0.19883) |    250    |     0.1     |      11     |     0.044     | 0.78392  |\n",
      "| 4 | [0.19883,0.58936) |    250    |     0.1     |     110     |      0.44     | 0.81145  |\n",
      "| 5 | [0.58936,0.84548) |    250    |     0.1     |     188     |     0.752     | 0.71415  |\n",
      "| 6 | [0.84548,0.93177) |    250    |     0.1     |     231     |     0.924     | 0.54801  |\n",
      "| 7 | [0.93177,0.95011) |    250    |     0.1     |     236     |     0.944     | 0.37388  |\n",
      "| 8 | [0.95011,0.95938) |    250    |     0.1     |     244     |     0.976     | 0.18693  |\n",
      "| 9 | [0.95938,0.98463] |    250    |     0.1     |     244     |     0.976     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# 训练GBDT模型\n",
    "from tianjikit.runmodel import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method='most', scale_method= None)\n",
    "gbdt = model.train_gbdt(cv=5, model_idx=5,\n",
    "       learning_rate=0.01, n_estimators=1000, max_depth= 3, min_samples_split= 50, \n",
    "       min_samples_leaf= 5, subsample=0.7, max_features='sqrt',random_state= 0) \n",
    "model.test(gbdt)\n",
    "dfimportance = model.dfimportances['gbdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:37:03.638000Z",
     "start_time": "2018-10-26T04:36:12.139000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START DATA PREPROCESSING ...\n",
      "\n",
      "train set size:  7500\n",
      "test set size:  2500\n",
      "coverage threshold:  0.1\n",
      "outlier threshold:  None\n",
      "ks threshold:  0\n",
      "chi2 threshold:  0\n",
      "fillna method:  None\n",
      "scale method:  None\n",
      "------------------------------------------------------------------------\n",
      "original feature number:  20\n",
      "feature number remain after dropfeature:  20\n",
      "feature number increased to after fill_na:  20\n",
      "------------------------------------------------------------------------\n",
      "START TRAIN XGBOOST MODEL ...\n",
      "\n",
      "2018-10-26 12:36:13: k = 1\n",
      "\n",
      "train: ks = 0.99601 \t auc = 1.0 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,4e-05)    |    600    |     0.1     |      0      |      0.0      | 0.19927  |\n",
      "| 1 |  [4e-05,0.00012)  |    600    |     0.1     |      0      |      0.0      | 0.39854  |\n",
      "| 2 | [0.00012,0.00047) |    600    |     0.1     |      0      |      0.0      | 0.59781  |\n",
      "| 3 | [0.00047,0.00529) |    600    |     0.1     |      0      |      0.0      | 0.79708  |\n",
      "| 4 | [0.00529,0.04046) |    599    |     0.1     |      0      |      0.0      | 0.99601  |\n",
      "| 5 | [0.04046,0.99284) |    600    |     0.1     |     588     |      0.98     | 0.80321  |\n",
      "| 6 | [0.99284,0.99799) |    600    |     0.1     |     600     |      1.0      | 0.60241  |\n",
      "| 7 | [0.99799,0.99938) |    600    |     0.1     |     600     |      1.0      | 0.40161  |\n",
      "| 8 | [0.99938,0.99982) |    600    |     0.1     |     600     |      1.0      |  0.2008  |\n",
      "| 9 |   [0.99982,1.0]   |    600    |     0.1     |     600     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.80681 \t auc = 0.961371980882\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,4e-05)    |    150    |     0.1     |      1      |    0.00667    | 0.19654  |\n",
      "| 1 |  [4e-05,0.00014)  |    150    |     0.1     |      1      |    0.00667    | 0.39308  |\n",
      "| 2 | [0.00014,0.00066) |    150    |     0.1     |      0      |      0.0      | 0.59228  |\n",
      "| 3 | [0.00066,0.02122) |    150    |     0.1     |      11     |    0.07333    | 0.76217  |\n",
      "| 4 | [0.02122,0.75601) |    150    |     0.1     |      58     |    0.38667    | 0.80681  |\n",
      "| 5 | [0.75601,0.97002) |    150    |     0.1     |     114     |      0.76     | 0.70221  |\n",
      "| 6 | [0.97002,0.99612) |    150    |     0.1     |     131     |    0.87333    | 0.55231  |\n",
      "| 7 | [0.99612,0.99915) |    150    |     0.1     |     138     |      0.92     | 0.38375  |\n",
      "| 8 | [0.99915,0.99978) |    150    |     0.1     |     147     |      0.98     | 0.19121  |\n",
      "| 9 |   [0.99978,1.0]   |    151    |     0.1     |     147     |    0.97351    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:36:25: k = 2\n",
      "\n",
      "train: ks = 0.99635 \t auc = 1.0 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,2e-05)    |    600    |     0.1     |      0      |      0.0      | 0.19927  |\n",
      "| 1 |   [2e-05,9e-05)   |    600    |     0.1     |      0      |      0.0      | 0.39854  |\n",
      "| 2 |  [9e-05,0.00038)  |    600    |     0.1     |      0      |      0.0      | 0.59781  |\n",
      "| 3 | [0.00038,0.00488) |    600    |     0.1     |      0      |      0.0      | 0.79708  |\n",
      "| 4 | [0.00488,0.04228) |    600    |     0.1     |      0      |      0.0      | 0.99635  |\n",
      "| 5 | [0.04228,0.99326) |    600    |     0.1     |     589     |    0.98167    | 0.80294  |\n",
      "| 6 | [0.99326,0.99812) |    600    |     0.1     |     600     |      1.0      | 0.60221  |\n",
      "| 7 | [0.99812,0.99945) |    599    |     0.1     |     599     |      1.0      | 0.40181  |\n",
      "| 8 | [0.99945,0.99986) |    601    |     0.1     |     601     |      1.0      | 0.20074  |\n",
      "| 9 |   [0.99986,1.0]   |    600    |     0.1     |     600     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.78801 \t auc = 0.956799308789\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,3e-05)    |    150    |     0.1     |      3      |      0.02     |  0.1912  |\n",
      "| 1 |   [3e-05,0.0001)  |    150    |     0.1     |      0      |      0.0      |  0.3904  |\n",
      "| 2 |  [0.0001,0.00059) |    150    |     0.1     |      2      |    0.01333    | 0.58428  |\n",
      "| 3 | [0.00059,0.01765) |    150    |     0.1     |      5      |    0.03333    | 0.77014  |\n",
      "| 4 | [0.01765,0.80811) |    150    |     0.1     |      68     |    0.45333    | 0.78801  |\n",
      "| 5 | [0.80811,0.98514) |    150    |     0.1     |     111     |      0.74     | 0.69121  |\n",
      "| 6 | [0.98514,0.99764) |    150    |     0.1     |     126     |      0.84     | 0.55441  |\n",
      "| 7 | [0.99764,0.99928) |    150    |     0.1     |     140     |    0.93333    | 0.38028  |\n",
      "| 8 | [0.99928,0.99984) |    150    |     0.1     |     146     |    0.97333    | 0.19014  |\n",
      "| 9 |   [0.99984,1.0]   |    150    |     0.1     |     146     |    0.97333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:36:37: k = 3\n",
      "\n",
      "train: ks = 0.99635 \t auc = 1.0 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,3e-05)    |    600    |     0.1     |      0      |      0.0      | 0.19927  |\n",
      "| 1 |  [3e-05,0.00012)  |    600    |     0.1     |      0      |      0.0      | 0.39854  |\n",
      "| 2 | [0.00012,0.00047) |    600    |     0.1     |      0      |      0.0      | 0.59781  |\n",
      "| 3 | [0.00047,0.00469) |    600    |     0.1     |      0      |      0.0      | 0.79708  |\n",
      "| 4 | [0.00469,0.04039) |    600    |     0.1     |      0      |      0.0      | 0.99635  |\n",
      "| 5 | [0.04039,0.99334) |    600    |     0.1     |     589     |    0.98167    | 0.80294  |\n",
      "| 6 | [0.99334,0.99797) |    600    |     0.1     |     600     |      1.0      | 0.60221  |\n",
      "| 7 | [0.99797,0.99937) |    600    |     0.1     |     600     |      1.0      | 0.40147  |\n",
      "| 8 | [0.99937,0.99981) |    599    |     0.1     |     599     |      1.0      | 0.20107  |\n",
      "| 9 |   [0.99981,1.0]   |    601    |     0.1     |     601     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.78267 \t auc = 0.958287332597\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,4e-05)    |    150    |     0.1     |      0      |      0.0      |  0.1992  |\n",
      "| 1 |  [4e-05,0.00013)  |    150    |     0.1     |      1      |    0.00667    | 0.39574  |\n",
      "| 2 | [0.00013,0.00057) |    150    |     0.1     |      1      |    0.00667    | 0.59227  |\n",
      "| 3 | [0.00057,0.01657) |    150    |     0.1     |      13     |    0.08667    | 0.75681  |\n",
      "| 4 | [0.01657,0.61263) |    150    |     0.1     |      65     |    0.43333    | 0.78267  |\n",
      "| 5 | [0.61263,0.96048) |    150    |     0.1     |     102     |      0.68     | 0.70988  |\n",
      "| 6 | [0.96048,0.99608) |    150    |     0.1     |     135     |      0.9      | 0.54908  |\n",
      "| 7 | [0.99608,0.99918) |    150    |     0.1     |     141     |      0.94     | 0.37227  |\n",
      "| 8 | [0.99918,0.99977) |    150    |     0.1     |     143     |    0.95333    | 0.19014  |\n",
      "| 9 |   [0.99977,1.0]   |    150    |     0.1     |     146     |    0.97333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:36:45: k = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train: ks = 0.99635 \t auc = 1.0 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,3e-05)    |    600    |     0.1     |      0      |      0.0      | 0.19927  |\n",
      "| 1 |  [3e-05,0.00013)  |    600    |     0.1     |      0      |      0.0      | 0.39854  |\n",
      "| 2 | [0.00013,0.00049) |    600    |     0.1     |      0      |      0.0      | 0.59781  |\n",
      "| 3 | [0.00049,0.00608) |    600    |     0.1     |      0      |      0.0      | 0.79708  |\n",
      "| 4 | [0.00608,0.04446) |    600    |     0.1     |      0      |      0.0      | 0.99635  |\n",
      "| 5 | [0.04446,0.99215) |    600    |     0.1     |     589     |    0.98167    | 0.80294  |\n",
      "| 6 | [0.99215,0.99748) |    600    |     0.1     |     600     |      1.0      | 0.60221  |\n",
      "| 7 | [0.99748,0.99925) |    600    |     0.1     |     600     |      1.0      | 0.40147  |\n",
      "| 8 | [0.99925,0.99979) |    600    |     0.1     |     600     |      1.0      | 0.20074  |\n",
      "| 9 |   [0.99979,1.0]   |    600    |     0.1     |     600     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.83868 \t auc = 0.977203190807\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,4e-05)    |    150    |     0.1     |      1      |    0.00667    | 0.19654  |\n",
      "| 1 |  [4e-05,0.00013)  |    150    |     0.1     |      0      |      0.0      | 0.39574  |\n",
      "| 2 | [0.00013,0.00047) |    150    |     0.1     |      0      |      0.0      | 0.59494  |\n",
      "| 3 | [0.00047,0.00651) |    150    |     0.1     |      5      |    0.03333    | 0.78081  |\n",
      "| 4 | [0.00651,0.64146) |    150    |     0.1     |      53     |    0.35333    | 0.83868  |\n",
      "| 5 | [0.64146,0.94576) |    150    |     0.1     |     106     |    0.70667    | 0.75522  |\n",
      "| 6 |  [0.94576,0.9935) |    150    |     0.1     |     136     |    0.90667    | 0.59174  |\n",
      "| 7 |  [0.9935,0.99855) |    150    |     0.1     |     147     |      0.98     | 0.39894  |\n",
      "| 8 |  [0.99855,0.9997) |    150    |     0.1     |     150     |      1.0      | 0.19813  |\n",
      "| 9 |    [0.9997,1.0]   |    150    |     0.1     |     149     |    0.99333    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "2018-10-26 12:36:53: k = 5\n",
      "\n",
      "train: ks = 0.99602 \t auc = 1.0 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,4e-05)    |    600    |     0.1     |      0      |      0.0      |  0.1992  |\n",
      "| 1 |  [4e-05,0.00014)  |    600    |     0.1     |      0      |      0.0      | 0.39841  |\n",
      "| 2 | [0.00014,0.00049) |    600    |     0.1     |      0      |      0.0      | 0.59761  |\n",
      "| 3 | [0.00049,0.00542) |    600    |     0.1     |      0      |      0.0      | 0.79681  |\n",
      "| 4 | [0.00542,0.04153) |    600    |     0.1     |      0      |      0.0      | 0.99602  |\n",
      "| 5 | [0.04153,0.99276) |    600    |     0.1     |     588     |      0.98     | 0.80328  |\n",
      "| 6 | [0.99276,0.99794) |    600    |     0.1     |     600     |      1.0      | 0.60254  |\n",
      "| 7 | [0.99794,0.99944) |    599    |     0.1     |     599     |      1.0      | 0.40214  |\n",
      "| 8 | [0.99944,0.99985) |    601    |     0.1     |     601     |      1.0      | 0.20107  |\n",
      "| 9 |   [0.99985,1.0]   |    601    |     0.1     |     601     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "validate: ks = 0.80655 \t auc = 0.964903942009\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,5e-05)    |    150    |     0.1     |      0      |      0.0      | 0.19947  |\n",
      "| 1 |  [5e-05,0.00016)  |    150    |     0.1     |      1      |    0.00667    | 0.39627  |\n",
      "| 2 | [0.00016,0.00072) |    150    |     0.1     |      1      |    0.00667    | 0.59306  |\n",
      "| 3 | [0.00072,0.02396) |    150    |     0.1     |      7      |    0.04667    | 0.77385  |\n",
      "| 4 | [0.02396,0.73041) |    149    |     0.1     |      62     |    0.41611    | 0.80655  |\n",
      "| 5 | [0.73041,0.98377) |    150    |     0.1     |     110     |    0.73333    | 0.71249  |\n",
      "| 6 | [0.98377,0.99735) |    150    |     0.1     |     129     |      0.86     | 0.56772  |\n",
      "| 7 | [0.99735,0.99946) |    150    |     0.1     |     146     |    0.97333    | 0.37759  |\n",
      "| 8 | [0.99946,0.99987) |    150    |     0.1     |     143     |    0.95333    | 0.19547  |\n",
      "| 9 |   [0.99987,1.0]   |    150    |     0.1     |     148     |    0.98667    |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "#################################################################################\n",
      "train : ks mean 0.99622 ; auc mean 1.00000\n",
      "validate : ks mean 0.80454 ; auc mean 0.96371\n",
      "\n",
      "START TEST MODEL ... \n",
      "\n",
      "test: ks = 0.80665 \t auc = 0.961964218036 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |    [0.0,5e-05)    |    250    |     0.1     |      3      |     0.012     | 0.19878  |\n",
      "| 1 |  [5e-05,0.00019)  |    250    |     0.1     |      2      |     0.008     | 0.39916  |\n",
      "| 2 |  [0.00019,0.0008) |    250    |     0.1     |      2      |     0.008     | 0.59955  |\n",
      "| 3 |  [0.0008,0.02013) |    250    |     0.1     |      14     |     0.056     | 0.78072  |\n",
      "| 4 | [0.02013,0.72985) |    250    |     0.1     |     111     |     0.444     | 0.80665  |\n",
      "| 5 | [0.72985,0.98272) |    250    |     0.1     |     192     |     0.768     | 0.70293  |\n",
      "| 6 | [0.98272,0.99717) |    250    |     0.1     |     225     |      0.9      | 0.54641  |\n",
      "| 7 | [0.99717,0.99931) |    250    |     0.1     |     238     |     0.952     | 0.36908  |\n",
      "| 8 | [0.99931,0.99985) |    250    |     0.1     |     242     |     0.968     | 0.18534  |\n",
      "| 9 |   [0.99985,1.0]   |    250    |     0.1     |     243     |     0.972     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# 训练XGBOOST模型\n",
    "from tianjikit.runmodel import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "                 outliers_th=None, fillna_method= None, scale_method= None)\n",
    "xgb = model.train_xgb(cv=5,learning_rate=0.1, model_idx=5,\n",
    "      n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "      colsample_bytree=0.8,scale_pos_weight=1, n_jobs=4, seed=10) \n",
    "model.test(xgb)\n",
    "dfimportance = model.dfimportances['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:37:37.279000Z",
     "start_time": "2018-10-26T04:37:27.970000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START DATA PREPROCESSING ...\n",
      "\n",
      "train set size:  7500\n",
      "test set size:  2500\n",
      "coverage threshold:  0.1\n",
      "outlier threshold:  None\n",
      "ks threshold:  0\n",
      "chi2 threshold:  0\n",
      "fillna method:  most\n",
      "scale method:  None\n",
      "------------------------------------------------------------------------\n",
      "original feature number:  20\n",
      "feature number remain after dropfeature:  20\n",
      "feature number increased to after fill_na:  23\n",
      "------------------------------------------------------------------------\n",
      "START TRAIN NEURAL NETWORK MODEL ...\n",
      "\n",
      "2018-10-26 12:37:30:\n",
      "\n",
      "train: ks = 0.98241 \t auc = 0.999362408891 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |     [0.0,0.0)     |    750    |     0.1     |      0      |      0.0      | 0.19926  |\n",
      "| 1 |    [0.0,1e-05)    |    750    |     0.1     |      0      |      0.0      | 0.39851  |\n",
      "| 2 |  [1e-05,0.00057)  |    750    |     0.1     |      1      |    0.00133    | 0.59723  |\n",
      "| 3 | [0.00057,0.03802) |    750    |     0.1     |      2      |    0.00267    | 0.79543  |\n",
      "| 4 | [0.03802,0.59253) |    750    |     0.1     |      23     |    0.03067    | 0.98241  |\n",
      "| 5 | [0.59253,0.98189) |    750    |     0.1     |     710     |    0.94667    |  0.803   |\n",
      "| 6 | [0.98189,0.99877) |    750    |     0.1     |     750     |      1.0      | 0.60225  |\n",
      "| 7 | [0.99877,0.99995) |    750    |     0.1     |     750     |      1.0      |  0.4015  |\n",
      "| 8 |   [0.99995,1.0)   |    750    |     0.1     |     750     |      1.0      | 0.20075  |\n",
      "| 9 |     [1.0,1.0]     |    750    |     0.1     |     750     |      1.0      |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "\n",
      "START TEST MODEL ... \n",
      "\n",
      "test: ks = 0.73591 \t auc = 0.939374500645 \n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "|   |  feature_interval | order_num | order_ratio | overdue_num | overdue_ratio | ks_value |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n",
      "| 0 |     [0.0,0.0)     |    250    |     0.1     |      4      |     0.016     | 0.19719  |\n",
      "| 1 |    [0.0,1e-05)    |    250    |     0.1     |      2      |     0.008     | 0.39756  |\n",
      "| 2 |   [1e-05,0.001)   |    250    |     0.1     |      5      |      0.02     | 0.59314  |\n",
      "| 3 |  [0.001,0.07001)  |    250    |     0.1     |      38     |     0.152     | 0.73591  |\n",
      "| 4 | [0.07001,0.72878) |    250    |     0.1     |     132     |     0.528     | 0.72822  |\n",
      "| 5 | [0.72878,0.98222) |    250    |     0.1     |     174     |     0.696     | 0.65332  |\n",
      "| 6 | [0.98222,0.99901) |    250    |     0.1     |     209     |     0.836     |  0.5224  |\n",
      "| 7 | [0.99901,0.99995) |    250    |     0.1     |     231     |     0.924     | 0.35627  |\n",
      "| 8 |   [0.99995,1.0)   |    250    |     0.1     |     240     |      0.96     | 0.17573  |\n",
      "| 9 |     [1.0,1.0]     |    250    |     0.1     |     237     |     0.948     |   0.0    |\n",
      "+---+-------------------+-----------+-------------+-------------+---------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# 训练神经网络模型\n",
    "from tianjikit.runmodel import RunModel\n",
    "model = RunModel(dftrain = dftrain,dftest = dftest,coverage_th=0.1, ks_th=0, chi2_th=0, \n",
    "             outliers_th=None, fillna_method='most', scale_method= None)\n",
    "nn = model.train_nn(cv = None, model_idx = 5,\n",
    "     hidden_layer_sizes=(100,20), activation='relu', alpha=0.0001, \n",
    "     learning_rate='constant', learning_rate_init=0.001, max_iter=200,tol=0.0001, \n",
    "     early_stopping=False, validation_fraction=0.1, warm_start=False, random_state = None)\n",
    "model.test(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五，xgboost调参示范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:37:58.003000Z",
     "start_time": "2018-10-26T04:37:57.942000Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from tianjikit.tunning import Tunning\n",
    "\n",
    "data,label = datasets.make_classification(n_samples= 10000, n_features=20, n_informative= 6 ,\n",
    "             n_classes=2, n_clusters_per_class=10,random_state=0)\n",
    "dfdata = pd.DataFrame(data,columns = [u'f'+str(i) for i in range(data.shape[1])])\n",
    "dfdata['label'] = label\n",
    "dftrain,dftest = train_test_split(dfdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:38:01.363000Z",
     "start_time": "2018-10-26T04:38:01.345000Z"
    }
   },
   "outputs": [],
   "source": [
    "params_dict = dict()\n",
    "\n",
    "# 以下为待调整参数\n",
    "# booster参数\n",
    "params_dict['learning_rate'] = 0.1        # 学习率，初始值为 0.1，通常越小越好。\n",
    "params_dict['n_estimators'] = 50          # 加法模型树的数量，初始值为50，通常通过xgboost自带模型cv确认。\n",
    "\n",
    "# tree参数\n",
    "params_dict['max_depth'] = 5              # 树的深度，通常取值在[3,10]之间，初始值常取[3,6]之间\n",
    "params_dict['min_child_weight']=1         # 最小叶子节点样本权重和，越大模型越保守。\n",
    "params_dict['gamma']= 0                   # 节点分裂所需的最小损失函数下降值，越大模型越保守。\n",
    "params_dict['subsample']= 0.8             # 横向采样，样本采样比例，通常取值在 [0.5，1]之间 \n",
    "params_dict['colsample_bytree'] = 0.8     # 纵向采样，特征采样比例，通常取值在 [0.5，1]之间 \n",
    "\n",
    "# regulazation参数 \n",
    "# Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda  \n",
    "params_dict['reg_alpha'] = 0              #L1 正则化项的权重系数，越大模型越保守，通常取值在[0,1]之间。\n",
    "params_dict['reg_lambda'] = 1             #L2 正则化项的权重系数，越大模型越保守，通常取值在[1,100]之间。\n",
    "\n",
    "# 以下参数通常不需要调整\n",
    "params_dict['objective'] = 'binary:logistic'\n",
    "params_dict['n_jobs'] = 4\n",
    "params_dict['scale_pos_weight'] = 1       #不平衡样本时设定为正值可以使算法更快收敛。\n",
    "params_dict['seed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:38:14.485000Z",
     "start_time": "2018-10-26T04:38:05.816000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711867</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id train_score validate_score test_score learning_rate n_estimators  \\\n",
       "0        0    0.711867       0.524533   0.538377           0.1           50   \n",
       "\n",
       "  max_depth min_child_weight gamma subsample colsample_bytree reg_alpha  \\\n",
       "0         5                1     0       0.8              0.8         0   \n",
       "\n",
       "  reg_lambda  \n",
       "0          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step0: 初始化\n",
    "model = XGBClassifier()\n",
    "tune = Tunning(model = model,dftrain = dftrain,dftest = dftest,params_dict = params_dict,n_jobs = 4)\n",
    "tune.dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:38:58.696000Z",
     "start_time": "2018-10-26T04:38:32.716000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.650211\ttrain-ks:0.215644\ttest-auc:0.617175\ttest-ks:0.172071\n",
      "Multiple eval metrics have been passed: 'test-ks' will be used for early stopping.\n",
      "\n",
      "Will train until test-ks hasn't improved in 100 rounds.\n",
      "[1]\ttrain-auc:0.801364\ttrain-ks:0.449576\ttest-auc:0.762951\ttest-ks:0.396161\n",
      "[2]\ttrain-auc:0.825735\ttrain-ks:0.502388\ttest-auc:0.7807\ttest-ks:0.427575\n",
      "[3]\ttrain-auc:0.841881\ttrain-ks:0.526476\ttest-auc:0.788658\ttest-ks:0.444223\n",
      "[4]\ttrain-auc:0.85548\ttrain-ks:0.547742\ttest-auc:0.799637\ttest-ks:0.455096\n",
      "[5]\ttrain-auc:0.864493\ttrain-ks:0.566979\ttest-auc:0.807322\ttest-ks:0.474325\n",
      "[6]\ttrain-auc:0.872816\ttrain-ks:0.582781\ttest-auc:0.814585\ttest-ks:0.488015\n",
      "[7]\ttrain-auc:0.878036\ttrain-ks:0.592275\ttest-auc:0.816817\ttest-ks:0.489873\n",
      "[8]\ttrain-auc:0.88316\ttrain-ks:0.600612\ttest-auc:0.817964\ttest-ks:0.49168\n",
      "[9]\ttrain-auc:0.889966\ttrain-ks:0.613248\ttest-auc:0.821236\ttest-ks:0.495217\n",
      "[10]\ttrain-auc:0.893615\ttrain-ks:0.622356\ttest-auc:0.822257\ttest-ks:0.49535\n",
      "[11]\ttrain-auc:0.897611\ttrain-ks:0.630456\ttest-auc:0.823717\ttest-ks:0.499258\n",
      "[12]\ttrain-auc:0.90047\ttrain-ks:0.636131\ttest-auc:0.824401\ttest-ks:0.506796\n",
      "[13]\ttrain-auc:0.903089\ttrain-ks:0.641799\ttest-auc:0.824415\ttest-ks:0.504341\n",
      "[14]\ttrain-auc:0.907809\ttrain-ks:0.653346\ttest-auc:0.828038\ttest-ks:0.507934\n",
      "[15]\ttrain-auc:0.91211\ttrain-ks:0.662437\ttest-auc:0.828169\ttest-ks:0.509527\n",
      "[16]\ttrain-auc:0.915176\ttrain-ks:0.671209\ttest-auc:0.828805\ttest-ks:0.507146\n",
      "[17]\ttrain-auc:0.919237\ttrain-ks:0.68226\ttest-auc:0.828855\ttest-ks:0.509025\n",
      "[18]\ttrain-auc:0.922017\ttrain-ks:0.688082\ttest-auc:0.828867\ttest-ks:0.508852\n",
      "[19]\ttrain-auc:0.924436\ttrain-ks:0.692807\ttest-auc:0.82824\ttest-ks:0.50866\n",
      "[20]\ttrain-auc:0.925885\ttrain-ks:0.696396\ttest-auc:0.827901\ttest-ks:0.506525\n",
      "[21]\ttrain-auc:0.928441\ttrain-ks:0.701653\ttest-auc:0.827977\ttest-ks:0.50817\n",
      "[22]\ttrain-auc:0.931104\ttrain-ks:0.705509\ttest-auc:0.827837\ttest-ks:0.506087\n",
      "[23]\ttrain-auc:0.933722\ttrain-ks:0.711797\ttest-auc:0.827049\ttest-ks:0.504006\n",
      "[24]\ttrain-auc:0.935948\ttrain-ks:0.719318\ttest-auc:0.826044\ttest-ks:0.504696\n",
      "[25]\ttrain-auc:0.938163\ttrain-ks:0.724912\ttest-auc:0.825664\ttest-ks:0.503591\n",
      "[26]\ttrain-auc:0.940221\ttrain-ks:0.73165\ttest-auc:0.825614\ttest-ks:0.505698\n",
      "[27]\ttrain-auc:0.943184\ttrain-ks:0.739486\ttest-auc:0.826546\ttest-ks:0.50786\n",
      "[28]\ttrain-auc:0.945716\ttrain-ks:0.746717\ttest-auc:0.826675\ttest-ks:0.507238\n",
      "[29]\ttrain-auc:0.947712\ttrain-ks:0.751926\ttest-auc:0.826243\ttest-ks:0.506659\n",
      "[30]\ttrain-auc:0.949288\ttrain-ks:0.755947\ttest-auc:0.827021\ttest-ks:0.50663\n",
      "[31]\ttrain-auc:0.950893\ttrain-ks:0.760493\ttest-auc:0.82689\ttest-ks:0.50822\n",
      "[32]\ttrain-auc:0.952464\ttrain-ks:0.765164\ttest-auc:0.827408\ttest-ks:0.507762\n",
      "[33]\ttrain-auc:0.953896\ttrain-ks:0.7693\ttest-auc:0.828159\ttest-ks:0.506935\n",
      "[34]\ttrain-auc:0.955315\ttrain-ks:0.774656\ttest-auc:0.828741\ttest-ks:0.511452\n",
      "[35]\ttrain-auc:0.956666\ttrain-ks:0.777522\ttest-auc:0.82881\ttest-ks:0.510264\n",
      "[36]\ttrain-auc:0.957969\ttrain-ks:0.783228\ttest-auc:0.829001\ttest-ks:0.509991\n",
      "[37]\ttrain-auc:0.959643\ttrain-ks:0.787773\ttest-auc:0.828576\ttest-ks:0.507533\n",
      "[38]\ttrain-auc:0.96099\ttrain-ks:0.791689\ttest-auc:0.827849\ttest-ks:0.504655\n",
      "[39]\ttrain-auc:0.962568\ttrain-ks:0.797478\ttest-auc:0.827278\ttest-ks:0.507303\n",
      "[40]\ttrain-auc:0.964133\ttrain-ks:0.801371\ttest-auc:0.827488\ttest-ks:0.507105\n",
      "[41]\ttrain-auc:0.965185\ttrain-ks:0.804182\ttest-auc:0.827272\ttest-ks:0.505477\n",
      "[42]\ttrain-auc:0.966157\ttrain-ks:0.807887\ttest-auc:0.82769\ttest-ks:0.506933\n",
      "[43]\ttrain-auc:0.967048\ttrain-ks:0.809975\ttest-auc:0.828507\ttest-ks:0.508141\n",
      "[44]\ttrain-auc:0.968456\ttrain-ks:0.813656\ttest-auc:0.828919\ttest-ks:0.508578\n",
      "[45]\ttrain-auc:0.969446\ttrain-ks:0.819252\ttest-auc:0.829571\ttest-ks:0.509341\n",
      "[46]\ttrain-auc:0.970588\ttrain-ks:0.822678\ttest-auc:0.830116\ttest-ks:0.51361\n",
      "[47]\ttrain-auc:0.971587\ttrain-ks:0.82631\ttest-auc:0.83016\ttest-ks:0.512648\n",
      "[48]\ttrain-auc:0.972605\ttrain-ks:0.829613\ttest-auc:0.829678\ttest-ks:0.511314\n",
      "[49]\ttrain-auc:0.973828\ttrain-ks:0.834878\ttest-auc:0.830065\ttest-ks:0.51089\n",
      "[50]\ttrain-auc:0.974975\ttrain-ks:0.8403\ttest-auc:0.830307\ttest-ks:0.509771\n",
      "[51]\ttrain-auc:0.97534\ttrain-ks:0.842424\ttest-auc:0.830029\ttest-ks:0.509775\n",
      "[52]\ttrain-auc:0.976447\ttrain-ks:0.846302\ttest-auc:0.82879\ttest-ks:0.506225\n",
      "[53]\ttrain-auc:0.976994\ttrain-ks:0.848305\ttest-auc:0.828954\ttest-ks:0.50517\n",
      "[54]\ttrain-auc:0.977924\ttrain-ks:0.852356\ttest-auc:0.82882\ttest-ks:0.506692\n",
      "[55]\ttrain-auc:0.978786\ttrain-ks:0.854954\ttest-auc:0.828762\ttest-ks:0.507141\n",
      "[56]\ttrain-auc:0.979659\ttrain-ks:0.858304\ttest-auc:0.829412\ttest-ks:0.510306\n",
      "[57]\ttrain-auc:0.980461\ttrain-ks:0.862887\ttest-auc:0.829709\ttest-ks:0.50739\n",
      "[58]\ttrain-auc:0.98107\ttrain-ks:0.865226\ttest-auc:0.828973\ttest-ks:0.507605\n",
      "[59]\ttrain-auc:0.981987\ttrain-ks:0.868758\ttest-auc:0.829065\ttest-ks:0.509068\n",
      "[60]\ttrain-auc:0.982643\ttrain-ks:0.870721\ttest-auc:0.829247\ttest-ks:0.508458\n",
      "[61]\ttrain-auc:0.983177\ttrain-ks:0.873645\ttest-auc:0.829365\ttest-ks:0.505992\n",
      "[62]\ttrain-auc:0.984065\ttrain-ks:0.877072\ttest-auc:0.830011\ttest-ks:0.508261\n",
      "[63]\ttrain-auc:0.984604\ttrain-ks:0.879627\ttest-auc:0.829515\ttest-ks:0.507888\n",
      "[64]\ttrain-auc:0.985272\ttrain-ks:0.882703\ttest-auc:0.829077\ttest-ks:0.508039\n",
      "[65]\ttrain-auc:0.9859\ttrain-ks:0.885877\ttest-auc:0.829037\ttest-ks:0.508997\n",
      "[66]\ttrain-auc:0.986378\ttrain-ks:0.888796\ttest-auc:0.828895\ttest-ks:0.508093\n",
      "[67]\ttrain-auc:0.987157\ttrain-ks:0.892664\ttest-auc:0.828785\ttest-ks:0.509794\n",
      "[68]\ttrain-auc:0.98768\ttrain-ks:0.895759\ttest-auc:0.829039\ttest-ks:0.510727\n",
      "[69]\ttrain-auc:0.988188\ttrain-ks:0.897932\ttest-auc:0.828995\ttest-ks:0.510314\n",
      "[70]\ttrain-auc:0.988689\ttrain-ks:0.901205\ttest-auc:0.828899\ttest-ks:0.509289\n",
      "[71]\ttrain-auc:0.989225\ttrain-ks:0.903809\ttest-auc:0.828519\ttest-ks:0.510144\n",
      "[72]\ttrain-auc:0.989766\ttrain-ks:0.90675\ttest-auc:0.828058\ttest-ks:0.509898\n",
      "[73]\ttrain-auc:0.990156\ttrain-ks:0.907698\ttest-auc:0.828395\ttest-ks:0.511616\n",
      "[74]\ttrain-auc:0.990613\ttrain-ks:0.910451\ttest-auc:0.82796\ttest-ks:0.507572\n",
      "[75]\ttrain-auc:0.991052\ttrain-ks:0.913462\ttest-auc:0.828343\ttest-ks:0.509374\n",
      "[76]\ttrain-auc:0.991582\ttrain-ks:0.915611\ttest-auc:0.828166\ttest-ks:0.508981\n",
      "[77]\ttrain-auc:0.99209\ttrain-ks:0.917745\ttest-auc:0.827743\ttest-ks:0.509183\n",
      "[78]\ttrain-auc:0.992529\ttrain-ks:0.920355\ttest-auc:0.827243\ttest-ks:0.508172\n",
      "[79]\ttrain-auc:0.992909\ttrain-ks:0.922236\ttest-auc:0.827116\ttest-ks:0.505632\n",
      "[80]\ttrain-auc:0.993174\ttrain-ks:0.924053\ttest-auc:0.827387\ttest-ks:0.505379\n",
      "[81]\ttrain-auc:0.993552\ttrain-ks:0.926329\ttest-auc:0.827639\ttest-ks:0.506463\n",
      "[82]\ttrain-auc:0.993955\ttrain-ks:0.928244\ttest-auc:0.828419\ttest-ks:0.505757\n",
      "[83]\ttrain-auc:0.994243\ttrain-ks:0.929847\ttest-auc:0.827936\ttest-ks:0.506805\n",
      "[84]\ttrain-auc:0.994459\ttrain-ks:0.932376\ttest-auc:0.827927\ttest-ks:0.504569\n",
      "[85]\ttrain-auc:0.994692\ttrain-ks:0.933708\ttest-auc:0.827769\ttest-ks:0.50165\n",
      "[86]\ttrain-auc:0.994886\ttrain-ks:0.934853\ttest-auc:0.827819\ttest-ks:0.502114\n",
      "[87]\ttrain-auc:0.995161\ttrain-ks:0.936731\ttest-auc:0.827617\ttest-ks:0.501211\n",
      "[88]\ttrain-auc:0.995459\ttrain-ks:0.938535\ttest-auc:0.827203\ttest-ks:0.500016\n",
      "[89]\ttrain-auc:0.995686\ttrain-ks:0.940331\ttest-auc:0.827333\ttest-ks:0.49947\n",
      "[90]\ttrain-auc:0.995849\ttrain-ks:0.941617\ttest-auc:0.827891\ttest-ks:0.501785\n",
      "[91]\ttrain-auc:0.996004\ttrain-ks:0.941602\ttest-auc:0.82758\ttest-ks:0.50126\n",
      "[92]\ttrain-auc:0.996223\ttrain-ks:0.944186\ttest-auc:0.826656\ttest-ks:0.501906\n",
      "[93]\ttrain-auc:0.996389\ttrain-ks:0.946057\ttest-auc:0.826665\ttest-ks:0.501592\n",
      "[94]\ttrain-auc:0.996605\ttrain-ks:0.948413\ttest-auc:0.826994\ttest-ks:0.502634\n",
      "[95]\ttrain-auc:0.996786\ttrain-ks:0.94921\ttest-auc:0.827103\ttest-ks:0.502733\n",
      "[96]\ttrain-auc:0.997016\ttrain-ks:0.951479\ttest-auc:0.826701\ttest-ks:0.501116\n",
      "[97]\ttrain-auc:0.997193\ttrain-ks:0.953325\ttest-auc:0.826113\ttest-ks:0.501503\n",
      "[98]\ttrain-auc:0.997325\ttrain-ks:0.954278\ttest-auc:0.8262\ttest-ks:0.499043\n",
      "[99]\ttrain-auc:0.997475\ttrain-ks:0.956053\ttest-auc:0.826808\ttest-ks:0.501259\n",
      "[100]\ttrain-auc:0.99757\ttrain-ks:0.956726\ttest-auc:0.826862\ttest-ks:0.502794\n",
      "[101]\ttrain-auc:0.997672\ttrain-ks:0.957941\ttest-auc:0.826929\ttest-ks:0.499251\n",
      "[102]\ttrain-auc:0.997823\ttrain-ks:0.959143\ttest-auc:0.826776\ttest-ks:0.497169\n",
      "[103]\ttrain-auc:0.997917\ttrain-ks:0.959677\ttest-auc:0.827391\ttest-ks:0.500434\n",
      "[104]\ttrain-auc:0.998054\ttrain-ks:0.961136\ttest-auc:0.827098\ttest-ks:0.500706\n",
      "[105]\ttrain-auc:0.998176\ttrain-ks:0.962336\ttest-auc:0.826795\ttest-ks:0.499784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106]\ttrain-auc:0.998308\ttrain-ks:0.964614\ttest-auc:0.826603\ttest-ks:0.497703\n",
      "[107]\ttrain-auc:0.998439\ttrain-ks:0.965949\ttest-auc:0.826222\ttest-ks:0.499508\n",
      "[108]\ttrain-auc:0.99853\ttrain-ks:0.96634\ttest-auc:0.826275\ttest-ks:0.500965\n",
      "[109]\ttrain-auc:0.998629\ttrain-ks:0.967404\ttest-auc:0.826465\ttest-ks:0.501421\n",
      "[110]\ttrain-auc:0.998725\ttrain-ks:0.968384\ttest-auc:0.826455\ttest-ks:0.501277\n",
      "[111]\ttrain-auc:0.998766\ttrain-ks:0.968726\ttest-auc:0.82664\ttest-ks:0.500594\n",
      "[112]\ttrain-auc:0.998851\ttrain-ks:0.970536\ttest-auc:0.826719\ttest-ks:0.500608\n",
      "[113]\ttrain-auc:0.998913\ttrain-ks:0.971598\ttest-auc:0.826901\ttest-ks:0.500324\n",
      "[114]\ttrain-auc:0.999002\ttrain-ks:0.972679\ttest-auc:0.826583\ttest-ks:0.499342\n",
      "[115]\ttrain-auc:0.999067\ttrain-ks:0.973674\ttest-auc:0.826368\ttest-ks:0.499197\n",
      "[116]\ttrain-auc:0.999144\ttrain-ks:0.97493\ttest-auc:0.82632\ttest-ks:0.502528\n",
      "[117]\ttrain-auc:0.999207\ttrain-ks:0.975947\ttest-auc:0.826206\ttest-ks:0.501606\n",
      "[118]\ttrain-auc:0.999231\ttrain-ks:0.976743\ttest-auc:0.826484\ttest-ks:0.502041\n",
      "[119]\ttrain-auc:0.999277\ttrain-ks:0.977394\ttest-auc:0.826253\ttest-ks:0.501603\n",
      "[120]\ttrain-auc:0.999284\ttrain-ks:0.978127\ttest-auc:0.826629\ttest-ks:0.505413\n",
      "[121]\ttrain-auc:0.999336\ttrain-ks:0.9792\ttest-auc:0.827024\ttest-ks:0.506351\n",
      "[122]\ttrain-auc:0.999398\ttrain-ks:0.979463\ttest-auc:0.827265\ttest-ks:0.50491\n",
      "[123]\ttrain-auc:0.999443\ttrain-ks:0.980661\ttest-auc:0.827529\ttest-ks:0.508193\n",
      "[124]\ttrain-auc:0.999478\ttrain-ks:0.981448\ttest-auc:0.827203\ttest-ks:0.507249\n",
      "[125]\ttrain-auc:0.99953\ttrain-ks:0.9832\ttest-auc:0.827051\ttest-ks:0.505759\n",
      "[126]\ttrain-auc:0.999576\ttrain-ks:0.98393\ttest-auc:0.827314\ttest-ks:0.507751\n",
      "[127]\ttrain-auc:0.999597\ttrain-ks:0.984002\ttest-auc:0.827227\ttest-ks:0.504699\n",
      "[128]\ttrain-auc:0.999611\ttrain-ks:0.984998\ttest-auc:0.827099\ttest-ks:0.504871\n",
      "[129]\ttrain-auc:0.999638\ttrain-ks:0.98553\ttest-auc:0.826927\ttest-ks:0.503409\n",
      "[130]\ttrain-auc:0.999668\ttrain-ks:0.985927\ttest-auc:0.82708\ttest-ks:0.504943\n",
      "[131]\ttrain-auc:0.999682\ttrain-ks:0.986142\ttest-auc:0.827101\ttest-ks:0.503733\n",
      "[132]\ttrain-auc:0.9997\ttrain-ks:0.986532\ttest-auc:0.826883\ttest-ks:0.502627\n",
      "[133]\ttrain-auc:0.999723\ttrain-ks:0.986733\ttest-auc:0.82684\ttest-ks:0.501886\n",
      "[134]\ttrain-auc:0.999741\ttrain-ks:0.9876\ttest-auc:0.826912\ttest-ks:0.503321\n",
      "[135]\ttrain-auc:0.999761\ttrain-ks:0.987869\ttest-auc:0.827922\ttest-ks:0.505234\n",
      "[136]\ttrain-auc:0.999791\ttrain-ks:0.988538\ttest-auc:0.827851\ttest-ks:0.507867\n",
      "[137]\ttrain-auc:0.999807\ttrain-ks:0.989135\ttest-auc:0.82751\ttest-ks:0.505373\n",
      "[138]\ttrain-auc:0.999815\ttrain-ks:0.9892\ttest-auc:0.8279\ttest-ks:0.505413\n",
      "[139]\ttrain-auc:0.999823\ttrain-ks:0.989599\ttest-auc:0.828166\ttest-ks:0.504985\n",
      "[140]\ttrain-auc:0.999829\ttrain-ks:0.989667\ttest-auc:0.828758\ttest-ks:0.504598\n",
      "[141]\ttrain-auc:0.999845\ttrain-ks:0.990536\ttest-auc:0.829244\ttest-ks:0.508232\n",
      "[142]\ttrain-auc:0.999855\ttrain-ks:0.991\ttest-auc:0.82934\ttest-ks:0.507312\n",
      "[143]\ttrain-auc:0.999865\ttrain-ks:0.991268\ttest-auc:0.829511\ttest-ks:0.507703\n",
      "[144]\ttrain-auc:0.99988\ttrain-ks:0.992136\ttest-auc:0.829596\ttest-ks:0.505957\n",
      "[145]\ttrain-auc:0.999891\ttrain-ks:0.993271\ttest-auc:0.829562\ttest-ks:0.506612\n",
      "[146]\ttrain-auc:0.9999\ttrain-ks:0.993204\ttest-auc:0.829516\ttest-ks:0.50698\n",
      "Stopping. Best iteration:\n",
      "[46]\ttrain-auc:0.970588+0.00140071\ttrain-ks:0.822678+0.00741465\ttest-auc:0.830116+0.00998625\ttest-ks:0.51361+0.0239243\n",
      "\n",
      "Best round num:  46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711867</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.524126</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id train_score validate_score test_score learning_rate n_estimators  \\\n",
       "0        0    0.711867       0.524533   0.538377           0.1           50   \n",
       "1        1      0.8214       0.498133   0.524126           0.3           46   \n",
       "\n",
       "  max_depth min_child_weight gamma subsample colsample_bytree reg_alpha  \\\n",
       "0         5                1     0       0.8              0.8         0   \n",
       "1         5                1     0       0.8              0.8         0   \n",
       "\n",
       "  reg_lambda  \n",
       "0          1  \n",
       "1          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step1: tune n_estimators for relatively high learning_rate (eg: 0.1)\n",
    "param_test1 = { 'learning_rate': 0.3, 'n_estimators':1000}\n",
    "tune.params_dict.update(param_test1)\n",
    "tune.model.set_params(**tune.params_dict)\n",
    "tune.xgboost_cv(cv= 5, early_stopping_rounds= 100,n_jobs = 4,seed = 0)\n",
    "tune.dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:42:36.973000Z",
     "start_time": "2018-10-26T04:42:08.167000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: \n",
      "+----+-------------------------------------------+------------------+-----------------+\n",
      "|    |                   params                  | mean_train_score | mean_test_score |\n",
      "+----+-------------------------------------------+------------------+-----------------+\n",
      "| 0  |  {'max_depth': 3, 'min_child_weight': 1}  |  0.595866666667  |  0.458133333333 |\n",
      "| 1  |  {'max_depth': 3, 'min_child_weight': 10} |  0.579733333333  |  0.458666666667 |\n",
      "| 2  |  {'max_depth': 3, 'min_child_weight': 20} |  0.565133333333  |      0.456      |\n",
      "| 3  |  {'max_depth': 3, 'min_child_weight': 50} |  0.538666666667  |      0.4528     |\n",
      "| 4  | {'max_depth': 3, 'min_child_weight': 100} |  0.499733333333  |  0.423466666667 |\n",
      "| 5  |  {'max_depth': 4, 'min_child_weight': 1}  |  0.703533333333  |      0.4776     |\n",
      "| 6  |  {'max_depth': 4, 'min_child_weight': 10} |  0.674133333333  |      0.488      |\n",
      "| 7  |  {'max_depth': 4, 'min_child_weight': 20} |  0.637133333333  |  0.470133333333 |\n",
      "| 8  |  {'max_depth': 4, 'min_child_weight': 50} |      0.581       |  0.464266666667 |\n",
      "| 9  | {'max_depth': 4, 'min_child_weight': 100} |  0.530533333333  |  0.442133333333 |\n",
      "| 10 |  {'max_depth': 5, 'min_child_weight': 1}  |      0.8214      |  0.498133333333 |\n",
      "| 11 |  {'max_depth': 5, 'min_child_weight': 10} |  0.746466666667  |      0.4992     |\n",
      "| 12 |  {'max_depth': 5, 'min_child_weight': 20} |  0.693466666667  |      0.4848     |\n",
      "| 13 |  {'max_depth': 5, 'min_child_weight': 50} |  0.617266666667  |       0.48      |\n",
      "| 14 | {'max_depth': 5, 'min_child_weight': 100} |      0.546       |  0.453333333333 |\n",
      "+----+-------------------------------------------+------------------+-----------------+\n",
      "Best Params: \n",
      "{'max_depth': 5, 'min_child_weight': 10}\n",
      "Best Score: \n",
      "0.4992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711867</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.524126</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id train_score validate_score test_score learning_rate n_estimators  \\\n",
       "0        0    0.711867       0.524533   0.538377           0.1           50   \n",
       "1        1      0.8214       0.498133   0.524126           0.3           46   \n",
       "2        2    0.746467         0.4992   0.506889           0.3           46   \n",
       "3        3    0.746467         0.4992   0.506889           0.3           46   \n",
       "4        4    0.746467         0.4992   0.506889           0.3           46   \n",
       "\n",
       "  max_depth min_child_weight gamma subsample colsample_bytree reg_alpha  \\\n",
       "0         5                1     0       0.8              0.8         0   \n",
       "1         5                1     0       0.8              0.8         0   \n",
       "2         5               10     0       0.8              0.8         0   \n",
       "3         5               10     0       0.8              0.8         0   \n",
       "4         5               10     0       0.8              0.8         0   \n",
       "\n",
       "  reg_lambda  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step2：tune max_depth & min_child_weight \n",
    "param_test2 = { 'max_depth': range(3, 6), 'min_child_weight': [1,10,20,50,100] } \n",
    "best_param = tune.gridsearch_cv(param_test2,n_jobs = 4)\n",
    "tune.dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:43:04.250000Z",
     "start_time": "2018-10-26T04:42:47.455000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: \n",
      "+---+----------------+------------------+-----------------+\n",
      "|   |     params     | mean_train_score | mean_test_score |\n",
      "+---+----------------+------------------+-----------------+\n",
      "| 0 | {'gamma': 0.0} |  0.746466666667  |      0.4992     |\n",
      "| 1 | {'gamma': 0.1} |      0.7514      |  0.499466666667 |\n",
      "| 2 | {'gamma': 0.2} |      0.7498      |  0.494666666667 |\n",
      "| 3 | {'gamma': 0.3} |  0.749466666667  |  0.487466666667 |\n",
      "| 4 | {'gamma': 0.4} |  0.752733333333  |  0.493066666667 |\n",
      "| 5 | {'gamma': 0.5} |  0.752733333333  |  0.494133333333 |\n",
      "+---+----------------+------------------+-----------------+\n",
      "Best Params: \n",
      "{'gamma': 0.1}\n",
      "Best Score: \n",
      "0.4994666666666666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711867</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.524126</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.499467</td>\n",
       "      <td>0.524069</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id train_score validate_score test_score learning_rate n_estimators  \\\n",
       "0        0    0.711867       0.524533   0.538377           0.1           50   \n",
       "1        1      0.8214       0.498133   0.524126           0.3           46   \n",
       "2        2    0.746467         0.4992   0.506889           0.3           46   \n",
       "3        3    0.746467         0.4992   0.506889           0.3           46   \n",
       "4        4    0.746467         0.4992   0.506889           0.3           46   \n",
       "5        5      0.7514       0.499467   0.524069           0.3           46   \n",
       "\n",
       "  max_depth min_child_weight gamma subsample colsample_bytree reg_alpha  \\\n",
       "0         5                1     0       0.8              0.8         0   \n",
       "1         5                1     0       0.8              0.8         0   \n",
       "2         5               10     0       0.8              0.8         0   \n",
       "3         5               10     0       0.8              0.8         0   \n",
       "4         5               10     0       0.8              0.8         0   \n",
       "5         5               10   0.1       0.8              0.8         0   \n",
       "\n",
       "  reg_lambda  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step3：tune gamma\n",
    "param_test3 = {'gamma': [i / 10.0 for i in range(0, 6)]}\n",
    "best_param = tune.gridsearch_cv(param_test3,n_jobs = 4)\n",
    "tune.dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:44:18.807000Z",
     "start_time": "2018-10-26T04:43:27.506000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: \n",
      "+----+---------------------------------------------+------------------+-----------------+\n",
      "|    |                    params                   | mean_train_score | mean_test_score |\n",
      "+----+---------------------------------------------+------------------+-----------------+\n",
      "| 0  | {'subsample': 0.6, 'colsample_bytree': 0.6} |      0.7136      |      0.472      |\n",
      "| 1  | {'subsample': 0.7, 'colsample_bytree': 0.6} |      0.7204      |  0.469333333333 |\n",
      "| 2  | {'subsample': 0.8, 'colsample_bytree': 0.6} |      0.7344      |  0.490666666667 |\n",
      "| 3  | {'subsample': 0.9, 'colsample_bytree': 0.6} |  0.752666666667  |      0.5048     |\n",
      "| 4  | {'subsample': 1.0, 'colsample_bytree': 0.6} |  0.753533333333  |  0.509866666667 |\n",
      "| 5  | {'subsample': 0.6, 'colsample_bytree': 0.7} |      0.7044      |  0.462933333333 |\n",
      "| 6  | {'subsample': 0.7, 'colsample_bytree': 0.7} |      0.7288      |      0.4776     |\n",
      "| 7  | {'subsample': 0.8, 'colsample_bytree': 0.7} |  0.739533333333  |  0.490933333333 |\n",
      "| 8  | {'subsample': 0.9, 'colsample_bytree': 0.7} |  0.748933333333  |  0.502933333333 |\n",
      "| 9  | {'subsample': 1.0, 'colsample_bytree': 0.7} |  0.764266666667  |      0.508      |\n",
      "| 10 | {'subsample': 0.6, 'colsample_bytree': 0.8} |      0.7162      |  0.475466666667 |\n",
      "| 11 | {'subsample': 0.7, 'colsample_bytree': 0.8} |  0.743466666667  |      0.4864     |\n",
      "| 12 | {'subsample': 0.8, 'colsample_bytree': 0.8} |      0.7514      |  0.499466666667 |\n",
      "| 13 | {'subsample': 0.9, 'colsample_bytree': 0.8} |  0.758866666667  |  0.509866666667 |\n",
      "| 14 | {'subsample': 1.0, 'colsample_bytree': 0.8} |  0.764466666667  |      0.5088     |\n",
      "| 15 | {'subsample': 0.6, 'colsample_bytree': 0.9} |  0.720266666667  |      0.484      |\n",
      "| 16 | {'subsample': 0.7, 'colsample_bytree': 0.9} |      0.7412      |  0.502666666667 |\n",
      "| 17 | {'subsample': 0.8, 'colsample_bytree': 0.9} |  0.757466666667  |      0.4904     |\n",
      "| 18 | {'subsample': 0.9, 'colsample_bytree': 0.9} |      0.7586      |  0.507466666667 |\n",
      "| 19 | {'subsample': 1.0, 'colsample_bytree': 0.9} |  0.766666666667  |  0.505066666667 |\n",
      "| 20 | {'subsample': 0.6, 'colsample_bytree': 1.0} |  0.732333333333  |      0.4848     |\n",
      "| 21 | {'subsample': 0.7, 'colsample_bytree': 1.0} |  0.751066666667  |      0.4872     |\n",
      "| 22 | {'subsample': 0.8, 'colsample_bytree': 1.0} |      0.7554      |  0.502133333333 |\n",
      "| 23 | {'subsample': 0.9, 'colsample_bytree': 1.0} |      0.7674      |  0.510933333333 |\n",
      "| 24 | {'subsample': 1.0, 'colsample_bytree': 1.0} |  0.766666666667  |      0.508      |\n",
      "+----+---------------------------------------------+------------------+-----------------+\n",
      "Best Params: \n",
      "{'subsample': 0.9, 'colsample_bytree': 1.0}\n",
      "Best Score: \n",
      "0.5109333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711867</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.524126</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.499467</td>\n",
       "      <td>0.524069</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.510933</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id train_score validate_score test_score learning_rate n_estimators  \\\n",
       "0        0    0.711867       0.524533   0.538377           0.1           50   \n",
       "1        1      0.8214       0.498133   0.524126           0.3           46   \n",
       "2        2    0.746467         0.4992   0.506889           0.3           46   \n",
       "3        3    0.746467         0.4992   0.506889           0.3           46   \n",
       "4        4    0.746467         0.4992   0.506889           0.3           46   \n",
       "5        5      0.7514       0.499467   0.524069           0.3           46   \n",
       "6        6      0.7674       0.510933   0.543003           0.3           46   \n",
       "\n",
       "  max_depth min_child_weight gamma subsample colsample_bytree reg_alpha  \\\n",
       "0         5                1     0       0.8              0.8         0   \n",
       "1         5                1     0       0.8              0.8         0   \n",
       "2         5               10     0       0.8              0.8         0   \n",
       "3         5               10     0       0.8              0.8         0   \n",
       "4         5               10     0       0.8              0.8         0   \n",
       "5         5               10   0.1       0.8              0.8         0   \n",
       "6         5               10   0.1       0.9                1         0   \n",
       "\n",
       "  reg_lambda  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step4：tune subsample & colsample_bytree \n",
    "param_test4 = { 'subsample': [i / 10.0 for i in range(6, 11)],\n",
    "               'colsample_bytree': [i / 10.0 for i in range(6, 11)] } \n",
    "best_param = tune.gridsearch_cv(param_test4,n_jobs = 4)\n",
    "tune.dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:45:45.159000Z",
     "start_time": "2018-10-26T04:45:20.830000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: \n",
      "+---+----------------------+------------------+-----------------+\n",
      "|   |        params        | mean_train_score | mean_test_score |\n",
      "+---+----------------------+------------------+-----------------+\n",
      "| 0 | {'reg_alpha': 1e-05} |      0.7674      |  0.510933333333 |\n",
      "| 1 | {'reg_alpha': 0.01}  |  0.766733333333  |      0.5104     |\n",
      "| 2 |  {'reg_alpha': 0.1}  |  0.759066666667  |      0.4992     |\n",
      "| 3 |   {'reg_alpha': 1}   |  0.777066666667  |  0.531733333333 |\n",
      "| 4 |  {'reg_alpha': 10}   |  0.703866666667  |  0.525866666667 |\n",
      "| 5 |  {'reg_alpha': 100}  |      0.3606      |  0.335733333333 |\n",
      "+---+----------------------+------------------+-----------------+\n",
      "Best Params: \n",
      "{'reg_alpha': 1}\n",
      "Best Score: \n",
      "0.5317333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711867</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.524126</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.499467</td>\n",
       "      <td>0.524069</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.510933</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.531733</td>\n",
       "      <td>0.537952</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.531733</td>\n",
       "      <td>0.537952</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id train_score validate_score test_score learning_rate n_estimators  \\\n",
       "0        0    0.711867       0.524533   0.538377           0.1           50   \n",
       "1        1      0.8214       0.498133   0.524126           0.3           46   \n",
       "2        2    0.746467         0.4992   0.506889           0.3           46   \n",
       "3        3    0.746467         0.4992   0.506889           0.3           46   \n",
       "4        4    0.746467         0.4992   0.506889           0.3           46   \n",
       "5        5      0.7514       0.499467   0.524069           0.3           46   \n",
       "6        6      0.7674       0.510933   0.543003           0.3           46   \n",
       "7        7    0.777067       0.531733   0.537952           0.3           46   \n",
       "8        8    0.777067       0.531733   0.537952           0.3           46   \n",
       "\n",
       "  max_depth min_child_weight gamma subsample colsample_bytree reg_alpha  \\\n",
       "0         5                1     0       0.8              0.8         0   \n",
       "1         5                1     0       0.8              0.8         0   \n",
       "2         5               10     0       0.8              0.8         0   \n",
       "3         5               10     0       0.8              0.8         0   \n",
       "4         5               10     0       0.8              0.8         0   \n",
       "5         5               10   0.1       0.8              0.8         0   \n",
       "6         5               10   0.1       0.9                1         0   \n",
       "7         5               10   0.1       0.9                1         1   \n",
       "8         5               10   0.1       0.9                1         1   \n",
       "\n",
       "  reg_lambda  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  \n",
       "8          1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step5: tune reg_alpha \n",
    "param_test5 = { 'reg_alpha': [1e-5, 1e-2, 0.1, 1,10,100] } \n",
    "best_param = tune.gridsearch_cv(param_test5,n_jobs = 4)\n",
    "tune.dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T04:46:17.647000Z",
     "start_time": "2018-10-26T04:45:59.762000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results: \n",
      "+---+-----------------------+------------------+-----------------+\n",
      "|   |         params        | mean_train_score | mean_test_score |\n",
      "+---+-----------------------+------------------+-----------------+\n",
      "| 0 | {'reg_lambda': 1e-05} |      0.777       |      0.5032     |\n",
      "| 1 |  {'reg_lambda': 0.01} |  0.776133333333  |      0.5064     |\n",
      "| 2 |  {'reg_lambda': 0.1}  |      0.775       |  0.506933333333 |\n",
      "| 3 |   {'reg_lambda': 1}   |  0.777066666667  |  0.531733333333 |\n",
      "| 4 |   {'reg_lambda': 10}  |  0.741666666667  |  0.518666666667 |\n",
      "| 5 |  {'reg_lambda': 100}  |  0.654866666667  |  0.511733333333 |\n",
      "+---+-----------------------+------------------+-----------------+\n",
      "Best Params: \n",
      "{'reg_lambda': 1}\n",
      "Best Score: \n",
      "0.5317333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711867</td>\n",
       "      <td>0.524533</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.524126</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.499467</td>\n",
       "      <td>0.524069</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.510933</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.531733</td>\n",
       "      <td>0.537952</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.531733</td>\n",
       "      <td>0.537952</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.777067</td>\n",
       "      <td>0.531733</td>\n",
       "      <td>0.537952</td>\n",
       "      <td>0.3</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id train_score validate_score test_score learning_rate n_estimators  \\\n",
       "0        0    0.711867       0.524533   0.538377           0.1           50   \n",
       "1        1      0.8214       0.498133   0.524126           0.3           46   \n",
       "2        2    0.746467         0.4992   0.506889           0.3           46   \n",
       "3        3    0.746467         0.4992   0.506889           0.3           46   \n",
       "4        4    0.746467         0.4992   0.506889           0.3           46   \n",
       "5        5      0.7514       0.499467   0.524069           0.3           46   \n",
       "6        6      0.7674       0.510933   0.543003           0.3           46   \n",
       "7        7    0.777067       0.531733   0.537952           0.3           46   \n",
       "8        8    0.777067       0.531733   0.537952           0.3           46   \n",
       "9        9    0.777067       0.531733   0.537952           0.3           46   \n",
       "\n",
       "  max_depth min_child_weight gamma subsample colsample_bytree reg_alpha  \\\n",
       "0         5                1     0       0.8              0.8         0   \n",
       "1         5                1     0       0.8              0.8         0   \n",
       "2         5               10     0       0.8              0.8         0   \n",
       "3         5               10     0       0.8              0.8         0   \n",
       "4         5               10     0       0.8              0.8         0   \n",
       "5         5               10   0.1       0.8              0.8         0   \n",
       "6         5               10   0.1       0.9                1         0   \n",
       "7         5               10   0.1       0.9                1         1   \n",
       "8         5               10   0.1       0.9                1         1   \n",
       "9         5               10   0.1       0.9                1         1   \n",
       "\n",
       "  reg_lambda  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  \n",
       "7          1  \n",
       "8          1  \n",
       "9          1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step6: tune reg_lambda \n",
    "param_test6 = { 'reg_lambda': [1e-5, 1e-2, 0.1, 1,10,100] }\n",
    "best_param = tune.gridsearch_cv(param_test6,n_jobs = 4)\n",
    "tune.dfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-26T04:46:45.232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.778448\ttrain-ks:0.410749\ttest-auc:0.743775\ttest-ks:0.369227\n",
      "Multiple eval metrics have been passed: 'test-ks' will be used for early stopping.\n",
      "\n",
      "Will train until test-ks hasn't improved in 100 rounds.\n",
      "[1]\ttrain-auc:0.793301\ttrain-ks:0.434408\ttest-auc:0.760236\ttest-ks:0.383839\n",
      "[2]\ttrain-auc:0.797672\ttrain-ks:0.449583\ttest-auc:0.765614\ttest-ks:0.400716\n",
      "[3]\ttrain-auc:0.802649\ttrain-ks:0.457103\ttest-auc:0.771631\ttest-ks:0.411271\n",
      "[4]\ttrain-auc:0.805567\ttrain-ks:0.459226\ttest-auc:0.773887\ttest-ks:0.415588\n",
      "[5]\ttrain-auc:0.809329\ttrain-ks:0.467562\ttest-auc:0.777389\ttest-ks:0.423882\n",
      "[6]\ttrain-auc:0.812722\ttrain-ks:0.472734\ttest-auc:0.780796\ttest-ks:0.42692\n",
      "[7]\ttrain-auc:0.813672\ttrain-ks:0.476692\ttest-auc:0.781283\ttest-ks:0.426884\n",
      "[8]\ttrain-auc:0.814211\ttrain-ks:0.475902\ttest-auc:0.781616\ttest-ks:0.432436\n",
      "[9]\ttrain-auc:0.814063\ttrain-ks:0.476714\ttest-auc:0.780347\ttest-ks:0.428695\n",
      "[10]\ttrain-auc:0.814979\ttrain-ks:0.477943\ttest-auc:0.780269\ttest-ks:0.43131\n",
      "[11]\ttrain-auc:0.816292\ttrain-ks:0.481182\ttest-auc:0.781583\ttest-ks:0.434703\n",
      "[12]\ttrain-auc:0.817608\ttrain-ks:0.481253\ttest-auc:0.782559\ttest-ks:0.433408\n",
      "[13]\ttrain-auc:0.819029\ttrain-ks:0.48407\ttest-auc:0.783737\ttest-ks:0.431323\n",
      "[14]\ttrain-auc:0.819727\ttrain-ks:0.485191\ttest-auc:0.784155\ttest-ks:0.430846\n",
      "[15]\ttrain-auc:0.819928\ttrain-ks:0.485329\ttest-auc:0.784691\ttest-ks:0.431393\n",
      "[16]\ttrain-auc:0.820996\ttrain-ks:0.486821\ttest-auc:0.78544\ttest-ks:0.435869\n",
      "[17]\ttrain-auc:0.821697\ttrain-ks:0.491148\ttest-auc:0.786391\ttest-ks:0.437367\n",
      "[18]\ttrain-auc:0.822031\ttrain-ks:0.489719\ttest-auc:0.786416\ttest-ks:0.438549\n",
      "[19]\ttrain-auc:0.822577\ttrain-ks:0.491475\ttest-auc:0.786622\ttest-ks:0.43965\n",
      "[20]\ttrain-auc:0.823104\ttrain-ks:0.490581\ttest-auc:0.78746\ttest-ks:0.440762\n",
      "[21]\ttrain-auc:0.823116\ttrain-ks:0.491882\ttest-auc:0.78735\ttest-ks:0.43876\n",
      "[22]\ttrain-auc:0.823128\ttrain-ks:0.493803\ttest-auc:0.787286\ttest-ks:0.438753\n",
      "[23]\ttrain-auc:0.823858\ttrain-ks:0.493127\ttest-auc:0.787992\ttest-ks:0.441421\n",
      "[24]\ttrain-auc:0.824201\ttrain-ks:0.492287\ttest-auc:0.788191\ttest-ks:0.440879\n",
      "[25]\ttrain-auc:0.824808\ttrain-ks:0.493781\ttest-auc:0.788957\ttest-ks:0.441197\n",
      "[26]\ttrain-auc:0.825075\ttrain-ks:0.494377\ttest-auc:0.789151\ttest-ks:0.443634\n",
      "[27]\ttrain-auc:0.825216\ttrain-ks:0.494895\ttest-auc:0.789628\ttest-ks:0.443243\n",
      "[28]\ttrain-auc:0.8256\ttrain-ks:0.494846\ttest-auc:0.789931\ttest-ks:0.444164\n",
      "[29]\ttrain-auc:0.825971\ttrain-ks:0.494807\ttest-auc:0.790271\ttest-ks:0.443851\n",
      "[30]\ttrain-auc:0.826184\ttrain-ks:0.495249\ttest-auc:0.79029\ttest-ks:0.443516\n",
      "[31]\ttrain-auc:0.826816\ttrain-ks:0.49636\ttest-auc:0.790825\ttest-ks:0.443742\n",
      "[32]\ttrain-auc:0.826997\ttrain-ks:0.497178\ttest-auc:0.791058\ttest-ks:0.443649\n",
      "[33]\ttrain-auc:0.827435\ttrain-ks:0.497036\ttest-auc:0.791337\ttest-ks:0.445007\n",
      "[34]\ttrain-auc:0.828012\ttrain-ks:0.497234\ttest-auc:0.791619\ttest-ks:0.442834\n",
      "[35]\ttrain-auc:0.828164\ttrain-ks:0.497746\ttest-auc:0.791461\ttest-ks:0.442217\n",
      "[36]\ttrain-auc:0.828528\ttrain-ks:0.498691\ttest-auc:0.791772\ttest-ks:0.445602\n",
      "[37]\ttrain-auc:0.828681\ttrain-ks:0.499309\ttest-auc:0.791917\ttest-ks:0.445093\n",
      "[38]\ttrain-auc:0.829461\ttrain-ks:0.50045\ttest-auc:0.792451\ttest-ks:0.446125\n",
      "[39]\ttrain-auc:0.830051\ttrain-ks:0.50068\ttest-auc:0.793137\ttest-ks:0.447887\n",
      "[40]\ttrain-auc:0.830469\ttrain-ks:0.501611\ttest-auc:0.793439\ttest-ks:0.447993\n",
      "[41]\ttrain-auc:0.830741\ttrain-ks:0.502796\ttest-auc:0.79364\ttest-ks:0.448434\n",
      "[42]\ttrain-auc:0.831172\ttrain-ks:0.503206\ttest-auc:0.793957\ttest-ks:0.448454\n",
      "[43]\ttrain-auc:0.831407\ttrain-ks:0.502403\ttest-auc:0.794059\ttest-ks:0.448722\n",
      "[44]\ttrain-auc:0.83215\ttrain-ks:0.50313\ttest-auc:0.794815\ttest-ks:0.449006\n",
      "[45]\ttrain-auc:0.832599\ttrain-ks:0.502936\ttest-auc:0.795189\ttest-ks:0.448204\n",
      "[46]\ttrain-auc:0.833281\ttrain-ks:0.503766\ttest-auc:0.795641\ttest-ks:0.450595\n",
      "[47]\ttrain-auc:0.833737\ttrain-ks:0.503686\ttest-auc:0.795962\ttest-ks:0.449948\n",
      "[48]\ttrain-auc:0.834039\ttrain-ks:0.504547\ttest-auc:0.796035\ttest-ks:0.4505\n",
      "[49]\ttrain-auc:0.834532\ttrain-ks:0.504985\ttest-auc:0.79627\ttest-ks:0.450982\n",
      "[50]\ttrain-auc:0.834775\ttrain-ks:0.504493\ttest-auc:0.796352\ttest-ks:0.449857\n",
      "[51]\ttrain-auc:0.835471\ttrain-ks:0.505299\ttest-auc:0.796829\ttest-ks:0.451973\n",
      "[52]\ttrain-auc:0.836034\ttrain-ks:0.506855\ttest-auc:0.797276\ttest-ks:0.453475\n",
      "[53]\ttrain-auc:0.836223\ttrain-ks:0.507721\ttest-auc:0.797312\ttest-ks:0.452873\n",
      "[54]\ttrain-auc:0.836833\ttrain-ks:0.509275\ttest-auc:0.797831\ttest-ks:0.453443\n",
      "[55]\ttrain-auc:0.837315\ttrain-ks:0.509683\ttest-auc:0.798291\ttest-ks:0.452253\n",
      "[56]\ttrain-auc:0.837601\ttrain-ks:0.509995\ttest-auc:0.798553\ttest-ks:0.453446\n",
      "[57]\ttrain-auc:0.837741\ttrain-ks:0.510306\ttest-auc:0.798602\ttest-ks:0.452872\n",
      "[58]\ttrain-auc:0.838374\ttrain-ks:0.510637\ttest-auc:0.798982\ttest-ks:0.454522\n",
      "[59]\ttrain-auc:0.838825\ttrain-ks:0.511491\ttest-auc:0.799288\ttest-ks:0.455184\n",
      "[60]\ttrain-auc:0.839235\ttrain-ks:0.512621\ttest-auc:0.799556\ttest-ks:0.456024\n",
      "[61]\ttrain-auc:0.839563\ttrain-ks:0.513217\ttest-auc:0.79975\ttest-ks:0.456057\n",
      "[62]\ttrain-auc:0.83996\ttrain-ks:0.513268\ttest-auc:0.800168\ttest-ks:0.455506\n",
      "[63]\ttrain-auc:0.840234\ttrain-ks:0.514443\ttest-auc:0.800468\ttest-ks:0.456317\n",
      "[64]\ttrain-auc:0.840752\ttrain-ks:0.514924\ttest-auc:0.800862\ttest-ks:0.456532\n",
      "[65]\ttrain-auc:0.841183\ttrain-ks:0.515334\ttest-auc:0.801049\ttest-ks:0.457897\n",
      "[66]\ttrain-auc:0.841642\ttrain-ks:0.516135\ttest-auc:0.801094\ttest-ks:0.458272\n",
      "[67]\ttrain-auc:0.84201\ttrain-ks:0.517076\ttest-auc:0.801358\ttest-ks:0.457586\n",
      "[68]\ttrain-auc:0.842512\ttrain-ks:0.517869\ttest-auc:0.80177\ttest-ks:0.457741\n",
      "[69]\ttrain-auc:0.842923\ttrain-ks:0.518457\ttest-auc:0.801999\ttest-ks:0.458599\n",
      "[70]\ttrain-auc:0.84317\ttrain-ks:0.518842\ttest-auc:0.802166\ttest-ks:0.458978\n",
      "[71]\ttrain-auc:0.843402\ttrain-ks:0.519302\ttest-auc:0.802246\ttest-ks:0.460608\n",
      "[72]\ttrain-auc:0.843672\ttrain-ks:0.5197\ttest-auc:0.802318\ttest-ks:0.459419\n",
      "[73]\ttrain-auc:0.844039\ttrain-ks:0.520625\ttest-auc:0.802491\ttest-ks:0.459285\n",
      "[74]\ttrain-auc:0.844387\ttrain-ks:0.520655\ttest-auc:0.802777\ttest-ks:0.459758\n",
      "[75]\ttrain-auc:0.844695\ttrain-ks:0.521409\ttest-auc:0.802959\ttest-ks:0.45979\n",
      "[76]\ttrain-auc:0.845246\ttrain-ks:0.522258\ttest-auc:0.803399\ttest-ks:0.46173\n",
      "[77]\ttrain-auc:0.845564\ttrain-ks:0.523708\ttest-auc:0.803515\ttest-ks:0.46202\n",
      "[78]\ttrain-auc:0.845793\ttrain-ks:0.523259\ttest-auc:0.803715\ttest-ks:0.462007\n",
      "[79]\ttrain-auc:0.846286\ttrain-ks:0.524104\ttest-auc:0.804155\ttest-ks:0.461767\n",
      "[80]\ttrain-auc:0.846811\ttrain-ks:0.525175\ttest-auc:0.804599\ttest-ks:0.462731\n",
      "[81]\ttrain-auc:0.847121\ttrain-ks:0.525505\ttest-auc:0.804714\ttest-ks:0.463258\n",
      "[82]\ttrain-auc:0.847358\ttrain-ks:0.525589\ttest-auc:0.804945\ttest-ks:0.464461\n",
      "[83]\ttrain-auc:0.847674\ttrain-ks:0.526365\ttest-auc:0.805076\ttest-ks:0.464205\n",
      "[84]\ttrain-auc:0.848016\ttrain-ks:0.526304\ttest-auc:0.805253\ttest-ks:0.464708\n",
      "[85]\ttrain-auc:0.848223\ttrain-ks:0.527039\ttest-auc:0.805358\ttest-ks:0.463686\n",
      "[86]\ttrain-auc:0.848685\ttrain-ks:0.527763\ttest-auc:0.805565\ttest-ks:0.464195\n",
      "[87]\ttrain-auc:0.84893\ttrain-ks:0.528824\ttest-auc:0.805756\ttest-ks:0.464343\n",
      "[88]\ttrain-auc:0.849238\ttrain-ks:0.528894\ttest-auc:0.805943\ttest-ks:0.464648\n",
      "[89]\ttrain-auc:0.84957\ttrain-ks:0.5294\ttest-auc:0.806124\ttest-ks:0.464828\n",
      "[90]\ttrain-auc:0.849947\ttrain-ks:0.529731\ttest-auc:0.806337\ttest-ks:0.464731\n",
      "[91]\ttrain-auc:0.850402\ttrain-ks:0.530374\ttest-auc:0.806672\ttest-ks:0.464385\n",
      "[92]\ttrain-auc:0.850733\ttrain-ks:0.531048\ttest-auc:0.806949\ttest-ks:0.464646\n",
      "[93]\ttrain-auc:0.851038\ttrain-ks:0.531978\ttest-auc:0.80713\ttest-ks:0.465371\n",
      "[94]\ttrain-auc:0.851508\ttrain-ks:0.532504\ttest-auc:0.807518\ttest-ks:0.46562\n",
      "[95]\ttrain-auc:0.851913\ttrain-ks:0.533061\ttest-auc:0.807898\ttest-ks:0.467183\n",
      "[96]\ttrain-auc:0.852409\ttrain-ks:0.533789\ttest-auc:0.808324\ttest-ks:0.467277\n",
      "[97]\ttrain-auc:0.852792\ttrain-ks:0.534647\ttest-auc:0.808669\ttest-ks:0.468674\n",
      "[98]\ttrain-auc:0.853071\ttrain-ks:0.535096\ttest-auc:0.808831\ttest-ks:0.467326\n",
      "[99]\ttrain-auc:0.853395\ttrain-ks:0.535646\ttest-auc:0.809027\ttest-ks:0.467559\n",
      "[100]\ttrain-auc:0.853625\ttrain-ks:0.53639\ttest-auc:0.809207\ttest-ks:0.467749\n",
      "[101]\ttrain-auc:0.85399\ttrain-ks:0.53685\ttest-auc:0.809449\ttest-ks:0.46917\n",
      "[102]\ttrain-auc:0.854241\ttrain-ks:0.537656\ttest-auc:0.809593\ttest-ks:0.468419\n",
      "[103]\ttrain-auc:0.854626\ttrain-ks:0.537711\ttest-auc:0.809875\ttest-ks:0.469236\n",
      "[104]\ttrain-auc:0.85484\ttrain-ks:0.538378\ttest-auc:0.810072\ttest-ks:0.46953\n",
      "[105]\ttrain-auc:0.855102\ttrain-ks:0.538843\ttest-auc:0.810228\ttest-ks:0.46904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106]\ttrain-auc:0.85543\ttrain-ks:0.539545\ttest-auc:0.810552\ttest-ks:0.470361\n",
      "[107]\ttrain-auc:0.855699\ttrain-ks:0.540127\ttest-auc:0.810619\ttest-ks:0.470587\n",
      "[108]\ttrain-auc:0.856104\ttrain-ks:0.540858\ttest-auc:0.810984\ttest-ks:0.471464\n",
      "[109]\ttrain-auc:0.856355\ttrain-ks:0.541059\ttest-auc:0.811094\ttest-ks:0.471448\n",
      "[110]\ttrain-auc:0.85679\ttrain-ks:0.541987\ttest-auc:0.811449\ttest-ks:0.472046\n",
      "[111]\ttrain-auc:0.857258\ttrain-ks:0.543114\ttest-auc:0.811741\ttest-ks:0.471728\n",
      "[112]\ttrain-auc:0.857497\ttrain-ks:0.543648\ttest-auc:0.811951\ttest-ks:0.472007\n",
      "[113]\ttrain-auc:0.857828\ttrain-ks:0.543985\ttest-auc:0.812298\ttest-ks:0.472286\n",
      "[114]\ttrain-auc:0.858212\ttrain-ks:0.543982\ttest-auc:0.812615\ttest-ks:0.472421\n",
      "[115]\ttrain-auc:0.858392\ttrain-ks:0.544064\ttest-auc:0.81265\ttest-ks:0.47378\n",
      "[116]\ttrain-auc:0.858837\ttrain-ks:0.544973\ttest-auc:0.813192\ttest-ks:0.473476\n",
      "[117]\ttrain-auc:0.859217\ttrain-ks:0.54578\ttest-auc:0.813529\ttest-ks:0.474268\n",
      "[118]\ttrain-auc:0.859516\ttrain-ks:0.54642\ttest-auc:0.813738\ttest-ks:0.474737\n",
      "[119]\ttrain-auc:0.859687\ttrain-ks:0.54714\ttest-auc:0.813817\ttest-ks:0.474793\n",
      "[120]\ttrain-auc:0.860094\ttrain-ks:0.547571\ttest-auc:0.814238\ttest-ks:0.476692\n",
      "[121]\ttrain-auc:0.860282\ttrain-ks:0.548573\ttest-auc:0.814337\ttest-ks:0.475964\n",
      "[122]\ttrain-auc:0.860823\ttrain-ks:0.549306\ttest-auc:0.814672\ttest-ks:0.47733\n",
      "[123]\ttrain-auc:0.861208\ttrain-ks:0.550395\ttest-auc:0.814966\ttest-ks:0.478613\n",
      "[124]\ttrain-auc:0.861626\ttrain-ks:0.551504\ttest-auc:0.815256\ttest-ks:0.479216\n",
      "[125]\ttrain-auc:0.861846\ttrain-ks:0.552076\ttest-auc:0.815432\ttest-ks:0.479753\n",
      "[126]\ttrain-auc:0.86214\ttrain-ks:0.552357\ttest-auc:0.815589\ttest-ks:0.480021\n",
      "[127]\ttrain-auc:0.862348\ttrain-ks:0.553034\ttest-auc:0.815619\ttest-ks:0.480942\n",
      "[128]\ttrain-auc:0.862563\ttrain-ks:0.553244\ttest-auc:0.815667\ttest-ks:0.480165\n",
      "[129]\ttrain-auc:0.862703\ttrain-ks:0.553114\ttest-auc:0.815778\ttest-ks:0.480704\n",
      "[130]\ttrain-auc:0.862908\ttrain-ks:0.553912\ttest-auc:0.815844\ttest-ks:0.481198\n",
      "[131]\ttrain-auc:0.863332\ttrain-ks:0.555124\ttest-auc:0.816155\ttest-ks:0.481755\n",
      "[132]\ttrain-auc:0.863523\ttrain-ks:0.555137\ttest-auc:0.816225\ttest-ks:0.482024\n",
      "[133]\ttrain-auc:0.863816\ttrain-ks:0.555932\ttest-auc:0.816364\ttest-ks:0.483042\n",
      "[134]\ttrain-auc:0.864059\ttrain-ks:0.556207\ttest-auc:0.816414\ttest-ks:0.483565\n",
      "[135]\ttrain-auc:0.864336\ttrain-ks:0.5567\ttest-auc:0.816619\ttest-ks:0.483021\n",
      "[136]\ttrain-auc:0.86463\ttrain-ks:0.556658\ttest-auc:0.816822\ttest-ks:0.482797\n",
      "[137]\ttrain-auc:0.865034\ttrain-ks:0.557435\ttest-auc:0.817145\ttest-ks:0.483814\n",
      "[138]\ttrain-auc:0.865325\ttrain-ks:0.558031\ttest-auc:0.817391\ttest-ks:0.483845\n",
      "[139]\ttrain-auc:0.86559\ttrain-ks:0.558145\ttest-auc:0.817574\ttest-ks:0.484072\n",
      "[140]\ttrain-auc:0.865967\ttrain-ks:0.55926\ttest-auc:0.817912\ttest-ks:0.484072\n",
      "[141]\ttrain-auc:0.866227\ttrain-ks:0.560268\ttest-auc:0.81808\ttest-ks:0.485095\n",
      "[142]\ttrain-auc:0.866526\ttrain-ks:0.560576\ttest-auc:0.818396\ttest-ks:0.484894\n",
      "[143]\ttrain-auc:0.86684\ttrain-ks:0.561408\ttest-auc:0.818735\ttest-ks:0.484546\n",
      "[144]\ttrain-auc:0.867173\ttrain-ks:0.562202\ttest-auc:0.818992\ttest-ks:0.485359\n",
      "[145]\ttrain-auc:0.867511\ttrain-ks:0.562538\ttest-auc:0.819221\ttest-ks:0.485686\n",
      "[146]\ttrain-auc:0.867724\ttrain-ks:0.563546\ttest-auc:0.819415\ttest-ks:0.485525\n",
      "[147]\ttrain-auc:0.867857\ttrain-ks:0.563209\ttest-auc:0.819386\ttest-ks:0.485606\n",
      "[148]\ttrain-auc:0.868146\ttrain-ks:0.563974\ttest-auc:0.819562\ttest-ks:0.484764\n",
      "[149]\ttrain-auc:0.868367\ttrain-ks:0.564437\ttest-auc:0.8197\ttest-ks:0.485667\n",
      "[150]\ttrain-auc:0.868574\ttrain-ks:0.565418\ttest-auc:0.819836\ttest-ks:0.4861\n",
      "[151]\ttrain-auc:0.868697\ttrain-ks:0.565508\ttest-auc:0.819885\ttest-ks:0.485837\n",
      "[152]\ttrain-auc:0.868932\ttrain-ks:0.566241\ttest-auc:0.820072\ttest-ks:0.487398\n",
      "[153]\ttrain-auc:0.869157\ttrain-ks:0.565576\ttest-auc:0.820236\ttest-ks:0.486906\n",
      "[154]\ttrain-auc:0.869376\ttrain-ks:0.566119\ttest-auc:0.820334\ttest-ks:0.487184\n",
      "[155]\ttrain-auc:0.869525\ttrain-ks:0.566309\ttest-auc:0.820452\ttest-ks:0.488217\n",
      "[156]\ttrain-auc:0.869831\ttrain-ks:0.56717\ttest-auc:0.820658\ttest-ks:0.488217\n",
      "[157]\ttrain-auc:0.870036\ttrain-ks:0.567374\ttest-auc:0.820731\ttest-ks:0.486897\n",
      "[158]\ttrain-auc:0.870261\ttrain-ks:0.567711\ttest-auc:0.820878\ttest-ks:0.487426\n",
      "[159]\ttrain-auc:0.870399\ttrain-ks:0.567706\ttest-auc:0.82095\ttest-ks:0.487424\n",
      "[160]\ttrain-auc:0.870611\ttrain-ks:0.567842\ttest-auc:0.820989\ttest-ks:0.486479\n",
      "[161]\ttrain-auc:0.870872\ttrain-ks:0.568775\ttest-auc:0.821147\ttest-ks:0.487281\n",
      "[162]\ttrain-auc:0.871075\ttrain-ks:0.569308\ttest-auc:0.821349\ttest-ks:0.487529\n",
      "[163]\ttrain-auc:0.871343\ttrain-ks:0.569775\ttest-auc:0.821436\ttest-ks:0.487337\n",
      "[164]\ttrain-auc:0.871679\ttrain-ks:0.57071\ttest-auc:0.821705\ttest-ks:0.489468\n",
      "[165]\ttrain-auc:0.871917\ttrain-ks:0.571239\ttest-auc:0.821879\ttest-ks:0.488912\n",
      "[166]\ttrain-auc:0.872118\ttrain-ks:0.572184\ttest-auc:0.822084\ttest-ks:0.48896\n",
      "[167]\ttrain-auc:0.872282\ttrain-ks:0.572247\ttest-auc:0.822201\ttest-ks:0.488379\n",
      "[168]\ttrain-auc:0.872622\ttrain-ks:0.57311\ttest-auc:0.82244\ttest-ks:0.489632\n",
      "[169]\ttrain-auc:0.872884\ttrain-ks:0.573644\ttest-auc:0.822635\ttest-ks:0.490758\n",
      "[170]\ttrain-auc:0.873192\ttrain-ks:0.574188\ttest-auc:0.822795\ttest-ks:0.491594\n",
      "[171]\ttrain-auc:0.873331\ttrain-ks:0.57464\ttest-auc:0.822873\ttest-ks:0.491588\n",
      "[172]\ttrain-auc:0.873556\ttrain-ks:0.574993\ttest-auc:0.82299\ttest-ks:0.490705\n",
      "[173]\ttrain-auc:0.87378\ttrain-ks:0.575449\ttest-auc:0.823156\ttest-ks:0.491856\n",
      "[174]\ttrain-auc:0.874042\ttrain-ks:0.576037\ttest-auc:0.823444\ttest-ks:0.492127\n",
      "[175]\ttrain-auc:0.87424\ttrain-ks:0.576441\ttest-auc:0.823545\ttest-ks:0.492916\n",
      "[176]\ttrain-auc:0.874517\ttrain-ks:0.576844\ttest-auc:0.823776\ttest-ks:0.493148\n",
      "[177]\ttrain-auc:0.87472\ttrain-ks:0.577514\ttest-auc:0.823879\ttest-ks:0.493164\n",
      "[178]\ttrain-auc:0.874917\ttrain-ks:0.577729\ttest-auc:0.823996\ttest-ks:0.493734\n",
      "[179]\ttrain-auc:0.875024\ttrain-ks:0.577595\ttest-auc:0.824025\ttest-ks:0.494229\n",
      "[180]\ttrain-auc:0.875168\ttrain-ks:0.577858\ttest-auc:0.824121\ttest-ks:0.493962\n",
      "[181]\ttrain-auc:0.87536\ttrain-ks:0.578118\ttest-auc:0.824194\ttest-ks:0.493136\n",
      "[182]\ttrain-auc:0.875573\ttrain-ks:0.579122\ttest-auc:0.82433\ttest-ks:0.492557\n",
      "[183]\ttrain-auc:0.87578\ttrain-ks:0.579913\ttest-auc:0.824493\ttest-ks:0.493037\n",
      "[184]\ttrain-auc:0.875906\ttrain-ks:0.580384\ttest-auc:0.824547\ttest-ks:0.493347\n",
      "[185]\ttrain-auc:0.876139\ttrain-ks:0.580507\ttest-auc:0.824728\ttest-ks:0.494317\n",
      "[186]\ttrain-auc:0.876345\ttrain-ks:0.581127\ttest-auc:0.824858\ttest-ks:0.494398\n",
      "[187]\ttrain-auc:0.876463\ttrain-ks:0.581668\ttest-auc:0.824894\ttest-ks:0.494721\n",
      "[188]\ttrain-auc:0.876642\ttrain-ks:0.582064\ttest-auc:0.825038\ttest-ks:0.495538\n",
      "[189]\ttrain-auc:0.876819\ttrain-ks:0.582189\ttest-auc:0.825189\ttest-ks:0.49603\n",
      "[190]\ttrain-auc:0.876996\ttrain-ks:0.582466\ttest-auc:0.825365\ttest-ks:0.495953\n",
      "[191]\ttrain-auc:0.877132\ttrain-ks:0.582639\ttest-auc:0.825458\ttest-ks:0.495951\n",
      "[192]\ttrain-auc:0.877314\ttrain-ks:0.582842\ttest-auc:0.825604\ttest-ks:0.496996\n",
      "[193]\ttrain-auc:0.877586\ttrain-ks:0.583531\ttest-auc:0.825779\ttest-ks:0.495539\n",
      "[194]\ttrain-auc:0.877775\ttrain-ks:0.583778\ttest-auc:0.825903\ttest-ks:0.495736\n",
      "[195]\ttrain-auc:0.878001\ttrain-ks:0.584275\ttest-auc:0.826098\ttest-ks:0.494822\n",
      "[196]\ttrain-auc:0.878316\ttrain-ks:0.585077\ttest-auc:0.826274\ttest-ks:0.496134\n",
      "[197]\ttrain-auc:0.878474\ttrain-ks:0.58529\ttest-auc:0.826369\ttest-ks:0.497819\n",
      "[198]\ttrain-auc:0.87872\ttrain-ks:0.586019\ttest-auc:0.826536\ttest-ks:0.497278\n",
      "[199]\ttrain-auc:0.878924\ttrain-ks:0.586503\ttest-auc:0.826574\ttest-ks:0.497233\n",
      "[200]\ttrain-auc:0.879067\ttrain-ks:0.586637\ttest-auc:0.826667\ttest-ks:0.496958\n",
      "[201]\ttrain-auc:0.879302\ttrain-ks:0.58723\ttest-auc:0.826826\ttest-ks:0.497229\n",
      "[202]\ttrain-auc:0.879508\ttrain-ks:0.587556\ttest-auc:0.826925\ttest-ks:0.497986\n",
      "[203]\ttrain-auc:0.879776\ttrain-ks:0.587889\ttest-auc:0.827112\ttest-ks:0.497886\n",
      "[204]\ttrain-auc:0.879995\ttrain-ks:0.588554\ttest-auc:0.827231\ttest-ks:0.498749\n",
      "[205]\ttrain-auc:0.880195\ttrain-ks:0.588779\ttest-auc:0.827382\ttest-ks:0.498893\n",
      "[206]\ttrain-auc:0.880356\ttrain-ks:0.589243\ttest-auc:0.827456\ttest-ks:0.499177\n",
      "[207]\ttrain-auc:0.880503\ttrain-ks:0.589379\ttest-auc:0.827602\ttest-ks:0.499652\n",
      "[208]\ttrain-auc:0.880683\ttrain-ks:0.589604\ttest-auc:0.827669\ttest-ks:0.499382\n",
      "[209]\ttrain-auc:0.880809\ttrain-ks:0.59034\ttest-auc:0.827698\ttest-ks:0.499922\n",
      "[210]\ttrain-auc:0.880946\ttrain-ks:0.590534\ttest-auc:0.827739\ttest-ks:0.499612\n",
      "[211]\ttrain-auc:0.881107\ttrain-ks:0.591024\ttest-auc:0.827864\ttest-ks:0.499885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212]\ttrain-auc:0.881304\ttrain-ks:0.591488\ttest-auc:0.827986\ttest-ks:0.499399\n",
      "[213]\ttrain-auc:0.881446\ttrain-ks:0.591957\ttest-auc:0.828055\ttest-ks:0.500147\n",
      "[214]\ttrain-auc:0.881613\ttrain-ks:0.592224\ttest-auc:0.828168\ttest-ks:0.500332\n",
      "[215]\ttrain-auc:0.881737\ttrain-ks:0.592555\ttest-auc:0.82827\ttest-ks:0.499849\n",
      "[216]\ttrain-auc:0.881888\ttrain-ks:0.592959\ttest-auc:0.82831\ttest-ks:0.500088\n",
      "[217]\ttrain-auc:0.882013\ttrain-ks:0.593094\ttest-auc:0.828433\ttest-ks:0.500234\n",
      "[218]\ttrain-auc:0.882164\ttrain-ks:0.593243\ttest-auc:0.828519\ttest-ks:0.500945\n",
      "[219]\ttrain-auc:0.882327\ttrain-ks:0.593307\ttest-auc:0.828619\ttest-ks:0.501158\n",
      "[220]\ttrain-auc:0.882448\ttrain-ks:0.593245\ttest-auc:0.828723\ttest-ks:0.501702\n",
      "[221]\ttrain-auc:0.882568\ttrain-ks:0.593294\ttest-auc:0.828781\ttest-ks:0.501949\n",
      "[222]\ttrain-auc:0.882722\ttrain-ks:0.593568\ttest-auc:0.828943\ttest-ks:0.502049\n",
      "[223]\ttrain-auc:0.882932\ttrain-ks:0.593913\ttest-auc:0.829121\ttest-ks:0.503273\n",
      "[224]\ttrain-auc:0.883129\ttrain-ks:0.594424\ttest-auc:0.829296\ttest-ks:0.503377\n",
      "[225]\ttrain-auc:0.883301\ttrain-ks:0.594758\ttest-auc:0.829426\ttest-ks:0.502762\n",
      "[226]\ttrain-auc:0.883398\ttrain-ks:0.594847\ttest-auc:0.829463\ttest-ks:0.503935\n",
      "[227]\ttrain-auc:0.883623\ttrain-ks:0.595283\ttest-auc:0.829518\ttest-ks:0.503683\n",
      "[228]\ttrain-auc:0.883783\ttrain-ks:0.595524\ttest-auc:0.829571\ttest-ks:0.504225\n",
      "[229]\ttrain-auc:0.883889\ttrain-ks:0.595709\ttest-auc:0.829619\ttest-ks:0.504733\n",
      "[230]\ttrain-auc:0.884037\ttrain-ks:0.596303\ttest-auc:0.829725\ttest-ks:0.504386\n",
      "[231]\ttrain-auc:0.884144\ttrain-ks:0.596497\ttest-auc:0.829776\ttest-ks:0.504705\n",
      "[232]\ttrain-auc:0.884298\ttrain-ks:0.597007\ttest-auc:0.829892\ttest-ks:0.504679\n",
      "[233]\ttrain-auc:0.884457\ttrain-ks:0.596924\ttest-auc:0.829952\ttest-ks:0.50495\n",
      "[234]\ttrain-auc:0.884566\ttrain-ks:0.597367\ttest-auc:0.830063\ttest-ks:0.504922\n",
      "[235]\ttrain-auc:0.884737\ttrain-ks:0.597484\ttest-auc:0.830179\ttest-ks:0.504678\n",
      "[236]\ttrain-auc:0.8849\ttrain-ks:0.598021\ttest-auc:0.830251\ttest-ks:0.504983\n",
      "[237]\ttrain-auc:0.884991\ttrain-ks:0.598084\ttest-auc:0.830294\ttest-ks:0.505459\n",
      "[238]\ttrain-auc:0.885131\ttrain-ks:0.598684\ttest-auc:0.83035\ttest-ks:0.50597\n",
      "[239]\ttrain-auc:0.885238\ttrain-ks:0.598813\ttest-auc:0.830432\ttest-ks:0.505579\n",
      "[240]\ttrain-auc:0.885379\ttrain-ks:0.599278\ttest-auc:0.830556\ttest-ks:0.506024\n",
      "[241]\ttrain-auc:0.885562\ttrain-ks:0.599512\ttest-auc:0.830667\ttest-ks:0.507011\n",
      "[242]\ttrain-auc:0.88572\ttrain-ks:0.599754\ttest-auc:0.83076\ttest-ks:0.507445\n",
      "[243]\ttrain-auc:0.885885\ttrain-ks:0.600277\ttest-auc:0.83087\ttest-ks:0.508232\n",
      "[244]\ttrain-auc:0.886002\ttrain-ks:0.600235\ttest-auc:0.830916\ttest-ks:0.507708\n",
      "[245]\ttrain-auc:0.886241\ttrain-ks:0.601114\ttest-auc:0.83107\ttest-ks:0.507496\n",
      "[246]\ttrain-auc:0.886351\ttrain-ks:0.601421\ttest-auc:0.831066\ttest-ks:0.507466\n",
      "[247]\ttrain-auc:0.886506\ttrain-ks:0.601424\ttest-auc:0.831156\ttest-ks:0.508515\n",
      "[248]\ttrain-auc:0.886648\ttrain-ks:0.601498\ttest-auc:0.83122\ttest-ks:0.509303\n",
      "[249]\ttrain-auc:0.886783\ttrain-ks:0.602015\ttest-auc:0.831292\ttest-ks:0.508817\n",
      "[250]\ttrain-auc:0.886965\ttrain-ks:0.602354\ttest-auc:0.831381\ttest-ks:0.507364\n",
      "[251]\ttrain-auc:0.887044\ttrain-ks:0.602889\ttest-auc:0.831431\ttest-ks:0.507941\n",
      "[252]\ttrain-auc:0.887204\ttrain-ks:0.602893\ttest-auc:0.831543\ttest-ks:0.508262\n",
      "[253]\ttrain-auc:0.887324\ttrain-ks:0.603191\ttest-auc:0.831602\ttest-ks:0.508421\n",
      "[254]\ttrain-auc:0.887426\ttrain-ks:0.603366\ttest-auc:0.831679\ttest-ks:0.508557\n",
      "[255]\ttrain-auc:0.887582\ttrain-ks:0.603499\ttest-auc:0.83179\ttest-ks:0.509769\n",
      "[256]\ttrain-auc:0.887714\ttrain-ks:0.603813\ttest-auc:0.83189\ttest-ks:0.510026\n",
      "[257]\ttrain-auc:0.887819\ttrain-ks:0.604057\ttest-auc:0.831913\ttest-ks:0.510028\n",
      "[258]\ttrain-auc:0.887954\ttrain-ks:0.60414\ttest-auc:0.831968\ttest-ks:0.509077\n",
      "[259]\ttrain-auc:0.888063\ttrain-ks:0.605063\ttest-auc:0.831958\ttest-ks:0.509167\n",
      "[260]\ttrain-auc:0.888206\ttrain-ks:0.605333\ttest-auc:0.831971\ttest-ks:0.508382\n",
      "[261]\ttrain-auc:0.888351\ttrain-ks:0.605625\ttest-auc:0.832021\ttest-ks:0.508836\n",
      "[262]\ttrain-auc:0.888484\ttrain-ks:0.606295\ttest-auc:0.832114\ttest-ks:0.509653\n",
      "[263]\ttrain-auc:0.888639\ttrain-ks:0.606746\ttest-auc:0.832166\ttest-ks:0.510146\n",
      "[264]\ttrain-auc:0.888766\ttrain-ks:0.606775\ttest-auc:0.832226\ttest-ks:0.511708\n",
      "[265]\ttrain-auc:0.88895\ttrain-ks:0.607545\ttest-auc:0.83237\ttest-ks:0.512232\n",
      "[266]\ttrain-auc:0.889049\ttrain-ks:0.607707\ttest-auc:0.832432\ttest-ks:0.511591\n",
      "[267]\ttrain-auc:0.889133\ttrain-ks:0.607836\ttest-auc:0.83249\ttest-ks:0.511976\n",
      "[268]\ttrain-auc:0.889249\ttrain-ks:0.608088\ttest-auc:0.832543\ttest-ks:0.512\n",
      "[269]\ttrain-auc:0.889388\ttrain-ks:0.608997\ttest-auc:0.832669\ttest-ks:0.511452\n",
      "[270]\ttrain-auc:0.889517\ttrain-ks:0.608952\ttest-auc:0.832747\ttest-ks:0.511436\n",
      "[271]\ttrain-auc:0.88968\ttrain-ks:0.609302\ttest-auc:0.832903\ttest-ks:0.511192\n",
      "[272]\ttrain-auc:0.889831\ttrain-ks:0.609398\ttest-auc:0.832926\ttest-ks:0.512092\n",
      "[273]\ttrain-auc:0.89003\ttrain-ks:0.609773\ttest-auc:0.83307\ttest-ks:0.512374\n",
      "[274]\ttrain-auc:0.890158\ttrain-ks:0.609892\ttest-auc:0.833114\ttest-ks:0.513149\n",
      "[275]\ttrain-auc:0.890309\ttrain-ks:0.610342\ttest-auc:0.833145\ttest-ks:0.513052\n",
      "[276]\ttrain-auc:0.890395\ttrain-ks:0.610805\ttest-auc:0.833183\ttest-ks:0.513329\n",
      "[277]\ttrain-auc:0.890535\ttrain-ks:0.611134\ttest-auc:0.833227\ttest-ks:0.513676\n",
      "[278]\ttrain-auc:0.890585\ttrain-ks:0.611155\ttest-auc:0.833283\ttest-ks:0.513176\n",
      "[279]\ttrain-auc:0.890726\ttrain-ks:0.61172\ttest-auc:0.833359\ttest-ks:0.512264\n",
      "[280]\ttrain-auc:0.89084\ttrain-ks:0.612084\ttest-auc:0.833451\ttest-ks:0.512814\n",
      "[281]\ttrain-auc:0.890972\ttrain-ks:0.612157\ttest-auc:0.833521\ttest-ks:0.512564\n",
      "[282]\ttrain-auc:0.891111\ttrain-ks:0.61249\ttest-auc:0.833568\ttest-ks:0.51303\n",
      "[283]\ttrain-auc:0.891266\ttrain-ks:0.613024\ttest-auc:0.833693\ttest-ks:0.513064\n",
      "[284]\ttrain-auc:0.891374\ttrain-ks:0.613226\ttest-auc:0.833706\ttest-ks:0.513246\n",
      "[285]\ttrain-auc:0.891559\ttrain-ks:0.613349\ttest-auc:0.833787\ttest-ks:0.513934\n",
      "[286]\ttrain-auc:0.891733\ttrain-ks:0.614023\ttest-auc:0.833862\ttest-ks:0.513934\n",
      "[287]\ttrain-auc:0.891834\ttrain-ks:0.614547\ttest-auc:0.833892\ttest-ks:0.513378\n",
      "[288]\ttrain-auc:0.891987\ttrain-ks:0.614813\ttest-auc:0.833942\ttest-ks:0.513659\n",
      "[289]\ttrain-auc:0.892127\ttrain-ks:0.615614\ttest-auc:0.83403\ttest-ks:0.512884\n",
      "[290]\ttrain-auc:0.892212\ttrain-ks:0.615495\ttest-auc:0.834064\ttest-ks:0.512442\n",
      "[291]\ttrain-auc:0.892331\ttrain-ks:0.615726\ttest-auc:0.834134\ttest-ks:0.513329\n",
      "[292]\ttrain-auc:0.892477\ttrain-ks:0.616309\ttest-auc:0.834205\ttest-ks:0.512857\n",
      "[293]\ttrain-auc:0.89261\ttrain-ks:0.616441\ttest-auc:0.834234\ttest-ks:0.512679\n",
      "[294]\ttrain-auc:0.892721\ttrain-ks:0.616571\ttest-auc:0.834286\ttest-ks:0.513905\n",
      "[295]\ttrain-auc:0.892819\ttrain-ks:0.617179\ttest-auc:0.834375\ttest-ks:0.5139\n",
      "[296]\ttrain-auc:0.892948\ttrain-ks:0.617586\ttest-auc:0.834397\ttest-ks:0.513904\n",
      "[297]\ttrain-auc:0.893071\ttrain-ks:0.617835\ttest-auc:0.834439\ttest-ks:0.514173\n",
      "[298]\ttrain-auc:0.893226\ttrain-ks:0.618456\ttest-auc:0.834516\ttest-ks:0.51418\n",
      "[299]\ttrain-auc:0.89335\ttrain-ks:0.619159\ttest-auc:0.834577\ttest-ks:0.514159\n",
      "[300]\ttrain-auc:0.893453\ttrain-ks:0.619293\ttest-auc:0.834614\ttest-ks:0.513962\n",
      "[301]\ttrain-auc:0.893603\ttrain-ks:0.619624\ttest-auc:0.834692\ttest-ks:0.514241\n",
      "[302]\ttrain-auc:0.893802\ttrain-ks:0.620227\ttest-auc:0.834742\ttest-ks:0.515048\n",
      "[303]\ttrain-auc:0.893908\ttrain-ks:0.620494\ttest-auc:0.834806\ttest-ks:0.514783\n",
      "[304]\ttrain-auc:0.894015\ttrain-ks:0.620627\ttest-auc:0.8348\ttest-ks:0.514238\n",
      "[305]\ttrain-auc:0.894119\ttrain-ks:0.620762\ttest-auc:0.834873\ttest-ks:0.514502\n",
      "[306]\ttrain-auc:0.894224\ttrain-ks:0.62103\ttest-auc:0.834975\ttest-ks:0.514772\n",
      "[307]\ttrain-auc:0.894322\ttrain-ks:0.621272\ttest-auc:0.835016\ttest-ks:0.514763\n",
      "[308]\ttrain-auc:0.894462\ttrain-ks:0.621267\ttest-auc:0.835095\ttest-ks:0.514639\n",
      "[309]\ttrain-auc:0.894637\ttrain-ks:0.621408\ttest-auc:0.835154\ttest-ks:0.514683\n",
      "[310]\ttrain-auc:0.894718\ttrain-ks:0.622209\ttest-auc:0.835182\ttest-ks:0.514474\n",
      "[311]\ttrain-auc:0.894831\ttrain-ks:0.622343\ttest-auc:0.8353\ttest-ks:0.514433\n",
      "[312]\ttrain-auc:0.894929\ttrain-ks:0.622155\ttest-auc:0.835393\ttest-ks:0.515228\n",
      "[313]\ttrain-auc:0.895018\ttrain-ks:0.622418\ttest-auc:0.83545\ttest-ks:0.514708\n",
      "[314]\ttrain-auc:0.895104\ttrain-ks:0.622614\ttest-auc:0.835432\ttest-ks:0.514937\n",
      "[315]\ttrain-auc:0.895228\ttrain-ks:0.623147\ttest-auc:0.835446\ttest-ks:0.514924\n",
      "[316]\ttrain-auc:0.895314\ttrain-ks:0.62348\ttest-auc:0.835468\ttest-ks:0.514726\n",
      "[317]\ttrain-auc:0.895481\ttrain-ks:0.623999\ttest-auc:0.835452\ttest-ks:0.515577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[318]\ttrain-auc:0.895569\ttrain-ks:0.623598\ttest-auc:0.835528\ttest-ks:0.516632\n",
      "[319]\ttrain-auc:0.895731\ttrain-ks:0.623749\ttest-auc:0.835515\ttest-ks:0.516482\n",
      "[320]\ttrain-auc:0.895868\ttrain-ks:0.623998\ttest-auc:0.835569\ttest-ks:0.516495\n",
      "[321]\ttrain-auc:0.896002\ttrain-ks:0.624343\ttest-auc:0.835617\ttest-ks:0.51664\n",
      "[322]\ttrain-auc:0.89609\ttrain-ks:0.624875\ttest-auc:0.835651\ttest-ks:0.517164\n",
      "[323]\ttrain-auc:0.896244\ttrain-ks:0.625475\ttest-auc:0.835748\ttest-ks:0.516895\n",
      "[324]\ttrain-auc:0.896312\ttrain-ks:0.625865\ttest-auc:0.835783\ttest-ks:0.516636\n",
      "[325]\ttrain-auc:0.896459\ttrain-ks:0.626398\ttest-auc:0.835854\ttest-ks:0.516362\n",
      "[326]\ttrain-auc:0.896601\ttrain-ks:0.626806\ttest-auc:0.835946\ttest-ks:0.51699\n",
      "[327]\ttrain-auc:0.896723\ttrain-ks:0.627274\ttest-auc:0.836024\ttest-ks:0.516258\n",
      "[328]\ttrain-auc:0.89684\ttrain-ks:0.627277\ttest-auc:0.836084\ttest-ks:0.51728\n",
      "[329]\ttrain-auc:0.89695\ttrain-ks:0.627336\ttest-auc:0.836116\ttest-ks:0.517543\n",
      "[330]\ttrain-auc:0.897066\ttrain-ks:0.627461\ttest-auc:0.836182\ttest-ks:0.51753\n",
      "[331]\ttrain-auc:0.897165\ttrain-ks:0.627612\ttest-auc:0.836182\ttest-ks:0.517513\n",
      "[332]\ttrain-auc:0.89727\ttrain-ks:0.628066\ttest-auc:0.836148\ttest-ks:0.517273\n",
      "[333]\ttrain-auc:0.897426\ttrain-ks:0.628215\ttest-auc:0.836227\ttest-ks:0.517703\n",
      "[334]\ttrain-auc:0.897538\ttrain-ks:0.628535\ttest-auc:0.836342\ttest-ks:0.517594\n",
      "[335]\ttrain-auc:0.897625\ttrain-ks:0.628853\ttest-auc:0.836368\ttest-ks:0.518015\n",
      "[336]\ttrain-auc:0.897762\ttrain-ks:0.629135\ttest-auc:0.836341\ttest-ks:0.518541\n",
      "[337]\ttrain-auc:0.897887\ttrain-ks:0.62952\ttest-auc:0.836336\ttest-ks:0.518587\n",
      "[338]\ttrain-auc:0.897937\ttrain-ks:0.629438\ttest-auc:0.836344\ttest-ks:0.519114\n",
      "[339]\ttrain-auc:0.898047\ttrain-ks:0.629522\ttest-auc:0.836359\ttest-ks:0.519898\n",
      "[340]\ttrain-auc:0.898166\ttrain-ks:0.629868\ttest-auc:0.836476\ttest-ks:0.519835\n",
      "[341]\ttrain-auc:0.898275\ttrain-ks:0.630149\ttest-auc:0.836455\ttest-ks:0.519101\n",
      "[342]\ttrain-auc:0.898382\ttrain-ks:0.630396\ttest-auc:0.836489\ttest-ks:0.520107\n",
      "[343]\ttrain-auc:0.898497\ttrain-ks:0.630597\ttest-auc:0.836468\ttest-ks:0.520098\n",
      "[344]\ttrain-auc:0.898601\ttrain-ks:0.631065\ttest-auc:0.836522\ttest-ks:0.519847\n",
      "[345]\ttrain-auc:0.898708\ttrain-ks:0.631198\ttest-auc:0.836595\ttest-ks:0.520645\n",
      "[346]\ttrain-auc:0.898821\ttrain-ks:0.631532\ttest-auc:0.836639\ttest-ks:0.51985\n",
      "[347]\ttrain-auc:0.898926\ttrain-ks:0.63163\ttest-auc:0.836708\ttest-ks:0.51985\n",
      "[348]\ttrain-auc:0.898987\ttrain-ks:0.63185\ttest-auc:0.836758\ttest-ks:0.519846\n",
      "[349]\ttrain-auc:0.899083\ttrain-ks:0.632233\ttest-auc:0.836801\ttest-ks:0.519595\n",
      "[350]\ttrain-auc:0.899195\ttrain-ks:0.632439\ttest-auc:0.8368\ttest-ks:0.520377\n",
      "[351]\ttrain-auc:0.899299\ttrain-ks:0.632466\ttest-auc:0.836843\ttest-ks:0.52\n",
      "[352]\ttrain-auc:0.899401\ttrain-ks:0.632801\ttest-auc:0.836937\ttest-ks:0.520365\n",
      "[353]\ttrain-auc:0.899482\ttrain-ks:0.633059\ttest-auc:0.836981\ttest-ks:0.520849\n",
      "[354]\ttrain-auc:0.899622\ttrain-ks:0.633596\ttest-auc:0.837046\ttest-ks:0.520882\n",
      "[355]\ttrain-auc:0.899737\ttrain-ks:0.633805\ttest-auc:0.837107\ttest-ks:0.520925\n",
      "[356]\ttrain-auc:0.899831\ttrain-ks:0.633995\ttest-auc:0.837147\ttest-ks:0.521194\n",
      "[357]\ttrain-auc:0.899905\ttrain-ks:0.634466\ttest-auc:0.837167\ttest-ks:0.521076\n",
      "[358]\ttrain-auc:0.900019\ttrain-ks:0.634667\ttest-auc:0.837216\ttest-ks:0.521604\n",
      "[359]\ttrain-auc:0.900162\ttrain-ks:0.634738\ttest-auc:0.837277\ttest-ks:0.521724\n",
      "[360]\ttrain-auc:0.900322\ttrain-ks:0.635419\ttest-auc:0.837371\ttest-ks:0.522348\n",
      "[361]\ttrain-auc:0.900423\ttrain-ks:0.635487\ttest-auc:0.837402\ttest-ks:0.521834\n",
      "[362]\ttrain-auc:0.900512\ttrain-ks:0.635685\ttest-auc:0.837444\ttest-ks:0.52147\n",
      "[363]\ttrain-auc:0.900635\ttrain-ks:0.636216\ttest-auc:0.837476\ttest-ks:0.521443\n",
      "[364]\ttrain-auc:0.900719\ttrain-ks:0.636546\ttest-auc:0.837484\ttest-ks:0.521072\n",
      "[365]\ttrain-auc:0.900832\ttrain-ks:0.636973\ttest-auc:0.837448\ttest-ks:0.520928\n",
      "[366]\ttrain-auc:0.900894\ttrain-ks:0.637079\ttest-auc:0.837483\ttest-ks:0.520951\n",
      "[367]\ttrain-auc:0.90102\ttrain-ks:0.637484\ttest-auc:0.837533\ttest-ks:0.521036\n",
      "[368]\ttrain-auc:0.901133\ttrain-ks:0.637794\ttest-auc:0.8376\ttest-ks:0.521304\n",
      "[369]\ttrain-auc:0.901256\ttrain-ks:0.638011\ttest-auc:0.837656\ttest-ks:0.521828\n",
      "[370]\ttrain-auc:0.901374\ttrain-ks:0.63826\ttest-auc:0.837705\ttest-ks:0.521818\n",
      "[371]\ttrain-auc:0.901483\ttrain-ks:0.638744\ttest-auc:0.837754\ttest-ks:0.522035\n",
      "[372]\ttrain-auc:0.901596\ttrain-ks:0.638812\ttest-auc:0.837852\ttest-ks:0.5216\n",
      "[373]\ttrain-auc:0.901699\ttrain-ks:0.639068\ttest-auc:0.837896\ttest-ks:0.52192\n",
      "[374]\ttrain-auc:0.901803\ttrain-ks:0.63947\ttest-auc:0.837955\ttest-ks:0.522453\n",
      "[375]\ttrain-auc:0.901862\ttrain-ks:0.638944\ttest-auc:0.838027\ttest-ks:0.523149\n",
      "[376]\ttrain-auc:0.901952\ttrain-ks:0.639601\ttest-auc:0.838038\ttest-ks:0.522383\n",
      "[377]\ttrain-auc:0.902058\ttrain-ks:0.639789\ttest-auc:0.838044\ttest-ks:0.522154\n",
      "[378]\ttrain-auc:0.90215\ttrain-ks:0.639789\ttest-auc:0.838036\ttest-ks:0.522486\n",
      "[379]\ttrain-auc:0.902255\ttrain-ks:0.639853\ttest-auc:0.838069\ttest-ks:0.52133\n",
      "[380]\ttrain-auc:0.902327\ttrain-ks:0.639994\ttest-auc:0.83808\ttest-ks:0.520677\n",
      "[381]\ttrain-auc:0.902427\ttrain-ks:0.640328\ttest-auc:0.838173\ttest-ks:0.521393\n",
      "[382]\ttrain-auc:0.902498\ttrain-ks:0.640657\ttest-auc:0.83819\ttest-ks:0.521388\n",
      "[383]\ttrain-auc:0.902618\ttrain-ks:0.640924\ttest-auc:0.83826\ttest-ks:0.521698\n",
      "[384]\ttrain-auc:0.902749\ttrain-ks:0.64119\ttest-auc:0.838362\ttest-ks:0.520924\n",
      "[385]\ttrain-auc:0.902866\ttrain-ks:0.641432\ttest-auc:0.838415\ttest-ks:0.521404\n",
      "[386]\ttrain-auc:0.902937\ttrain-ks:0.641518\ttest-auc:0.838458\ttest-ks:0.521183\n",
      "[387]\ttrain-auc:0.903007\ttrain-ks:0.641918\ttest-auc:0.83847\ttest-ks:0.521612\n",
      "[388]\ttrain-auc:0.903097\ttrain-ks:0.641973\ttest-auc:0.838435\ttest-ks:0.522128\n",
      "[389]\ttrain-auc:0.903213\ttrain-ks:0.642314\ttest-auc:0.838395\ttest-ks:0.521702\n",
      "[390]\ttrain-auc:0.903358\ttrain-ks:0.64278\ttest-auc:0.838469\ttest-ks:0.521869\n",
      "[391]\ttrain-auc:0.903444\ttrain-ks:0.643182\ttest-auc:0.838473\ttest-ks:0.521624\n",
      "[392]\ttrain-auc:0.903508\ttrain-ks:0.64331\ttest-auc:0.838527\ttest-ks:0.522227\n",
      "[393]\ttrain-auc:0.903641\ttrain-ks:0.643309\ttest-auc:0.838637\ttest-ks:0.522254\n",
      "[394]\ttrain-auc:0.903755\ttrain-ks:0.643716\ttest-auc:0.838639\ttest-ks:0.522669\n",
      "[395]\ttrain-auc:0.90383\ttrain-ks:0.6438\ttest-auc:0.83865\ttest-ks:0.522237\n",
      "[396]\ttrain-auc:0.903901\ttrain-ks:0.644332\ttest-auc:0.838677\ttest-ks:0.522527\n",
      "[397]\ttrain-auc:0.903982\ttrain-ks:0.644235\ttest-auc:0.838714\ttest-ks:0.522477\n",
      "[398]\ttrain-auc:0.904096\ttrain-ks:0.644514\ttest-auc:0.838683\ttest-ks:0.521956\n",
      "[399]\ttrain-auc:0.904203\ttrain-ks:0.644749\ttest-auc:0.838735\ttest-ks:0.522227\n",
      "[400]\ttrain-auc:0.904289\ttrain-ks:0.644982\ttest-auc:0.838782\ttest-ks:0.522242\n",
      "[401]\ttrain-auc:0.904374\ttrain-ks:0.645281\ttest-auc:0.838792\ttest-ks:0.522376\n",
      "[402]\ttrain-auc:0.90449\ttrain-ks:0.645735\ttest-auc:0.838896\ttest-ks:0.522859\n",
      "[403]\ttrain-auc:0.904566\ttrain-ks:0.645834\ttest-auc:0.838918\ttest-ks:0.522368\n",
      "[404]\ttrain-auc:0.904636\ttrain-ks:0.646201\ttest-auc:0.838949\ttest-ks:0.523175\n",
      "[405]\ttrain-auc:0.90469\ttrain-ks:0.646233\ttest-auc:0.838929\ttest-ks:0.523106\n",
      "[406]\ttrain-auc:0.90475\ttrain-ks:0.646102\ttest-auc:0.838917\ttest-ks:0.523108\n",
      "[407]\ttrain-auc:0.904855\ttrain-ks:0.646663\ttest-auc:0.838889\ttest-ks:0.522703\n",
      "[408]\ttrain-auc:0.904939\ttrain-ks:0.64703\ttest-auc:0.838886\ttest-ks:0.522536\n",
      "[409]\ttrain-auc:0.905024\ttrain-ks:0.647241\ttest-auc:0.838935\ttest-ks:0.522741\n",
      "[410]\ttrain-auc:0.90512\ttrain-ks:0.647614\ttest-auc:0.83899\ttest-ks:0.522896\n",
      "[411]\ttrain-auc:0.905183\ttrain-ks:0.648013\ttest-auc:0.839009\ttest-ks:0.522686\n",
      "[412]\ttrain-auc:0.905269\ttrain-ks:0.648207\ttest-auc:0.839056\ttest-ks:0.523457\n",
      "[413]\ttrain-auc:0.905374\ttrain-ks:0.648409\ttest-auc:0.839061\ttest-ks:0.52345\n",
      "[414]\ttrain-auc:0.905489\ttrain-ks:0.648585\ttest-auc:0.839112\ttest-ks:0.523886\n",
      "[415]\ttrain-auc:0.905566\ttrain-ks:0.648711\ttest-auc:0.839135\ttest-ks:0.523873\n",
      "[416]\ttrain-auc:0.905662\ttrain-ks:0.64906\ttest-auc:0.839138\ttest-ks:0.52375\n",
      "[417]\ttrain-auc:0.905734\ttrain-ks:0.64927\ttest-auc:0.839147\ttest-ks:0.523629\n",
      "[418]\ttrain-auc:0.905869\ttrain-ks:0.649876\ttest-auc:0.839124\ttest-ks:0.523895\n",
      "[419]\ttrain-auc:0.905983\ttrain-ks:0.650111\ttest-auc:0.839177\ttest-ks:0.523908\n",
      "[420]\ttrain-auc:0.906064\ttrain-ks:0.650257\ttest-auc:0.839219\ttest-ks:0.523902\n",
      "[421]\ttrain-auc:0.906164\ttrain-ks:0.650718\ttest-auc:0.839278\ttest-ks:0.523624\n",
      "[422]\ttrain-auc:0.906272\ttrain-ks:0.650918\ttest-auc:0.839282\ttest-ks:0.523891\n",
      "[423]\ttrain-auc:0.906394\ttrain-ks:0.650922\ttest-auc:0.839317\ttest-ks:0.523931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[424]\ttrain-auc:0.90651\ttrain-ks:0.651188\ttest-auc:0.839344\ttest-ks:0.52421\n",
      "[425]\ttrain-auc:0.90663\ttrain-ks:0.651586\ttest-auc:0.839357\ttest-ks:0.524748\n",
      "[426]\ttrain-auc:0.906766\ttrain-ks:0.652119\ttest-auc:0.839358\ttest-ks:0.525544\n",
      "[427]\ttrain-auc:0.906883\ttrain-ks:0.652519\ttest-auc:0.839375\ttest-ks:0.525273\n",
      "[428]\ttrain-auc:0.906963\ttrain-ks:0.652649\ttest-auc:0.839404\ttest-ks:0.525282\n",
      "[429]\ttrain-auc:0.907049\ttrain-ks:0.652861\ttest-auc:0.839419\ttest-ks:0.524717\n",
      "[430]\ttrain-auc:0.907139\ttrain-ks:0.652926\ttest-auc:0.839441\ttest-ks:0.524146\n",
      "[431]\ttrain-auc:0.907205\ttrain-ks:0.652856\ttest-auc:0.839455\ttest-ks:0.523323\n",
      "[432]\ttrain-auc:0.907299\ttrain-ks:0.652858\ttest-auc:0.839463\ttest-ks:0.524514\n",
      "[433]\ttrain-auc:0.907367\ttrain-ks:0.653182\ttest-auc:0.839483\ttest-ks:0.524879\n",
      "[434]\ttrain-auc:0.907452\ttrain-ks:0.653516\ttest-auc:0.839517\ttest-ks:0.524491\n",
      "[435]\ttrain-auc:0.907571\ttrain-ks:0.653522\ttest-auc:0.839591\ttest-ks:0.525205\n",
      "[436]\ttrain-auc:0.907678\ttrain-ks:0.653793\ttest-auc:0.839571\ttest-ks:0.524929\n",
      "[437]\ttrain-auc:0.907766\ttrain-ks:0.65419\ttest-auc:0.839618\ttest-ks:0.524474\n",
      "[438]\ttrain-auc:0.907873\ttrain-ks:0.654397\ttest-auc:0.839682\ttest-ks:0.524726\n",
      "[439]\ttrain-auc:0.907923\ttrain-ks:0.654421\ttest-auc:0.839691\ttest-ks:0.524747\n",
      "[440]\ttrain-auc:0.908012\ttrain-ks:0.654858\ttest-auc:0.839658\ttest-ks:0.525093\n",
      "[441]\ttrain-auc:0.908138\ttrain-ks:0.654889\ttest-auc:0.83968\ttest-ks:0.524849\n",
      "[442]\ttrain-auc:0.908225\ttrain-ks:0.655285\ttest-auc:0.83967\ttest-ks:0.524721\n",
      "[443]\ttrain-auc:0.908346\ttrain-ks:0.655611\ttest-auc:0.83978\ttest-ks:0.525103\n",
      "[444]\ttrain-auc:0.908422\ttrain-ks:0.655681\ttest-auc:0.839761\ttest-ks:0.524853\n",
      "[445]\ttrain-auc:0.908565\ttrain-ks:0.655881\ttest-auc:0.839813\ttest-ks:0.524933\n",
      "[446]\ttrain-auc:0.908654\ttrain-ks:0.655819\ttest-auc:0.839853\ttest-ks:0.524818\n",
      "[447]\ttrain-auc:0.908703\ttrain-ks:0.656347\ttest-auc:0.839891\ttest-ks:0.524551\n",
      "[448]\ttrain-auc:0.908782\ttrain-ks:0.656451\ttest-auc:0.839902\ttest-ks:0.524551\n",
      "[449]\ttrain-auc:0.908832\ttrain-ks:0.656576\ttest-auc:0.839913\ttest-ks:0.525331\n",
      "[450]\ttrain-auc:0.908909\ttrain-ks:0.656523\ttest-auc:0.839929\ttest-ks:0.525539\n",
      "[451]\ttrain-auc:0.908981\ttrain-ks:0.656642\ttest-auc:0.839953\ttest-ks:0.525125\n",
      "[452]\ttrain-auc:0.909034\ttrain-ks:0.656979\ttest-auc:0.839946\ttest-ks:0.524917\n",
      "[453]\ttrain-auc:0.909097\ttrain-ks:0.657169\ttest-auc:0.839978\ttest-ks:0.524962\n",
      "[454]\ttrain-auc:0.909231\ttrain-ks:0.657303\ttest-auc:0.839985\ttest-ks:0.525626\n",
      "[455]\ttrain-auc:0.909324\ttrain-ks:0.657972\ttest-auc:0.840031\ttest-ks:0.525394\n",
      "[456]\ttrain-auc:0.909439\ttrain-ks:0.658046\ttest-auc:0.840073\ttest-ks:0.524758\n",
      "[457]\ttrain-auc:0.909512\ttrain-ks:0.658247\ttest-auc:0.840093\ttest-ks:0.525543\n",
      "[458]\ttrain-auc:0.909579\ttrain-ks:0.658447\ttest-auc:0.840125\ttest-ks:0.525777\n",
      "[459]\ttrain-auc:0.909647\ttrain-ks:0.658585\ttest-auc:0.840123\ttest-ks:0.525265\n",
      "[460]\ttrain-auc:0.909708\ttrain-ks:0.658581\ttest-auc:0.840113\ttest-ks:0.52551\n",
      "[461]\ttrain-auc:0.909791\ttrain-ks:0.658843\ttest-auc:0.840148\ttest-ks:0.525769\n",
      "[462]\ttrain-auc:0.909871\ttrain-ks:0.658985\ttest-auc:0.840162\ttest-ks:0.525975\n",
      "[463]\ttrain-auc:0.909913\ttrain-ks:0.65903\ttest-auc:0.840185\ttest-ks:0.52602\n",
      "[464]\ttrain-auc:0.910018\ttrain-ks:0.659491\ttest-auc:0.840221\ttest-ks:0.526028\n",
      "[465]\ttrain-auc:0.910109\ttrain-ks:0.659708\ttest-auc:0.840252\ttest-ks:0.526277\n",
      "[466]\ttrain-auc:0.910222\ttrain-ks:0.659719\ttest-auc:0.840271\ttest-ks:0.526528\n",
      "[467]\ttrain-auc:0.910313\ttrain-ks:0.660072\ttest-auc:0.840296\ttest-ks:0.526527\n",
      "[468]\ttrain-auc:0.910391\ttrain-ks:0.66023\ttest-auc:0.840254\ttest-ks:0.526538\n",
      "[469]\ttrain-auc:0.910466\ttrain-ks:0.660386\ttest-auc:0.84025\ttest-ks:0.526776\n",
      "[470]\ttrain-auc:0.910567\ttrain-ks:0.660453\ttest-auc:0.840311\ttest-ks:0.526558\n",
      "[471]\ttrain-auc:0.910647\ttrain-ks:0.660705\ttest-auc:0.840372\ttest-ks:0.525765\n",
      "[472]\ttrain-auc:0.910742\ttrain-ks:0.660862\ttest-auc:0.84036\ttest-ks:0.525642\n",
      "[473]\ttrain-auc:0.910842\ttrain-ks:0.660986\ttest-auc:0.840374\ttest-ks:0.525872\n",
      "[474]\ttrain-auc:0.910899\ttrain-ks:0.661252\ttest-auc:0.84037\ttest-ks:0.525352\n",
      "[475]\ttrain-auc:0.910977\ttrain-ks:0.661518\ttest-auc:0.84041\ttest-ks:0.5262\n",
      "[476]\ttrain-auc:0.911055\ttrain-ks:0.661729\ttest-auc:0.84042\ttest-ks:0.525714\n",
      "[477]\ttrain-auc:0.911109\ttrain-ks:0.661996\ttest-auc:0.840434\ttest-ks:0.525661\n",
      "[478]\ttrain-auc:0.911203\ttrain-ks:0.662192\ttest-auc:0.840451\ttest-ks:0.526193\n",
      "[479]\ttrain-auc:0.911273\ttrain-ks:0.662452\ttest-auc:0.840523\ttest-ks:0.526458\n",
      "[480]\ttrain-auc:0.911354\ttrain-ks:0.662915\ttest-auc:0.840538\ttest-ks:0.5263\n",
      "[481]\ttrain-auc:0.911426\ttrain-ks:0.66285\ttest-auc:0.840544\ttest-ks:0.526005\n",
      "[482]\ttrain-auc:0.911522\ttrain-ks:0.66305\ttest-auc:0.840587\ttest-ks:0.526552\n",
      "[483]\ttrain-auc:0.911606\ttrain-ks:0.663326\ttest-auc:0.840636\ttest-ks:0.526841\n",
      "[484]\ttrain-auc:0.911708\ttrain-ks:0.663592\ttest-auc:0.840688\ttest-ks:0.526547\n",
      "[485]\ttrain-auc:0.911806\ttrain-ks:0.663849\ttest-auc:0.840743\ttest-ks:0.526832\n",
      "[486]\ttrain-auc:0.911896\ttrain-ks:0.66406\ttest-auc:0.840761\ttest-ks:0.526309\n",
      "[487]\ttrain-auc:0.911998\ttrain-ks:0.664392\ttest-auc:0.840768\ttest-ks:0.526764\n",
      "[488]\ttrain-auc:0.912081\ttrain-ks:0.664527\ttest-auc:0.840799\ttest-ks:0.526412\n",
      "[489]\ttrain-auc:0.912156\ttrain-ks:0.664793\ttest-auc:0.840829\ttest-ks:0.526279\n",
      "[490]\ttrain-auc:0.912216\ttrain-ks:0.665123\ttest-auc:0.840864\ttest-ks:0.526541\n",
      "[491]\ttrain-auc:0.912303\ttrain-ks:0.665331\ttest-auc:0.840872\ttest-ks:0.526201\n",
      "[492]\ttrain-auc:0.912374\ttrain-ks:0.665869\ttest-auc:0.840909\ttest-ks:0.526196\n",
      "[493]\ttrain-auc:0.912461\ttrain-ks:0.666137\ttest-auc:0.840967\ttest-ks:0.526479\n",
      "[494]\ttrain-auc:0.912555\ttrain-ks:0.666289\ttest-auc:0.841009\ttest-ks:0.527274\n",
      "[495]\ttrain-auc:0.912659\ttrain-ks:0.666731\ttest-auc:0.841027\ttest-ks:0.526818\n",
      "[496]\ttrain-auc:0.912759\ttrain-ks:0.666614\ttest-auc:0.841103\ttest-ks:0.527077\n",
      "[497]\ttrain-auc:0.912882\ttrain-ks:0.667332\ttest-auc:0.84114\ttest-ks:0.527084\n",
      "[498]\ttrain-auc:0.912982\ttrain-ks:0.667528\ttest-auc:0.841182\ttest-ks:0.527139\n",
      "[499]\ttrain-auc:0.91305\ttrain-ks:0.667739\ttest-auc:0.841187\ttest-ks:0.527673\n",
      "[500]\ttrain-auc:0.91316\ttrain-ks:0.667796\ttest-auc:0.841216\ttest-ks:0.527395\n",
      "[501]\ttrain-auc:0.913209\ttrain-ks:0.667798\ttest-auc:0.841233\ttest-ks:0.527285\n",
      "[502]\ttrain-auc:0.913266\ttrain-ks:0.668128\ttest-auc:0.841236\ttest-ks:0.527547\n",
      "[503]\ttrain-auc:0.913361\ttrain-ks:0.6684\ttest-auc:0.841312\ttest-ks:0.527132\n",
      "[504]\ttrain-auc:0.913424\ttrain-ks:0.668736\ttest-auc:0.841276\ttest-ks:0.527074\n",
      "[505]\ttrain-auc:0.91351\ttrain-ks:0.668669\ttest-auc:0.841302\ttest-ks:0.527356\n",
      "[506]\ttrain-auc:0.913591\ttrain-ks:0.668803\ttest-auc:0.841283\ttest-ks:0.527271\n",
      "[507]\ttrain-auc:0.913688\ttrain-ks:0.669136\ttest-auc:0.841341\ttest-ks:0.526952\n",
      "[508]\ttrain-auc:0.913783\ttrain-ks:0.66927\ttest-auc:0.841337\ttest-ks:0.52669\n",
      "[509]\ttrain-auc:0.913845\ttrain-ks:0.669338\ttest-auc:0.841351\ttest-ks:0.527023\n",
      "[510]\ttrain-auc:0.913911\ttrain-ks:0.669605\ttest-auc:0.84137\ttest-ks:0.527056\n",
      "[511]\ttrain-auc:0.913965\ttrain-ks:0.669805\ttest-auc:0.841371\ttest-ks:0.527067\n",
      "[512]\ttrain-auc:0.914019\ttrain-ks:0.66994\ttest-auc:0.841393\ttest-ks:0.527352\n",
      "[513]\ttrain-auc:0.914122\ttrain-ks:0.670142\ttest-auc:0.841442\ttest-ks:0.527604\n",
      "[514]\ttrain-auc:0.914193\ttrain-ks:0.670142\ttest-auc:0.841473\ttest-ks:0.527596\n",
      "[515]\ttrain-auc:0.914244\ttrain-ks:0.670543\ttest-auc:0.841461\ttest-ks:0.527187\n",
      "[516]\ttrain-auc:0.914341\ttrain-ks:0.670476\ttest-auc:0.841498\ttest-ks:0.527374\n",
      "[517]\ttrain-auc:0.914407\ttrain-ks:0.670606\ttest-auc:0.841509\ttest-ks:0.527382\n",
      "[518]\ttrain-auc:0.914542\ttrain-ks:0.670931\ttest-auc:0.841523\ttest-ks:0.527127\n",
      "[519]\ttrain-auc:0.914598\ttrain-ks:0.671331\ttest-auc:0.841544\ttest-ks:0.527905\n",
      "[520]\ttrain-auc:0.914692\ttrain-ks:0.671396\ttest-auc:0.841573\ttest-ks:0.527881\n",
      "[521]\ttrain-auc:0.91478\ttrain-ks:0.671336\ttest-auc:0.84157\ttest-ks:0.527758\n",
      "[522]\ttrain-auc:0.91487\ttrain-ks:0.671928\ttest-auc:0.841662\ttest-ks:0.528048\n",
      "[523]\ttrain-auc:0.914933\ttrain-ks:0.671872\ttest-auc:0.841687\ttest-ks:0.528348\n",
      "[524]\ttrain-auc:0.914989\ttrain-ks:0.671943\ttest-auc:0.84165\ttest-ks:0.52772\n",
      "[525]\ttrain-auc:0.915093\ttrain-ks:0.672193\ttest-auc:0.841641\ttest-ks:0.52785\n",
      "[526]\ttrain-auc:0.915154\ttrain-ks:0.672112\ttest-auc:0.841623\ttest-ks:0.52746\n",
      "[527]\ttrain-auc:0.915212\ttrain-ks:0.672574\ttest-auc:0.841617\ttest-ks:0.527436\n",
      "[528]\ttrain-auc:0.915317\ttrain-ks:0.672714\ttest-auc:0.841613\ttest-ks:0.527272\n",
      "[529]\ttrain-auc:0.915373\ttrain-ks:0.672844\ttest-auc:0.841625\ttest-ks:0.52779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[530]\ttrain-auc:0.915417\ttrain-ks:0.673039\ttest-auc:0.841612\ttest-ks:0.527512\n",
      "[531]\ttrain-auc:0.915498\ttrain-ks:0.673109\ttest-auc:0.841632\ttest-ks:0.527968\n",
      "[532]\ttrain-auc:0.91559\ttrain-ks:0.673376\ttest-auc:0.841664\ttest-ks:0.528219\n",
      "[533]\ttrain-auc:0.91565\ttrain-ks:0.67364\ttest-auc:0.841665\ttest-ks:0.528158\n",
      "[534]\ttrain-auc:0.915709\ttrain-ks:0.673635\ttest-auc:0.841676\ttest-ks:0.528515\n",
      "[535]\ttrain-auc:0.915844\ttrain-ks:0.673558\ttest-auc:0.841652\ttest-ks:0.528528\n",
      "[536]\ttrain-auc:0.915934\ttrain-ks:0.67384\ttest-auc:0.841715\ttest-ks:0.528767\n",
      "[537]\ttrain-auc:0.916022\ttrain-ks:0.67394\ttest-auc:0.841753\ttest-ks:0.529295\n",
      "[538]\ttrain-auc:0.916098\ttrain-ks:0.674104\ttest-auc:0.84175\ttest-ks:0.529353\n",
      "[539]\ttrain-auc:0.916151\ttrain-ks:0.674134\ttest-auc:0.841738\ttest-ks:0.529089\n",
      "[540]\ttrain-auc:0.916246\ttrain-ks:0.674446\ttest-auc:0.841784\ttest-ks:0.529369\n",
      "[541]\ttrain-auc:0.916307\ttrain-ks:0.674674\ttest-auc:0.841817\ttest-ks:0.529187\n",
      "[542]\ttrain-auc:0.91638\ttrain-ks:0.674541\ttest-auc:0.841825\ttest-ks:0.529102\n",
      "[543]\ttrain-auc:0.916434\ttrain-ks:0.674959\ttest-auc:0.841853\ttest-ks:0.529361\n",
      "[544]\ttrain-auc:0.916521\ttrain-ks:0.674609\ttest-auc:0.841881\ttest-ks:0.529695\n",
      "[545]\ttrain-auc:0.9166\ttrain-ks:0.674816\ttest-auc:0.841863\ttest-ks:0.529604\n",
      "[546]\ttrain-auc:0.916692\ttrain-ks:0.675018\ttest-auc:0.841927\ttest-ks:0.529324\n",
      "[547]\ttrain-auc:0.916754\ttrain-ks:0.67502\ttest-auc:0.841915\ttest-ks:0.529102\n",
      "[548]\ttrain-auc:0.916832\ttrain-ks:0.675287\ttest-auc:0.841948\ttest-ks:0.529362\n",
      "[549]\ttrain-auc:0.916889\ttrain-ks:0.675352\ttest-auc:0.842009\ttest-ks:0.529106\n",
      "[550]\ttrain-auc:0.916976\ttrain-ks:0.675685\ttest-auc:0.841995\ttest-ks:0.528576\n",
      "[551]\ttrain-auc:0.917078\ttrain-ks:0.676086\ttest-auc:0.84201\ttest-ks:0.529175\n",
      "[552]\ttrain-auc:0.917123\ttrain-ks:0.676278\ttest-auc:0.842006\ttest-ks:0.52841\n",
      "[553]\ttrain-auc:0.917188\ttrain-ks:0.676613\ttest-auc:0.842028\ttest-ks:0.528396\n",
      "[554]\ttrain-auc:0.917231\ttrain-ks:0.676616\ttest-auc:0.842034\ttest-ks:0.527992\n",
      "[555]\ttrain-auc:0.917319\ttrain-ks:0.67695\ttest-auc:0.842072\ttest-ks:0.528776\n",
      "[556]\ttrain-auc:0.9174\ttrain-ks:0.677017\ttest-auc:0.842089\ttest-ks:0.528274\n",
      "[557]\ttrain-auc:0.91748\ttrain-ks:0.677354\ttest-auc:0.842088\ttest-ks:0.528274\n",
      "[558]\ttrain-auc:0.917551\ttrain-ks:0.677361\ttest-auc:0.842101\ttest-ks:0.528272\n",
      "[559]\ttrain-auc:0.917636\ttrain-ks:0.67775\ttest-auc:0.84212\ttest-ks:0.528113\n",
      "[560]\ttrain-auc:0.917745\ttrain-ks:0.677912\ttest-auc:0.842151\ttest-ks:0.528062\n",
      "[561]\ttrain-auc:0.917854\ttrain-ks:0.678286\ttest-auc:0.842164\ttest-ks:0.528064\n",
      "[562]\ttrain-auc:0.917914\ttrain-ks:0.67835\ttest-auc:0.842138\ttest-ks:0.527889\n",
      "[563]\ttrain-auc:0.917986\ttrain-ks:0.678417\ttest-auc:0.842139\ttest-ks:0.527884\n",
      "[564]\ttrain-auc:0.918094\ttrain-ks:0.678612\ttest-auc:0.84216\ttest-ks:0.527877\n",
      "[565]\ttrain-auc:0.918151\ttrain-ks:0.678882\ttest-auc:0.8422\ttest-ks:0.527465\n",
      "[566]\ttrain-auc:0.918247\ttrain-ks:0.678953\ttest-auc:0.842232\ttest-ks:0.527608\n",
      "[567]\ttrain-auc:0.918309\ttrain-ks:0.679219\ttest-auc:0.84226\ttest-ks:0.528049\n",
      "[568]\ttrain-auc:0.918392\ttrain-ks:0.679347\ttest-auc:0.842275\ttest-ks:0.528049\n",
      "[569]\ttrain-auc:0.918438\ttrain-ks:0.679679\ttest-auc:0.842299\ttest-ks:0.528302\n",
      "[570]\ttrain-auc:0.918513\ttrain-ks:0.679747\ttest-auc:0.842328\ttest-ks:0.528307\n",
      "[571]\ttrain-auc:0.918582\ttrain-ks:0.679747\ttest-auc:0.842323\ttest-ks:0.528328\n",
      "[572]\ttrain-auc:0.918655\ttrain-ks:0.679812\ttest-auc:0.842334\ttest-ks:0.528079\n",
      "[573]\ttrain-auc:0.918741\ttrain-ks:0.680144\ttest-auc:0.842342\ttest-ks:0.527788\n",
      "[574]\ttrain-auc:0.918824\ttrain-ks:0.680217\ttest-auc:0.842381\ttest-ks:0.52823\n",
      "[575]\ttrain-auc:0.918893\ttrain-ks:0.680411\ttest-auc:0.842397\ttest-ks:0.5281\n",
      "[576]\ttrain-auc:0.918952\ttrain-ks:0.680541\ttest-auc:0.842389\ttest-ks:0.527744\n",
      "[577]\ttrain-auc:0.919002\ttrain-ks:0.680631\ttest-auc:0.842351\ttest-ks:0.527747\n",
      "[578]\ttrain-auc:0.919088\ttrain-ks:0.680844\ttest-auc:0.842418\ttest-ks:0.528012\n",
      "[579]\ttrain-auc:0.919151\ttrain-ks:0.680891\ttest-auc:0.842431\ttest-ks:0.528247\n",
      "[580]\ttrain-auc:0.919194\ttrain-ks:0.680893\ttest-auc:0.842446\ttest-ks:0.527793\n",
      "[581]\ttrain-auc:0.919284\ttrain-ks:0.681158\ttest-auc:0.842464\ttest-ks:0.527512\n",
      "[582]\ttrain-auc:0.919357\ttrain-ks:0.68136\ttest-auc:0.842481\ttest-ks:0.527317\n",
      "[583]\ttrain-auc:0.919409\ttrain-ks:0.681499\ttest-auc:0.842478\ttest-ks:0.527345\n",
      "[584]\ttrain-auc:0.919463\ttrain-ks:0.681655\ttest-auc:0.842471\ttest-ks:0.527829\n",
      "[585]\ttrain-auc:0.919548\ttrain-ks:0.681702\ttest-auc:0.842521\ttest-ks:0.528153\n",
      "[586]\ttrain-auc:0.919624\ttrain-ks:0.681846\ttest-auc:0.842547\ttest-ks:0.527599\n",
      "[587]\ttrain-auc:0.919683\ttrain-ks:0.681973\ttest-auc:0.842561\ttest-ks:0.527626\n",
      "[588]\ttrain-auc:0.919751\ttrain-ks:0.682363\ttest-auc:0.842579\ttest-ks:0.527419\n",
      "[589]\ttrain-auc:0.919842\ttrain-ks:0.682708\ttest-auc:0.84258\ttest-ks:0.527455\n",
      "[590]\ttrain-auc:0.919918\ttrain-ks:0.683161\ttest-auc:0.842559\ttest-ks:0.527798\n",
      "[591]\ttrain-auc:0.920001\ttrain-ks:0.683308\ttest-auc:0.842576\ttest-ks:0.528469\n",
      "[592]\ttrain-auc:0.920088\ttrain-ks:0.683757\ttest-auc:0.842555\ttest-ks:0.528526\n",
      "[593]\ttrain-auc:0.920152\ttrain-ks:0.683803\ttest-auc:0.842539\ttest-ks:0.527733\n",
      "[594]\ttrain-auc:0.920224\ttrain-ks:0.6839\ttest-auc:0.84258\ttest-ks:0.528066\n",
      "[595]\ttrain-auc:0.920273\ttrain-ks:0.683969\ttest-auc:0.842581\ttest-ks:0.52773\n",
      "[596]\ttrain-auc:0.920343\ttrain-ks:0.684438\ttest-auc:0.842609\ttest-ks:0.528532\n",
      "[597]\ttrain-auc:0.920447\ttrain-ks:0.68468\ttest-auc:0.842583\ttest-ks:0.529323\n",
      "[598]\ttrain-auc:0.920507\ttrain-ks:0.684559\ttest-auc:0.842572\ttest-ks:0.528523\n",
      "[599]\ttrain-auc:0.920589\ttrain-ks:0.684746\ttest-auc:0.842559\ttest-ks:0.528542\n",
      "[600]\ttrain-auc:0.920688\ttrain-ks:0.684905\ttest-auc:0.842566\ttest-ks:0.52907\n",
      "[601]\ttrain-auc:0.920742\ttrain-ks:0.684958\ttest-auc:0.842548\ttest-ks:0.528712\n",
      "[602]\ttrain-auc:0.920792\ttrain-ks:0.68549\ttest-auc:0.84256\ttest-ks:0.528679\n",
      "[603]\ttrain-auc:0.920902\ttrain-ks:0.68561\ttest-auc:0.842595\ttest-ks:0.528955\n",
      "[604]\ttrain-auc:0.920986\ttrain-ks:0.685839\ttest-auc:0.842644\ttest-ks:0.528964\n",
      "[605]\ttrain-auc:0.921057\ttrain-ks:0.685904\ttest-auc:0.842607\ttest-ks:0.528426\n",
      "[606]\ttrain-auc:0.921143\ttrain-ks:0.686231\ttest-auc:0.842609\ttest-ks:0.528154\n",
      "[607]\ttrain-auc:0.92119\ttrain-ks:0.686404\ttest-auc:0.842645\ttest-ks:0.52825\n",
      "[608]\ttrain-auc:0.921285\ttrain-ks:0.686698\ttest-auc:0.842648\ttest-ks:0.529003\n",
      "[609]\ttrain-auc:0.921348\ttrain-ks:0.686766\ttest-auc:0.842678\ttest-ks:0.529275\n",
      "[610]\ttrain-auc:0.921416\ttrain-ks:0.68723\ttest-auc:0.842716\ttest-ks:0.528486\n",
      "[611]\ttrain-auc:0.921469\ttrain-ks:0.687237\ttest-auc:0.842715\ttest-ks:0.528486\n",
      "[612]\ttrain-auc:0.921549\ttrain-ks:0.687383\ttest-auc:0.842733\ttest-ks:0.528577\n",
      "[613]\ttrain-auc:0.921625\ttrain-ks:0.687461\ttest-auc:0.842742\ttest-ks:0.528474\n",
      "[614]\ttrain-auc:0.921726\ttrain-ks:0.687649\ttest-auc:0.84278\ttest-ks:0.528714\n",
      "[615]\ttrain-auc:0.921798\ttrain-ks:0.687914\ttest-auc:0.842777\ttest-ks:0.528732\n",
      "[616]\ttrain-auc:0.921848\ttrain-ks:0.68816\ttest-auc:0.842778\ttest-ks:0.527966\n",
      "[617]\ttrain-auc:0.92191\ttrain-ks:0.688293\ttest-auc:0.842753\ttest-ks:0.527599\n",
      "[618]\ttrain-auc:0.921981\ttrain-ks:0.688304\ttest-auc:0.842748\ttest-ks:0.528108\n",
      "[619]\ttrain-auc:0.922096\ttrain-ks:0.688689\ttest-auc:0.842763\ttest-ks:0.528337\n",
      "[620]\ttrain-auc:0.922189\ttrain-ks:0.688776\ttest-auc:0.842766\ttest-ks:0.528115\n",
      "[621]\ttrain-auc:0.922283\ttrain-ks:0.689372\ttest-auc:0.84276\ttest-ks:0.528174\n",
      "[622]\ttrain-auc:0.922359\ttrain-ks:0.689762\ttest-auc:0.842746\ttest-ks:0.527976\n",
      "[623]\ttrain-auc:0.92244\ttrain-ks:0.689899\ttest-auc:0.842812\ttest-ks:0.528693\n",
      "[624]\ttrain-auc:0.922501\ttrain-ks:0.689773\ttest-auc:0.842843\ttest-ks:0.529082\n",
      "[625]\ttrain-auc:0.922566\ttrain-ks:0.6897\ttest-auc:0.842873\ttest-ks:0.52906\n",
      "[626]\ttrain-auc:0.92264\ttrain-ks:0.69014\ttest-auc:0.842874\ttest-ks:0.528663\n",
      "[627]\ttrain-auc:0.922734\ttrain-ks:0.69067\ttest-auc:0.842897\ttest-ks:0.529009\n",
      "[628]\ttrain-auc:0.922783\ttrain-ks:0.691074\ttest-auc:0.84292\ttest-ks:0.52947\n",
      "[629]\ttrain-auc:0.922853\ttrain-ks:0.69094\ttest-auc:0.8429\ttest-ks:0.529479\n",
      "[630]\ttrain-auc:0.922944\ttrain-ks:0.691399\ttest-auc:0.842912\ttest-ks:0.529463\n",
      "[631]\ttrain-auc:0.923\ttrain-ks:0.691607\ttest-auc:0.842901\ttest-ks:0.529732\n",
      "[632]\ttrain-auc:0.923045\ttrain-ks:0.691399\ttest-auc:0.842892\ttest-ks:0.52973\n",
      "[633]\ttrain-auc:0.923137\ttrain-ks:0.691666\ttest-auc:0.842882\ttest-ks:0.52981\n",
      "[634]\ttrain-auc:0.923192\ttrain-ks:0.691931\ttest-auc:0.842868\ttest-ks:0.529797\n",
      "[635]\ttrain-auc:0.923261\ttrain-ks:0.692068\ttest-auc:0.842885\ttest-ks:0.529516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[636]\ttrain-auc:0.923343\ttrain-ks:0.692267\ttest-auc:0.842941\ttest-ks:0.529272\n",
      "[637]\ttrain-auc:0.923429\ttrain-ks:0.692474\ttest-auc:0.842949\ttest-ks:0.529486\n",
      "[638]\ttrain-auc:0.92349\ttrain-ks:0.692541\ttest-auc:0.842982\ttest-ks:0.53054\n",
      "[639]\ttrain-auc:0.923531\ttrain-ks:0.692739\ttest-auc:0.842973\ttest-ks:0.530281\n",
      "[640]\ttrain-auc:0.923598\ttrain-ks:0.692677\ttest-auc:0.842998\ttest-ks:0.529229\n",
      "[641]\ttrain-auc:0.923648\ttrain-ks:0.69281\ttest-auc:0.843036\ttest-ks:0.529482\n",
      "[642]\ttrain-auc:0.923714\ttrain-ks:0.69288\ttest-auc:0.843019\ttest-ks:0.528954\n",
      "[643]\ttrain-auc:0.923759\ttrain-ks:0.692931\ttest-auc:0.843026\ttest-ks:0.529198\n",
      "[644]\ttrain-auc:0.923829\ttrain-ks:0.693354\ttest-auc:0.843061\ttest-ks:0.528444\n",
      "[645]\ttrain-auc:0.923883\ttrain-ks:0.693268\ttest-auc:0.843091\ttest-ks:0.529254\n",
      "[646]\ttrain-auc:0.923959\ttrain-ks:0.693541\ttest-auc:0.843079\ttest-ks:0.529712\n",
      "[647]\ttrain-auc:0.924024\ttrain-ks:0.693612\ttest-auc:0.843106\ttest-ks:0.529973\n",
      "[648]\ttrain-auc:0.924123\ttrain-ks:0.693806\ttest-auc:0.843095\ttest-ks:0.529151\n",
      "[649]\ttrain-auc:0.924206\ttrain-ks:0.693944\ttest-auc:0.843074\ttest-ks:0.529149\n",
      "[650]\ttrain-auc:0.924294\ttrain-ks:0.694074\ttest-auc:0.843119\ttest-ks:0.529677\n",
      "[651]\ttrain-auc:0.924373\ttrain-ks:0.694422\ttest-auc:0.843121\ttest-ks:0.529227\n",
      "[652]\ttrain-auc:0.924431\ttrain-ks:0.694694\ttest-auc:0.843145\ttest-ks:0.528915\n",
      "[653]\ttrain-auc:0.924491\ttrain-ks:0.694764\ttest-auc:0.843178\ttest-ks:0.529217\n",
      "[654]\ttrain-auc:0.924577\ttrain-ks:0.694939\ttest-auc:0.843166\ttest-ks:0.52918\n",
      "[655]\ttrain-auc:0.924659\ttrain-ks:0.695363\ttest-auc:0.843181\ttest-ks:0.528883\n",
      "[656]\ttrain-auc:0.924716\ttrain-ks:0.695708\ttest-auc:0.843197\ttest-ks:0.529151\n",
      "[657]\ttrain-auc:0.92481\ttrain-ks:0.695695\ttest-auc:0.843184\ttest-ks:0.529019\n",
      "[658]\ttrain-auc:0.924923\ttrain-ks:0.696106\ttest-auc:0.843173\ttest-ks:0.528867\n",
      "[659]\ttrain-auc:0.924997\ttrain-ks:0.696556\ttest-auc:0.843178\ttest-ks:0.529616\n",
      "[660]\ttrain-auc:0.92505\ttrain-ks:0.696624\ttest-auc:0.843165\ttest-ks:0.529639\n",
      "[661]\ttrain-auc:0.925108\ttrain-ks:0.696645\ttest-auc:0.843181\ttest-ks:0.529325\n",
      "[662]\ttrain-auc:0.92516\ttrain-ks:0.696721\ttest-auc:0.843181\ttest-ks:0.529562\n",
      "[663]\ttrain-auc:0.925219\ttrain-ks:0.696714\ttest-auc:0.843212\ttest-ks:0.529312\n",
      "[664]\ttrain-auc:0.925265\ttrain-ks:0.697033\ttest-auc:0.843218\ttest-ks:0.52935\n",
      "[665]\ttrain-auc:0.925334\ttrain-ks:0.697111\ttest-auc:0.843196\ttest-ks:0.529047\n",
      "[666]\ttrain-auc:0.925402\ttrain-ks:0.697646\ttest-auc:0.843192\ttest-ks:0.529727\n",
      "[667]\ttrain-auc:0.925472\ttrain-ks:0.697759\ttest-auc:0.843216\ttest-ks:0.529457\n",
      "[668]\ttrain-auc:0.925546\ttrain-ks:0.698118\ttest-auc:0.843208\ttest-ks:0.529185\n",
      "[669]\ttrain-auc:0.92562\ttrain-ks:0.698156\ttest-auc:0.843231\ttest-ks:0.52918\n",
      "[670]\ttrain-auc:0.925664\ttrain-ks:0.698235\ttest-auc:0.843263\ttest-ks:0.528916\n",
      "[671]\ttrain-auc:0.925704\ttrain-ks:0.6983\ttest-auc:0.84325\ttest-ks:0.529172\n",
      "[672]\ttrain-auc:0.925753\ttrain-ks:0.698289\ttest-auc:0.843251\ttest-ks:0.529252\n",
      "[673]\ttrain-auc:0.925801\ttrain-ks:0.698476\ttest-auc:0.843257\ttest-ks:0.529232\n",
      "[674]\ttrain-auc:0.925842\ttrain-ks:0.69863\ttest-auc:0.84324\ttest-ks:0.529495\n",
      "[675]\ttrain-auc:0.925904\ttrain-ks:0.698826\ttest-auc:0.843294\ttest-ks:0.528985\n",
      "[676]\ttrain-auc:0.925989\ttrain-ks:0.699289\ttest-auc:0.843311\ttest-ks:0.529401\n",
      "[677]\ttrain-auc:0.926029\ttrain-ks:0.699223\ttest-auc:0.843307\ttest-ks:0.529425\n",
      "[678]\ttrain-auc:0.926102\ttrain-ks:0.699157\ttest-auc:0.843288\ttest-ks:0.529139\n",
      "[679]\ttrain-auc:0.926193\ttrain-ks:0.699824\ttest-auc:0.843222\ttest-ks:0.529121\n",
      "[680]\ttrain-auc:0.926286\ttrain-ks:0.700091\ttest-auc:0.843332\ttest-ks:0.528863\n",
      "[681]\ttrain-auc:0.92635\ttrain-ks:0.700292\ttest-auc:0.843321\ttest-ks:0.529392\n",
      "[682]\ttrain-auc:0.926408\ttrain-ks:0.70056\ttest-auc:0.843315\ttest-ks:0.528859\n",
      "[683]\ttrain-auc:0.926471\ttrain-ks:0.700689\ttest-auc:0.843312\ttest-ks:0.528845\n",
      "[684]\ttrain-auc:0.926545\ttrain-ks:0.700755\ttest-auc:0.843285\ttest-ks:0.528121\n",
      "[685]\ttrain-auc:0.926612\ttrain-ks:0.701084\ttest-auc:0.843361\ttest-ks:0.528648\n",
      "[686]\ttrain-auc:0.926673\ttrain-ks:0.70142\ttest-auc:0.843376\ttest-ks:0.528646\n",
      "[687]\ttrain-auc:0.926729\ttrain-ks:0.701441\ttest-auc:0.843414\ttest-ks:0.528095\n",
      "[688]\ttrain-auc:0.926814\ttrain-ks:0.701688\ttest-auc:0.8434\ttest-ks:0.528536\n",
      "[689]\ttrain-auc:0.92693\ttrain-ks:0.701916\ttest-auc:0.843403\ttest-ks:0.527965\n",
      "[690]\ttrain-auc:0.926998\ttrain-ks:0.702027\ttest-auc:0.843438\ttest-ks:0.527682\n",
      "[691]\ttrain-auc:0.927073\ttrain-ks:0.702302\ttest-auc:0.843432\ttest-ks:0.527799\n",
      "[692]\ttrain-auc:0.927142\ttrain-ks:0.702763\ttest-auc:0.843482\ttest-ks:0.529092\n",
      "[693]\ttrain-auc:0.927181\ttrain-ks:0.702632\ttest-auc:0.843454\ttest-ks:0.529092\n",
      "[694]\ttrain-auc:0.927243\ttrain-ks:0.702675\ttest-auc:0.843488\ttest-ks:0.528558\n",
      "[695]\ttrain-auc:0.92732\ttrain-ks:0.702922\ttest-auc:0.843503\ttest-ks:0.528337\n",
      "[696]\ttrain-auc:0.927385\ttrain-ks:0.703262\ttest-auc:0.843505\ttest-ks:0.527642\n",
      "[697]\ttrain-auc:0.92744\ttrain-ks:0.703529\ttest-auc:0.843524\ttest-ks:0.527764\n",
      "[698]\ttrain-auc:0.927548\ttrain-ks:0.70349\ttest-auc:0.84353\ttest-ks:0.527799\n",
      "[699]\ttrain-auc:0.927622\ttrain-ks:0.703892\ttest-auc:0.843559\ttest-ks:0.527784\n",
      "[700]\ttrain-auc:0.927709\ttrain-ks:0.703833\ttest-auc:0.843613\ttest-ks:0.527581\n",
      "[701]\ttrain-auc:0.927773\ttrain-ks:0.704099\ttest-auc:0.843609\ttest-ks:0.528341\n",
      "[702]\ttrain-auc:0.927866\ttrain-ks:0.704334\ttest-auc:0.843606\ttest-ks:0.52777\n",
      "[703]\ttrain-auc:0.927963\ttrain-ks:0.70467\ttest-auc:0.843637\ttest-ks:0.528389\n",
      "[704]\ttrain-auc:0.928026\ttrain-ks:0.704603\ttest-auc:0.843621\ttest-ks:0.527872\n",
      "[705]\ttrain-auc:0.928081\ttrain-ks:0.704811\ttest-auc:0.843616\ttest-ks:0.527932\n",
      "[706]\ttrain-auc:0.928153\ttrain-ks:0.704894\ttest-auc:0.843623\ttest-ks:0.527872\n",
      "[707]\ttrain-auc:0.928244\ttrain-ks:0.705523\ttest-auc:0.843656\ttest-ks:0.527609\n",
      "[708]\ttrain-auc:0.928312\ttrain-ks:0.705479\ttest-auc:0.843663\ttest-ks:0.527745\n",
      "[709]\ttrain-auc:0.928377\ttrain-ks:0.705546\ttest-auc:0.843668\ttest-ks:0.528252\n",
      "[710]\ttrain-auc:0.928477\ttrain-ks:0.705898\ttest-auc:0.843702\ttest-ks:0.528592\n",
      "[711]\ttrain-auc:0.928572\ttrain-ks:0.706371\ttest-auc:0.8437\ttest-ks:0.52866\n",
      "[712]\ttrain-auc:0.928641\ttrain-ks:0.706619\ttest-auc:0.843739\ttest-ks:0.528913\n",
      "[713]\ttrain-auc:0.92873\ttrain-ks:0.706821\ttest-auc:0.843818\ttest-ks:0.528942\n",
      "[714]\ttrain-auc:0.928791\ttrain-ks:0.707156\ttest-auc:0.843816\ttest-ks:0.528691\n",
      "[715]\ttrain-auc:0.928865\ttrain-ks:0.706909\ttest-auc:0.843849\ttest-ks:0.529467\n",
      "[716]\ttrain-auc:0.92892\ttrain-ks:0.707218\ttest-auc:0.843865\ttest-ks:0.529227\n",
      "[717]\ttrain-auc:0.928977\ttrain-ks:0.707439\ttest-auc:0.843871\ttest-ks:0.529183\n",
      "[718]\ttrain-auc:0.929022\ttrain-ks:0.707312\ttest-auc:0.843878\ttest-ks:0.529505\n",
      "[719]\ttrain-auc:0.929061\ttrain-ks:0.707374\ttest-auc:0.843869\ttest-ks:0.529205\n",
      "[720]\ttrain-auc:0.929144\ttrain-ks:0.707783\ttest-auc:0.843953\ttest-ks:0.528944\n",
      "[721]\ttrain-auc:0.929236\ttrain-ks:0.708044\ttest-auc:0.843955\ttest-ks:0.528944\n",
      "[722]\ttrain-auc:0.929298\ttrain-ks:0.708364\ttest-auc:0.844014\ttest-ks:0.528912\n",
      "[723]\ttrain-auc:0.929377\ttrain-ks:0.708501\ttest-auc:0.84403\ttest-ks:0.5289\n",
      "[724]\ttrain-auc:0.929436\ttrain-ks:0.708766\ttest-auc:0.84404\ttest-ks:0.528895\n",
      "[725]\ttrain-auc:0.929516\ttrain-ks:0.709035\ttest-auc:0.84407\ttest-ks:0.528715\n",
      "[726]\ttrain-auc:0.929613\ttrain-ks:0.709031\ttest-auc:0.844061\ttest-ks:0.528462\n",
      "[727]\ttrain-auc:0.929681\ttrain-ks:0.709017\ttest-auc:0.844035\ttest-ks:0.528292\n"
     ]
    }
   ],
   "source": [
    "# step7: lower learning_rate and rise n_estimators\n",
    "param_test7 = { 'learning_rate': 0.01, 'n_estimators':1000}\n",
    "tune.params_dict.update(param_test7)\n",
    "tune.model.set_params(**tune.params_dict)\n",
    "tune.xgboost_cv(cv= 5, early_stopping_rounds= 100,n_jobs = 4)\n",
    "tune.dfscore "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
